{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11c16e9-c99b-4ef3-b77a-896da3df9793",
   "metadata": {},
   "source": [
    "# Traces for the previous choice\n",
    "Here we use the components extracted in the previous step and the timestamped data from the behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e2028-2d05-4490-b611-d5071459f8bc",
   "metadata": {},
   "source": [
    "# Prep: libraries, data, functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a99ec-4113-40c2-9fb6-6faaad36846c",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4d0cb-ed79-4cd1-94ef-42b0ceaacfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button, TextBox\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.widgets import CheckButtons\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle # yeah let's pickle\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.stats import sem\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import stats\n",
    "from scipy.stats import permutation_test as permutt\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from IPython import get_ipython\n",
    "import IPython\n",
    "\n",
    "import math\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from scipy.ndimage import binary_erosion\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be750489-3d4b-4995-afaa-33cc5287abe5",
   "metadata": {},
   "source": [
    "## Load the data & create a mega data structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c27366-ca92-4a40-a0af-5db7264739c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "## ===== DELETE THE COLUMNS WITH FRAME LASER AND TONE FRAME ===========================\n",
    "path = 'D:\\\\OneDrive - Rutgers University\\\\CaIm\\\\b3\\\\' \n",
    "mouse_ids =['os85a', 'os85b', 'os86a', 'os86b', 'os87', 'os88', 'os89']\n",
    "time_shifts = {'os85a': 0, 'os85b': 0, 'os86a': 0, 'os86b': 0, \n",
    "                     'os87': 250, 'os88': 0, 'os89': 0}\n",
    "data = {}\n",
    "tone_laser_t_diff = {'os85a': 954, 'os85b': 955, 'os86a': 956, 'os86b': 955, \n",
    "                     'os87': 956, 'os88': 955, 'os89': 955}\n",
    "for id in mouse_ids:\n",
    "    time_shift = time_shifts[id]\n",
    "    path_mouse = path + id + '\\\\'\n",
    "    experiment = {}\n",
    "    entries_exp = os.listdir(path_mouse)\n",
    "    for entry in entries_exp:\n",
    "        if entry[-7:] == '_B3.csv':\n",
    "            path_behav = path_mouse + '\\\\' + entry\n",
    "    behav = pd.read_csv(path_behav)\n",
    "    \n",
    "    # do the time\n",
    "    behav['laser_ts'] = [behav['laser_ts'][n] + time_shift for n in np.arange(behav.shape[0])]\n",
    "\n",
    "    # ============== add extra columns to behav ==============\n",
    "    # random tag\n",
    "    behav['rand'] = [np.random.randint(2) for t in behav['laser_ts'] ]  # column with random values\n",
    "    # previous choice\n",
    "    prev_ch = [0]\n",
    "    prev=[behav['choice'][n-1] for n in np.arange(1,behav.shape[0])]\n",
    "    prev_ch.extend(prev)\n",
    "    behav['prev_choice']=prev_ch\n",
    "    # previous side\n",
    "    prev_side = [0]\n",
    "    prev_s=[behav['side'][n-1] for n in np.arange(1,behav.shape[0])]\n",
    "    prev_side.extend(prev_s)\n",
    "    behav['prev_side']=prev_side\n",
    "    # previous reward\n",
    "    prev_rew = [0]\n",
    "    for n in np.arange(1,behav.shape[0]):\n",
    "        if behav['side'][n-1] == behav['choice'][n-1]:\n",
    "            prev_r = [behav['side'][n-1]]\n",
    "        elif behav['free'][n-1]:\n",
    "            prev_r = [behav['side'][n-1]]\n",
    "        else:\n",
    "            prev_r = [0]\n",
    "        prev_rew.extend(prev_r)\n",
    "    behav['prev_reward']=prev_rew\n",
    "    behav['tone_ts'] = [t-955 for t in behav['laser_ts'] ]\n",
    "    # add inter trial interval\n",
    "    iti = [None]\n",
    "    itis=[behav['laser_ts'][n] - behav['laser_ts'][n-1] for n in np.arange(1,behav.shape[0])]\n",
    "    iti.extend(itis)\n",
    "    behav['ITI']=iti\n",
    "    \n",
    "    # load the lick data\n",
    "    licks_L = pd.read_csv(path_behav[0:-4] + '_t_licks_L.csv', header = None)\n",
    "    licks_R = pd.read_csv(path_behav[0:-4] + '_t_licks_R.csv', header = None)\n",
    "    licks_L = [licks_L[0][n] + time_shift for n in np.arange(licks_L.shape[0])]\n",
    "    licks_R = [licks_R[0][n] + time_shift for n in np.arange(licks_R.shape[0])]\n",
    "\n",
    "     # frame timings\n",
    "    for entry in entries_exp:\n",
    "        if entry[-10:] == 'timing.csv':\n",
    "            path_frame_t = path_mouse + '\\\\' + entry\n",
    "    frame_ts = pd.read_csv(path_frame_t)\n",
    "         \n",
    "    # Load aucs\n",
    "    # Load stats and aucs files if they exist\n",
    "    if os.path.isfile(path + id +'\\\\aucs.pkl'):\n",
    "        with open(path + id +'\\\\aucs.pkl', 'rb') as f:\n",
    "            aucs = pickle.load(f)\n",
    "    experiment['aucs'] = aucs\n",
    "    stats_mouse = pd.read_csv(path + id + '\\\\stats.csv')\n",
    "    experiment['stats'] = stats_mouse\n",
    "    \n",
    "    # get the neuronal traces\n",
    "    path_neu = path_mouse + 'traces.json'\n",
    "    with open(path_neu, 'r') as json_file:\n",
    "        neu_traces = json.load(json_file)\n",
    "    neu_traces = np.array(neu_traces)\n",
    "    \n",
    "    path_deconv = path_mouse + 'deconvolved.json'\n",
    "    with open(path_deconv, 'r') as json_file:\n",
    "        deconvolved = json.load(json_file)\n",
    "    deconvolved = np.array(deconvolved)\n",
    "    path_accept = path_mouse + 'accepted.json'\n",
    "    if os.path.isfile(path_accept):\n",
    "        with open(path_accept, 'r') as json_file:\n",
    "            accepted = json.load(json_file)\n",
    "            # save onoly the accepted neurons\n",
    "            neu_traces = neu_traces[accepted,:]\n",
    "            deconvolved = deconvolved[accepted,:]\n",
    "\n",
    "    # normalize the traces\n",
    "\n",
    "    for trace_n in np.arange(len(neu_traces)):\n",
    "        trace = neu_traces[trace_n]\n",
    "        trace_z = stats.zscore(trace)\n",
    "        trace_z_min = min(trace_z)\n",
    "        trace_z0 = [x - trace_z_min for x in trace_z]\n",
    "        neu_traces[trace_n] = trace_z0\n",
    "        # smoothen for deconvolved\n",
    "        \n",
    "\n",
    "        # interpolate to correct the timing to make it to 100 ms\n",
    "    real_ts = frame_ts['real_ts'].tolist()\n",
    "    new_ts = np.arange(real_ts[0], real_ts[-1], 100)\n",
    "    t_diffs = frame_ts['t_diff'].tolist()\n",
    "    cursed = [t_diff > 330 for t_diff in t_diffs]\n",
    "    frame_ts_new = {'real_ts': new_ts, 't_diff': [100 for n in np.arange(len(new_ts))]}\n",
    "    frame_ts_new = pd.DataFrame(frame_ts_new)\n",
    "\n",
    "    # Interpolated traces\n",
    "    interpolated_traces = np.zeros((neu_traces.shape[0], len(new_ts)))\n",
    "    interpolated_deconv_traces = np.zeros((deconvolved.shape[0], len(new_ts)))\n",
    "    traces_smooth = np.zeros((neu_traces.shape[0], len(new_ts)))\n",
    "    # Interpolate each neuron's activity\n",
    "    for neuron_idx in range(neu_traces.shape[0]):\n",
    "        interpolator = interp1d(real_ts, neu_traces[neuron_idx], kind='linear', fill_value=\"extrapolate\")\n",
    "        interpolated_traces[neuron_idx] = interpolator(new_ts)\n",
    "        # interpolate deconvolved\n",
    "        interpolator_deconv = interp1d(real_ts, deconvolved[neuron_idx], kind='linear', fill_value=\"extrapolate\")\n",
    "        interpolated_deconv_traces[neuron_idx] = interpolator_deconv(new_ts)\n",
    "        \n",
    "        trace_d = interpolated_deconv_traces[neuron_idx]\n",
    "        trace_smooth = np.zeros_like(trace_d) \n",
    "        trace_smooth[0] = (trace_d[0] + trace_d[1]) / 2\n",
    "        trace_smooth[-1] = (trace_d[-2] + trace_d[-1]) / 2\n",
    "        for i in np.arange(1, len(trace_d)-1):\n",
    "            trace_smooth[i] = (trace_d[i-1] + trace_d[i] + trace_d[i+1]) / 3\n",
    "        traces_smooth[trace_n] = trace_smooth\n",
    "        \n",
    "\n",
    "\n",
    "# Add col to behav about ca imaging quality (we need to avoid periods of time with freezes)\n",
    "    # Iterate over each trial\n",
    "    freeze_threshold = 330\n",
    "    behav['ca_well'] = True\n",
    "    rec_len = interpolated_traces.shape[1]*100\n",
    "    trim = False\n",
    "    for index, row in behav.iterrows():\n",
    "        tone_ts = row['tone_ts']\n",
    "        start_window = tone_ts - 2000  \n",
    "        end_window = tone_ts + 5000     \n",
    "    \n",
    "        # Find frames within the time window\n",
    "        frames_in_window = frame_ts[(frame_ts['real_ts'] >= start_window) &\n",
    "                                        (frame_ts['real_ts'] <= end_window)]\n",
    "    \n",
    "        # Check if there are any freezes in this window\n",
    "        if any(frames_in_window['t_diff'] > freeze_threshold):\n",
    "            behav.at[index, 'ca_well'] = False\n",
    "        elif (end_window >= rec_len) & trim == False:\n",
    "            trim_idx = index\n",
    "            trim = True\n",
    "        # specifically for os89\n",
    "        # 610985 end of the 1st rec,  start of the 2nd\n",
    "        \n",
    "        if (id == 'os89'):\n",
    "            start_bad = 610985; end_bad = 722355; tr_dur = 6000\n",
    "            if (behav.at[index, 'laser_ts'] > (start_bad-tr_dur)) & (behav.at[index, 'laser_ts'] < (end_bad+tr_dur)):\n",
    "                behav.at[index-1, 'ca_well'] = False\n",
    "                behav.at[index, 'ca_well'] = False\n",
    "                behav.at[index+1, 'ca_well'] = False\n",
    "    behav = behav[behav['ca_well']].reset_index(drop=True)\n",
    "            \n",
    "\n",
    "    if trim:\n",
    "        behav = behav.iloc[:trim_idx]\n",
    "        \n",
    "    # remove few useless columns\n",
    "    behav.drop(columns=['right_crrect', 'left_crrect', 'ca_well'], inplace=True)\n",
    "    \n",
    "    experiment['behav'] = behav\n",
    "    experiment['licks_L'] = licks_L\n",
    "    experiment['licks_R'] = licks_R\n",
    "    \n",
    "    # get evaluations of the neurons\n",
    "    inside_neurons = pd.read_csv(path_mouse + 'inside_neurons.csv')\n",
    "    good_neurons = pd.read_csv(path_mouse + 'good_neurons.csv')\n",
    "    fair_neurons = pd.read_csv(path_mouse + 'fair_neurons.csv')\n",
    "    inside_neurons = inside_neurons['Inside'].to_list()\n",
    "    good_neurons = good_neurons['Status'].to_list()\n",
    "    fair_neurons = fair_neurons['Fair'].to_list()\n",
    "    \n",
    "\n",
    "    # make a big list of all good / fair neurons\n",
    "    all_good_neurons = []\n",
    "    all_fair_neurons = []\n",
    "    usable_neurons = []\n",
    "    idx = 0\n",
    "    for neuron in inside_neurons:\n",
    "        if neuron:  # If the neuron is inside\n",
    "            if (good_neurons[idx] == 1) & (fair_neurons[idx] == 0):\n",
    "                all_good_neurons.append(1) \n",
    "                all_fair_neurons.append(0)\n",
    "                usable_neurons.append(1) \n",
    "            elif (good_neurons[idx] == 0) & (fair_neurons[idx] == 1):\n",
    "                all_good_neurons.append(0) \n",
    "                all_fair_neurons.append(1)\n",
    "                usable_neurons.append(1) \n",
    "            elif (good_neurons[idx] == 1) & (fair_neurons[idx] == 1):\n",
    "             #   print(f'WTF {id}')\n",
    "                all_good_neurons.append(1) \n",
    "                all_fair_neurons.append(1)\n",
    "                usable_neurons.append(1) \n",
    "            else:\n",
    "                all_good_neurons.append(0) \n",
    "                all_fair_neurons.append(0)\n",
    "                usable_neurons.append(0) \n",
    "            idx += 1 \n",
    "        else: \n",
    "            all_good_neurons.append(0) \n",
    "            all_fair_neurons.append(0) \n",
    "            usable_neurons.append(0) \n",
    "\n",
    "    within_ca_img = behav['laser_ts']<neu_traces.shape[1]*100\n",
    "    non_missed = behav[within_ca_img & behav['missed']==0].shape[0]\n",
    "    correct_left = behav[within_ca_img & (behav['side']==1) & (behav['choice']==1)].shape[0]\n",
    "    correct_right = behav[within_ca_img & (behav['side']==-1) & (behav['choice']==-1)].shape[0]\n",
    "    print(id)\n",
    "    print(f'{non_missed} nomiss, correct: {correct_left} L, {correct_right} R;\\\n",
    "    neurons: {sum(all_good_neurons)} good, {sum(all_fair_neurons)} fair')\n",
    "    \n",
    "    #neu_traces = pd.read_csv(path_neu)\n",
    "  #  neu_traces = neu_traces.to_numpy()\n",
    "    experiment['good_neurons'] = all_good_neurons\n",
    "    experiment['fair_neurons'] = all_fair_neurons\n",
    "    experiment['usable_neurons'] = usable_neurons\n",
    "    experiment['smooth'] = traces_smooth\n",
    "    experiment['ca'] = interpolated_traces\n",
    "    experiment['deconv'] = interpolated_deconv_traces\n",
    "    experiment['frame_ts_og'] = frame_ts\n",
    "    experiment['frame_ts'] = frame_ts_new\n",
    "\n",
    "    # add all the experiment data \n",
    "    data[id] = experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f46b1-7815-4ddd-b269-bfff057f84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pre-computed AUCs if available\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    if os.path.isfile(path + id +'\\\\aucs.pkl'):\n",
    "        with open(path + id +'\\\\aucs.pkl', 'rb') as f:\n",
    "            aucs = pickle.load(f)\n",
    "    data[id]['aucs'] = aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8bbac-520b-4104-9c91-902688344adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothen up the traces\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    ew = data[id]['deconv']\n",
    "    smoothies = np.zeros_like(ew)\n",
    "    for n in np.arange(ew.shape[0]):\n",
    "        trace = pd.Series(ew[n])\n",
    "        smooth = trace.rolling(window=5).mean()\n",
    "        smoothies[n] = smooth\n",
    "    data[id]['smoothies'] = smoothies\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 3))        \n",
    "axs.plot(smoothies[n][:200])\n",
    "axs.plot(trace[:200])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c538e-26ce-4533-b6f9-312a353a3869",
   "metadata": {},
   "source": [
    "## A bunch of sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805225a-4bc9-470d-bcce-bb4d2f2154de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how well the timing looks\n",
    "need_timing_test = True\n",
    "test_range = np.arange(-15, 50, 1)\n",
    "\n",
    "if need_timing_test:\n",
    "    # For each mouse\n",
    "    for id in mouse_ids:\n",
    "        print(f\"::: Mouse  {id} :::\")\n",
    "        prophet_neus = []\n",
    "        data_exp = data[id]\n",
    "        traces = data_exp['ca']\n",
    "        deconvolveds = data_exp['deconv']\n",
    "        behav = data_exp['behav']\n",
    "        behav = behav[behav['missed']==0]\n",
    "        real_ts = data_exp['frame_ts']['real_ts'].tolist()\n",
    "        behav_l = behav[behav['side'] == 1]\n",
    "        behav_r = behav[behav['side'] == -1]\n",
    "        ts_l = behav_l['tone_ts'].values\n",
    "        ts_r = behav_r['tone_ts'].values\n",
    "        idx_ls = []\n",
    "        for t in ts_l:\n",
    "            # Find the index in the ts array closest to the tone_time\n",
    "            idx_l = (np.abs(real_ts - t)).argmin()\n",
    "            if idx_l + test_range[-1] < deconvolveds.shape[1]:\n",
    "                idx_ls.append(idx_l)\n",
    "        idx_rs = []\n",
    "        for t in ts_r:\n",
    "            # Find the index in the ts array closest to the tone_time\n",
    "            idx_r = (np.abs(real_ts - t)).argmin()\n",
    "            if idx_r + test_range[-1] < deconvolveds.shape[1]:\n",
    "                idx_rs.append(idx_r)\n",
    "    \n",
    "        for test_time in test_range:\n",
    "      #      print(f\":::== test time {test_time} ==:::\")\n",
    "            \n",
    "            n_selective = 0\n",
    "            neu_total = traces.shape[0]\n",
    "\n",
    "            for n in np.arange(neu_total):\n",
    "                # if the neurons is not good or fair, skip it\n",
    "              #  if data_exp['fair_neurons'][n] + data_exp['good_neurons'][n] == 0:\n",
    "                #    continue\n",
    "                \n",
    "                trace  = traces[n][:]\n",
    "                deconvolved = deconvolveds[n][:]\n",
    "                \n",
    "                # effects of the side\n",
    "                params = ['missed', 'side']\n",
    "                side_l = [trace[i + test_time] for i in idx_ls]\n",
    "                side_r = [trace[i + test_time] for i in idx_rs]\n",
    "\n",
    "                # Perform Wilcoxon signed-rank test\n",
    "                stat, p_val = stats.ttest_ind(side_l, side_r)            \n",
    "        \n",
    "                if p_val < 0.05:\n",
    "                    n_selective += 1\n",
    "            rate_selective = n_selective/neu_total\n",
    "            prophet_neus.append(n_selective)\n",
    "\n",
    "        #    print(f\" Prophet neurons: {n_selective} \")\n",
    "\n",
    "        plt.plot(test_range,prophet_neus)\n",
    "    plt.axvline(x=0, linestyle=':')\n",
    "    plt.axvline(x=3, linestyle=':')\n",
    "    plt.legend(mouse_ids)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac373d-b2a9-49ab-b46b-d534f8d98933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check89 = False\n",
    "if sanity_check89:\n",
    "    trace = data['os89']['ca'][0]\n",
    "    deconvolved = data['os89']['deconv'][0]\n",
    "    ts = np.arange(len(trace))\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(15, 5))\n",
    "    chunk = len(trace)//3\n",
    "    axs[0].plot(ts[0:2000],trace[0:2000])\n",
    "    axs[1].plot(ts[0:2000],deconvolved[0:2000])\n",
    "    axs[2].plot(ts[6000:7500], trace[6000:7500])\n",
    "    axs[3].plot(ts[6000:7500], deconvolved[6000:7500])\n",
    "    #axs[2].plot(ts[chunk*2:], trace[chunk*2:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7f0c3-925f-4b8c-9545-78276aa23088",
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_check = False\n",
    "id = 'os88'\n",
    "if deconv_check:\n",
    "    find_fair = True\n",
    "    n = 50\n",
    "    while find_fair:\n",
    "        if data[id]['fair_neurons'][n] != 1:\n",
    "            n += 1\n",
    "        else:\n",
    "            find_fair = False\n",
    "    trace = data[id]['ca'][n]\n",
    "    deconvolved = data[id]['deconv'][n]\n",
    "    ts = np.arange(len(trace))\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(15, 5))\n",
    "    chunk = len(trace)//3\n",
    "    axs[0].plot(ts[2000:3000],trace[2000:3000])\n",
    "    axs[1].plot(ts[2000:3000],deconvolved[2000:3000])\n",
    "    axs[2].plot(ts[chunk:chunk*2], trace[chunk:chunk*2])\n",
    "    axs[3].plot(ts[chunk:chunk*2], deconvolved[chunk:chunk*2])\n",
    "    #axs[2].plot(ts[chunk*2:], trace[chunk*2:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ab527-bef5-49ca-b157-f266982a3191",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions for data selection and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275649a-7bbb-4c7f-a16a-72343f0eddcf",
   "metadata": {},
   "source": [
    "## New soon-to-be canon functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507af78-b4f4-46fa-a01b-617f682f6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the needed event times from the behavioral data\n",
    "# for the specified attributes\n",
    "def get_behav_ts(behav, attr, attr_vals, event_type='tone_ts'):\n",
    "    \n",
    "    # select the behav trials according to attributes & values\n",
    "    for a, v, in zip(attr, attr_vals):\n",
    "        behav = behav[behav[a]==v]\n",
    "\n",
    "    ts = behav[event_type]\n",
    "    ts = ts.tolist()\n",
    "    \n",
    "    return ts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898f36a-e2f5-43bd-a880-14e258568418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_correction(p_values, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform FDR correction using the Benjamini-Hochberg method.\n",
    "\n",
    "    Parameters:\n",
    "    p_values (list or numpy array): Array of p-values.\n",
    "    alpha (float): Desired significance level.\n",
    "\n",
    "    Returns:\n",
    "    significant (numpy array): Boolean array indicating which p-values are significant after FDR correction.\n",
    "    \"\"\"\n",
    "    p_values = np.array(p_values)\n",
    "    m = len(p_values)  # Number of tests\n",
    "    sorted_indices = np.argsort(p_values)  # Indices that would sort the p-values\n",
    "    sorted_p_values = p_values[sorted_indices]  # Sorted p-values\n",
    "    adjusted_p_values = np.zeros(m)  # Array to hold adjusted p-values\n",
    "\n",
    "    # Calculate the adjusted p-values\n",
    "    for i in range(m):\n",
    "        adjusted_p_values[i] = sorted_p_values[i] * m / (i + 1)\n",
    "\n",
    "    # Ensure that adjusted p-values are non-decreasing\n",
    "    adjusted_p_values = np.minimum.accumulate(adjusted_p_values[::-1])[::-1]\n",
    "\n",
    "    # Determine which p-values are significant\n",
    "    significant = adjusted_p_values < alpha\n",
    "\n",
    "    # Return the significant p-values in the original order\n",
    "    significant_corrected = np.zeros(m, dtype=bool)\n",
    "    significant_corrected[sorted_indices] = significant\n",
    "\n",
    "    return significant_corrected, adjusted_p_values[sorted_indices]\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume p_values is a list or numpy array of p-values from your permutation tests.\n",
    "p_values = [0.01, 0.03, 0.2, 0.5, 0.04, 0.002, 0.07]\n",
    "alpha = 0.05\n",
    "\n",
    "significant, adjusted_p_values = fdr_correction(p_values, alpha=alpha)\n",
    "\n",
    "print(\"Significant neurons after FDR correction:\", significant)\n",
    "print(\"Adjusted p-values:\", adjusted_p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd8989-9917-4482-95ca-94ca0e98c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ NEW ONE WITH FRAME TIMINGS =============================\n",
    "# default span\n",
    "pre_event_ts = 2000\n",
    "post_event_ts = 6000\n",
    "# Function to extract data around some type of event in 'behav'\n",
    "def get_segments(behav, trace, frame_ts, attrs, attr_vals, trace_type=False, \n",
    "                 span = [pre_event_ts,post_event_ts]):\n",
    "    \n",
    "    for a_n in np.arange(len(attrs)):\n",
    "        behav = behav[behav[attrs[a_n]] == attr_vals[a_n] ]\n",
    "    ts = behav['tone_ts']\n",
    "    real_ts = frame_ts['real_ts']\n",
    "    fr_before = int(span[0]//100)\n",
    "    fr_after = int(span[1]//100)\n",
    "    \n",
    "    segments = []\n",
    "    segments_ts = []\n",
    "    # choose which neural signal to use\n",
    "    for t in ts:\n",
    "        # Find the closest index in frame_ts to the event time 't'\n",
    "        idx = (np.abs(real_ts - t)).argmin()\n",
    "        start = idx - fr_before\n",
    "        end =  idx + fr_after\n",
    "\n",
    "        good_timings = True\n",
    "        for t_diff in frame_ts['t_diff'][start:end]:\n",
    "            if t_diff > 300:\n",
    "                good_timings = False\n",
    "\n",
    "        if (start > 0) and (end < len(trace)) and good_timings:\n",
    "            segment = trace[start:end]\n",
    "            segment_ts = real_ts[start:end]\n",
    "            segment_ts = [time - t for time in segment_ts]\n",
    "            \n",
    "            \n",
    "            segments.append(segment)\n",
    "            segments_ts.append(segment_ts)\n",
    "    \n",
    "    return segments, segments_ts \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01d4fa-2e72-4c13-9d9f-c35b5e001b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =========================== HOPEFULLY GOOD ENOUGH LATEST VERSION FOR ALL SCRIPTS ==================================\n",
    "# Function to extract data around some type of event in 'behav'\n",
    "pre_event_points = 1000\n",
    "post_event_points = 5000\n",
    "def get_segments_canon(trace, ts, frame_ts, span = [pre_event_points,post_event_points]):\n",
    "\n",
    "    real_ts = frame_ts['real_ts']\n",
    "    fr_before = int(span[0]//100)\n",
    "    fr_after = int(span[1]//100)\n",
    "    \n",
    "    segments = []\n",
    "    segments_ts = []\n",
    "    # choose which neural signal to use\n",
    "    for t in ts:\n",
    "        # Find the closest index in frame_ts to the event time 't'\n",
    "        idx = (np.abs(real_ts - t)).argmin()\n",
    "        start = idx - fr_before\n",
    "        end =  idx + fr_after\n",
    "\n",
    "        good_timings = True\n",
    "        for t_diff in frame_ts['t_diff'][start:end]:\n",
    "            if t_diff > 300:\n",
    "                good_timings = False\n",
    "\n",
    "        if (start > 0) and (end < len(trace)) and good_timings:\n",
    "            segment = trace[start:end]\n",
    "            segment_ts = real_ts[start:end]\n",
    "            segment_ts = [time - t for time in segment_ts]\n",
    "            segments.append(segment)\n",
    "            segments_ts.append(segment_ts)   \n",
    "    \n",
    "    return segments, segments_ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1482131-0a9d-434f-b46b-c79ef036e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard timepoints to use\n",
    "# MB DELETE THOSE COMMENTED LINES\n",
    "#pre_event_points = 10\n",
    "#post_event_points = 30\n",
    "#sampling_rate=10\n",
    "\n",
    "# function to plot neuronal average traces\n",
    "def plot_aver_sem(traces, ts, clr, ghost_traces=False, linestyle=None, ax_n = 0):\n",
    "    # Time points for x-axis \n",
    "    #time_points = np.arange(-pre_event_points, post_event_points) * (1000 / sampling_rate)\n",
    "    # Do 2 subplots if ghost traces\n",
    "   \n",
    "    # Convert to numpy array and calculate mean and SEM\n",
    "    mean_trace = np.nanmean(traces, axis=0)\n",
    "    std_trace = sem(traces, axis=0, nan_policy='omit')\n",
    "\n",
    "    # Plot ghost traces if needed\n",
    "    if ghost_traces:\n",
    "        for trace, t in zip(traces, ts):\n",
    "            axs[ax_n + 1].plot(t, trace, clr, alpha=0.2)\n",
    "    \n",
    "    # Plot mean and SEM\n",
    "    axs[ax_n].plot(ts[0], mean_trace, clr, linestyle=linestyle)\n",
    "    axs[ax_n].fill_between(ts[0], mean_trace - std_trace, mean_trace + std_trace, color=clr, alpha=0.2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6975a5d-5562-4654-96a0-b9dc5f260b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard timepoints to use\n",
    "\n",
    "# function to plot neuronal average traces\n",
    "def plot_aver_sem_canon(traces, times, colr, ghost_traces=False, axn=0, linestyle=None, \n",
    "                        span = [pre_event_points,post_event_points], sampling_rate = 100):\n",
    "    # Time points for x-axis\n",
    "    pre_event_points = span[0]\n",
    "    post_event_points = span[1]\n",
    "    time_points = np.arange(-pre_event_points, post_event_points, sampling_rate) \n",
    "    # Do 2 subplots if ghost traces\n",
    "    if ghost_traces:\n",
    "        #fig, axs = plt.subplots(1, 2, figsize=(10, 3)) \n",
    "        for trace, ts in zip(traces, times):\n",
    "            axs[axn+1].plot(time_points, trace, colr, alpha=0.5)\n",
    "   # else:\n",
    "    #    fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    \n",
    "    # Mean and std\n",
    "    mean_trace = np.mean(traces, axis=0)\n",
    "    std_trace = sem(traces, axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    axs[axn].plot(time_points, mean_trace, colr, linestyle=linestyle)\n",
    "    axs[axn].fill_between(time_points, mean_trace - std_trace, mean_trace + std_trace, color=colr, alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe253d-1db8-4bac-bcda-5bb149f9b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(event_ts, trace, frame_ts, t1, t2):\n",
    "    \"\"\"\n",
    "    Calculate the area under the curve (AUC) of neural activity traces \n",
    "    around specific event times\n",
    "\n",
    "    \"\"\"\n",
    "    # get the number of frames needed to be fetched\n",
    "    fr_n = int((t2-t1)/100)\n",
    "\n",
    "    # get ts from the frame_ts dataframe\n",
    "    ts = frame_ts['real_ts'] \n",
    "    \n",
    "    auc_values = []\n",
    "    \n",
    "    for event_t in event_ts:\n",
    "        # Calculate the start and end indices based on t1 and t2\n",
    "        start_time = event_t + t1\n",
    "        \n",
    "        start_idx = (np.abs(ts - start_time)).argmin()\n",
    "        end_idx = start_idx + fr_n\n",
    "                \n",
    "        # Ensure the indices are within the range of the trace\n",
    "        if (start_idx < 0) or (end_idx >= (len(trace)-1)):\n",
    "          #  print(end_idx)\n",
    "            continue\n",
    "        \n",
    "        # Extract the segment of the trace\n",
    "        segment = trace[start_idx:end_idx + 1]\n",
    "        \n",
    "        # Calculate the AUC by simply summing it all haha\n",
    "        auc = sum(segment)\n",
    "        auc_values.append(auc)\n",
    "    \n",
    "    return auc_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac96e14-b315-431e-9e28-915dfc2c46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def permutation_test(data1, data2, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test on two datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - data1, data2: Arrays containing the data for the two groups.\n",
    "    - n_permutations: Number of permutations to perform.\n",
    "    \n",
    "    Returns:\n",
    "    - p-value: The proportion of permuted statistics more extreme than the observed.\n",
    "    \"\"\"\n",
    "    # Calculate the observed difference in means\n",
    "    observed_diff = np.mean(data1) - np.mean(data2)\n",
    "    \n",
    "    # Concatenate the datasets\n",
    "    combined_data = np.concatenate([data1, data2])\n",
    "    \n",
    "    # Initialize a counter for permutations where the permuted difference is more extreme than observed\n",
    "    count_extreme = 0\n",
    "    \n",
    "    # Perform permutations\n",
    "    for _ in range(n_permutations):\n",
    "        # Shuffle the combined data\n",
    "        np.random.shuffle(combined_data)\n",
    "        \n",
    "        # Split the permuted dataset\n",
    "        permuted_data1 = combined_data[:len(data1)]\n",
    "        permuted_data2 = combined_data[len(data1):]\n",
    "        \n",
    "        # Calculate the difference in means for the permuted datasets\n",
    "        permuted_diff = np.mean(permuted_data1) - np.mean(permuted_data2)\n",
    "        \n",
    "        # Check if the permuted difference is as extreme as the observed difference\n",
    "        if abs(permuted_diff) >= abs(observed_diff):\n",
    "            count_extreme += 1\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = count_extreme / n_permutations\n",
    "    \n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93357696-3f2e-462f-9da6-d93c05a4eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the new functions\n",
    "code = {'l': 1, 'r': -1}\n",
    "t1 = 0; t2 = 1200; t3 = 2500\n",
    "time_periods = [ [0, 1200], [1200, 2400], [2400, 3600] ]\n",
    "# For each mouse\n",
    "for id in mouse_ids[6:]:\n",
    "\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    data_exp = data[id]\n",
    "   # traces = data_exp['ca']\n",
    "    traces = data_exp['deconv']\n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    n_tr = behav.shape[0]\n",
    "    for neu in np.arange(traces.shape[0]):\n",
    "        # if the neurons is not good or fair, skip it\n",
    "        if data_exp['fair_neurons'][neu] + data_exp['good_neurons'][neu] == 0:\n",
    "            continue\n",
    "            \n",
    "        trace  = traces[neu][:]\n",
    "        disp_fig = False\n",
    "        aucs = {}\n",
    "        params = ['missed', 'laser', 'choice', 'side']\n",
    "        p_vals = {}\n",
    "        for t1,t2 in time_periods:\n",
    "            for side in ['l', 'r']:\n",
    "                event_ts = get_behav_ts(behav, params, [0, 0, code[side], code[side]])\n",
    "                aucs[side] = get_auc(event_ts, trace, frame_ts, t1, t2)\n",
    "            p_value_side = permutation_test(aucs['l'], aucs['r'], 1000)\n",
    "            \n",
    "            if p_value_side < 0.02:\n",
    "                disp_fig = True\n",
    "\n",
    "        if disp_fig:\n",
    "            # prep the figure\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "            for cond in ['side']:\n",
    "                params = [cond, 'missed']\n",
    "\n",
    "                ts_l = get_behav_ts(behav, params, [1, 0])\n",
    "                ts_r = get_behav_ts(behav, params, [-1, 0])\n",
    "                for event_t in ts_r:\n",
    "                    if (event_t < 720000) & (event_t > 600083):\n",
    "                        print(event_t)\n",
    "\n",
    "                segms_l, times_l = get_segments_canon(trace, ts_l, frame_ts)\n",
    "                segms_r, times_r = get_segments_canon(trace, ts_r, frame_ts)\n",
    "\n",
    "                plot_aver_sem_canon(segms_l, times_l, 'b', ghost_traces=True)\n",
    "                plot_aver_sem_canon(segms_r, times_r, 'r', ghost_traces=True)\n",
    "\n",
    "\n",
    "\n",
    "                for ax_n in [0,1]:\n",
    "                    axs[ax_n].axvline(x=0)\n",
    "                    axs[ax_n].axvline(x=1150)\n",
    "\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521db4a-bb83-4855-b0a4-5df3a4a6df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# distance btw points in component space\n",
    "\n",
    "def distance_btw_comp(condtions, data_exp, ca_df_time_points, w=[9, 17], span=[0, 30]):\n",
    "    coords_av = {condtions[0]:[], condtions[1]:[]}\n",
    "    \n",
    "\n",
    "    cas = ca_df_time_points.keys()\n",
    "    \n",
    "    for key in coords_av.keys():\n",
    "        params = param_val_keys[key]['params']\n",
    "        vals = param_val_keys[key]['vals']\n",
    "        coords_cond = []\n",
    "        \n",
    "        for ca_n in cas:\n",
    "            comp = ca_df_time_points[ca_n]\n",
    "            traces = get_segments_old(data_exp, params, vals, n, frame_type='frame_tone', span=span, is_pca=True, pc=comp)\n",
    "            coords_n = [np.mean(trace[span[0]+w[0]:span[0]+w[1]]) for trace in traces]\n",
    "            coord_n_av = np.mean(coords_n)\n",
    "            coords_cond.append(coord_n_av)\n",
    "        \n",
    "        coords_av[key] = coords_cond\n",
    "    \n",
    "    distance = np.sqrt(np.sum((np.array(coords_av[condtions[0]]) - np.array(coords_av[condtions[1]]))**2))\n",
    "    return distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de5fd3-192a-457a-a6f1-f211a8262a30",
   "metadata": {},
   "source": [
    "# All stats to extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06c5ee-60b7-49a9-a235-e54b113fae0c",
   "metadata": {},
   "source": [
    "### Get all AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c0522-456f-41aa-a332-870fa0fea7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add to all experiemnt a tables the auc for pre, tone, and resp\n",
    "code = {'pre': [-1000, 0], 'tone': [0, 1000], 'resp': [1000, 2000], 'resp2': [2000, 3000], 'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "\n",
    "    if 'aucs' in data[id].keys():\n",
    "        print(f'aucs for {id} done')\n",
    "        continue\n",
    "    elif os.path.isfile(path + id +'\\\\aucs.json'):\n",
    "        with open(path + id +'\\\\aucs.json', 'r') as f:\n",
    "            aucs = json.load(f)\n",
    "        data[id]['aucs'] = aucs\n",
    "\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav'] \n",
    "    all_ts = get_behav_ts(behav, [], [])\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    n_tr = behav.shape[0] \n",
    "    aucs = {}\n",
    "    for trace_type in ['ca', 'deconv']:\n",
    "        period_aucs = {}\n",
    "        period_aucs_to_save = {}\n",
    "        for time_period in time_periods:\n",
    "            print(f'{trace_type} {time_period}')\n",
    "            neu_aucs = {}\n",
    "            for n in np.arange(data_exp[trace_type].shape[0]):\n",
    "                trace = data_exp[trace_type][n]\n",
    "                t1, t2 = code[time_period]\n",
    "                \n",
    "                neu_aucs[n] = get_auc(all_ts, trace, frame_ts, t1, t2)\n",
    "                \n",
    "            # here we add period aucs\n",
    "            neu_aucs_df = pd.DataFrame(neu_aucs)\n",
    "            period_aucs[time_period] = neu_aucs_df\n",
    "        # here we add trace types aucs\n",
    "        aucs[trace_type] = period_aucs\n",
    "\n",
    "    print(behav.shape, neu_aucs_df.shape, data_exp[trace_type].shape)\n",
    "    data[id]['aucs'] = aucs\n",
    "    with open(path + id +'\\\\aucs.pkl', 'wb') as f:\n",
    "        pickle.dump(aucs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe9be0-4f5d-4e7f-968b-d6790666a212",
   "metadata": {},
   "source": [
    "### Add specifically laser AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad0fb1-0f10-4a76-bb1b-45927c20e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add to all experiemnt a tables the auc for pre, tone, and resp\n",
    "code = {'pre': [-1000, 0], 'tone': [0, 1000], 'resp': [1000, 2000], 'resp2': [2000, 3000], 'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "\n",
    "    aucs = data[id]['aucs'] \n",
    "\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav'] \n",
    "    all_ts = get_behav_ts(behav, [], [])\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    n_tr = behav.shape[0] \n",
    "    aucs = {}\n",
    "    for trace_type in ['ca', 'deconv']:\n",
    "        period_aucs = {}\n",
    "        period_aucs_to_save = {}\n",
    "        print(f'{trace_type} ')\n",
    "  \n",
    "        neu_aucs = {}\n",
    "        for n in np.arange(data_exp[trace_type].shape[0]):\n",
    "            trace = data_exp[trace_type][n]\n",
    "            t1 = 1250\n",
    "            t2 = 2250\n",
    "            \n",
    "            neu_aucs[n] = get_auc(all_ts, trace, frame_ts, t1, t2)\n",
    "            \n",
    "        # here we add period aucs\n",
    "        neu_aucs_df = pd.DataFrame(neu_aucs)\n",
    "\n",
    "    print(behav.shape, neu_aucs_df.shape, data_exp[trace_type].shape)\n",
    "    data[id]['aucs'][trace_type]['polas'] = neu_aucs_df\n",
    "    with open(path + id +'\\\\aucs.pkl', 'wb') as f:\n",
    "        pickle.dump(aucs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f44b3-45a7-4366-aca2-b705f6fcb7d2",
   "metadata": {},
   "source": [
    "## Major stats: side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293b13-b397-47b2-ae7b-654e8e1b54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = {'l': 1, 'r': -1, \n",
    "    #    'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "     #   'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "     #   'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "trace_types = ['ca', 'deconv']\n",
    "           \n",
    "# number of permutations to perform; ideally 10000\n",
    "n_permut = 10000\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    '''\n",
    "    if os.path.isfile(path + id + '\\\\stats.csv'):\n",
    "        stats_mouse = pd.read_csv(path + id + '\\\\stats.csv')\n",
    "        data[id]['stats'] = stats_mouse\n",
    "        print(f'stats loaded for {id}')\n",
    "        continue\n",
    "    '''\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    aucs = data_exp['aucs']\n",
    "    n_neu = len(data_exp['ca'])\n",
    "    n_tr = behav.shape[0] \n",
    "   # if 'stats' not in data[id].keys():\n",
    "    if True:\n",
    "        neu_ids = np.arange(n_neu)\n",
    "        usable = data_exp['usable_neurons']\n",
    "        data[id]['stats'] = {\n",
    "                             'neu_n': neu_ids,\n",
    "                             'usable': usable,\n",
    "                            }\n",
    "    # from behav, make the masks for the selection of aucs\n",
    "    correct_l = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 0)\n",
    "    correct_r = (behav['side'] ==-1) & (behav['choice'] ==-1) & (behav['laser'] == 0)\n",
    "    prev_l = (behav['prev_reward'] == 1) & (behav['laser'] == 0)\n",
    "    prev_r = (behav['prev_reward'] ==-1) & (behav['laser'] == 0)\n",
    "    same_l = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['prev_reward'] == 1) & (behav['laser'] == 0)\n",
    "    diff_l = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['prev_reward'] ==-1) & (behav['laser'] == 0)\n",
    "    same_r = (behav['side'] ==-1) & (behav['choice'] ==-1) & (behav['prev_reward'] ==-1) & (behav['laser'] == 0)\n",
    "    diff_r = (behav['side'] ==-1) & (behav['choice'] ==-1) & (behav['prev_reward'] == 1) & (behav['laser'] == 0)\n",
    "    stats_mouse = {}\n",
    "\n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    "        for metric in ['p_', 'diff_']:\n",
    "            stats_mouse[metric + 'side_' + time_period + '_' + trace_type] = []\n",
    "            stats_mouse[metric + 'oomf_l_' + time_period + '_' + trace_type] = []\n",
    "            stats_mouse[metric + 'oomf_r_' + time_period + '_' + trace_type] = []\n",
    "            stats_mouse[metric + 'prew_' + time_period + '_' + trace_type] = []\n",
    "            \n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    " #   for trace_type in ['ca', 'deconv']: \n",
    "   #     for time_period in time_periods:\n",
    "        aucs_neu_list = aucs[trace_type][time_period]\n",
    "        aucs_neu_np = np.array(aucs_neu_list)\n",
    "        for n in np.arange(n_neu):\n",
    "            if n % 100 == 0:\n",
    "                print(n, trace_type, time_period)\n",
    "            # select the neuron's aucs\n",
    "           # aucs_neu_n = [sublist[n] for sublist in aucs_neu_list]\n",
    "            aucs_neu_n = aucs_neu_np[:,n]\n",
    "            # Stats for side preference (all correct)\n",
    "            aucs_l = [elem for i, elem in enumerate(aucs_neu_n) if correct_l.iloc[i]]\n",
    "            aucs_r = [elem for i, elem in enumerate(aucs_neu_n) if correct_r.iloc[i]]\n",
    "            p_side = permutation_test(aucs_l, aucs_r, n_permut) \n",
    "            diff_side = np.mean(aucs_l) - np.mean(aucs_r) \n",
    "            stats_mouse['p_side_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_mouse['diff_side_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # Stats for prev reward\n",
    "            aucs_l = [elem for i, elem in enumerate(aucs_neu_n) if prev_l.iloc[i]]\n",
    "            aucs_r = [elem for i, elem in enumerate(aucs_neu_n) if prev_r.iloc[i]]\n",
    "            p = permutation_test(aucs_l, aucs_r, n_permut) \n",
    "            diff = np.mean(aucs_l) - np.mean(aucs_r) \n",
    "            stats_mouse['p_prew_' + time_period + '_' + trace_type].append(p)\n",
    "            stats_mouse['diff_prew_' + time_period + '_' + trace_type].append(diff)\n",
    "            # oomfs\n",
    "            # left\n",
    "            aucs_same = [elem for i, elem in enumerate(aucs_neu_n) if same_l.iloc[i]]\n",
    "            aucs_diff = [elem for i, elem in enumerate(aucs_neu_n) if diff_l.iloc[i]]\n",
    "            p = permutation_test(aucs_same, aucs_diff, n_permut) \n",
    "            diff = np.mean(aucs_diff) - np.mean(aucs_same) \n",
    "            stats_mouse['p_oomf_l_' + time_period + '_' + trace_type].append(p)\n",
    "            stats_mouse['diff_oomf_l_' + time_period + '_' + trace_type].append(diff)\n",
    "            # right\n",
    "            aucs_same = [elem for i, elem in enumerate(aucs_neu_n) if same_r.iloc[i]]\n",
    "            aucs_diff = [elem for i, elem in enumerate(aucs_neu_n) if diff_r.iloc[i]]\n",
    "            p = permutation_test(aucs_same, aucs_diff, n_permut) \n",
    "            diff = np.mean(aucs_diff) - np.mean(aucs_same) \n",
    "            stats_mouse['p_oomf_r_' + time_period + '_' + trace_type].append(p)\n",
    "            stats_mouse['diff_oomf_r_' + time_period + '_' + trace_type].append(diff)\n",
    "    # append everything to the main mouse stats data\n",
    "    for key in stats_mouse.keys():\n",
    "        data[id]['stats'][key] = stats_mouse[key]\n",
    "   \n",
    "for id in mouse_ids:\n",
    "    stats_exp = data[id]['stats']\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee4577-feb9-4bc8-8a0e-de55c7278cf5",
   "metadata": {},
   "source": [
    "### Save the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741d3ab-1748-435d-b528-d80460d5bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the stats\n",
    "for id in mouse_ids:\n",
    "    stats_exp = data[id]['stats']\n",
    "    stats_exp = pd.DataFrame(stats_exp)\n",
    "    data[id]['stats'] = stats_exp\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c126c0-918f-42a7-a16d-17380d8259dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the scipy permutation test is faster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7883a-772b-494c-9421-f9359b432f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.stats import permutation_test as permutt\n",
    "\n",
    "# Assuming aucs_y and aucs_n are your two lists\n",
    "\n",
    "def diff_stat(x, y):\n",
    "    \"\"\"Function to calculate the difference in means.\"\"\"\n",
    "    return np.mean(x) - np.mean(y)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "for tt in np.arange(100):\n",
    "    p_value = permutation_test(aucs_l, aucs_r, n_permut)\n",
    "    p_value = permutation_test(aucs_same, aucs_diff, n_permut)\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time with my own lil permutation test: {execution_time} seconds\")\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "for tt in np.arange(100):\n",
    "    p_value = permutt((aucs_l, aucs_r), diff_stat, permutation_type='independent', n_resamples=n_permut)\n",
    "    p_value = permutt((aucs_same, aucs_diff), diff_stat, permutation_type='independent', n_resamples=n_permut)\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time with Scipy permutation test: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741c1ea-c106-44c0-b153-5ffe3abed86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a1a1056-693b-4033-bf28-f661ac8e701a",
   "metadata": {},
   "source": [
    "### Add laser stats = FOR NOW ONLY DECONVOLVED!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620e67c-35f0-4db8-a319-09a2b7128eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = {'l': 1, 'r': -1, \n",
    "    #    'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "     #   'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "     #   'anticip': [3000, 4000]}\n",
    "#time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "time_periods = ['resp', 'resp2', 'post_laser']\n",
    "trace_types = ['deconv'] # HERE ONLY DECONVOLVED FOR NOW< BUT LATER ADD CA AS WELL\n",
    "           \n",
    "# number of permutations to perform; ideally 10000\n",
    "n_permut = 2000\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    '''\n",
    "    if os.path.isfile(path + id + '\\\\stats.csv'):\n",
    "        stats_mouse = pd.read_csv(path + id + '\\\\stats.csv')\n",
    "        data[id]['stats'] = stats_mouse\n",
    "        print(f'stats loaded for {id}')\n",
    "        continue\n",
    "    '''\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    aucs = data_exp['aucs']\n",
    "    n_neu = len(data_exp['ca'])\n",
    "    n_tr = behav.shape[0] \n",
    "   # if 'stats' not in data[id].keys():\n",
    "\n",
    "    # from behav, make the masks for the selection of aucs\n",
    "\n",
    "    las_l = (behav['side'] == 1) & (behav['laser'] == 1)\n",
    "    las_l0 = (behav['side'] == 1) &  (behav['laser'] == 0)\n",
    "    las_r = (behav['side'] == -1) &  (behav['laser'] == -1)\n",
    "    las_r0 = (behav['side'] == -1) & (behav['laser'] == 0)\n",
    "    \n",
    "    # here goes nothing\n",
    "    las_l_same = (behav['side'] == 1)  & (behav['laser'] == 1) & (behav['prev_reward'] == 1)\n",
    "    las_l0_same = (behav['side'] == 1)  & (behav['laser'] == 0) & (behav['prev_reward'] == 1)\n",
    "    las_l_diff = (behav['side'] == 1)  & (behav['laser'] == 1) & (behav['prev_reward'] == -1)\n",
    "    las_l0_diff = (behav['side'] == 1)  & (behav['laser'] == 0) & (behav['prev_reward'] == -1)\n",
    "    \n",
    "    las_r_same = (behav['side'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == -1)\n",
    "    las_r0_same = (behav['side'] == -1) & (behav['laser'] == 0) & (behav['prev_reward'] == -1)\n",
    "    las_r_diff = (behav['side'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == 1)\n",
    "    las_r0_diff = (behav['side'] == -1) & (behav['laser'] == 0) & (behav['prev_reward'] == 1)\n",
    "\n",
    "    \n",
    "    stats_add= {}\n",
    "\n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    "        for metric in ['p_', 'diff_']:\n",
    "            for side in ['l_', 'r_']:\n",
    "                stats_add[metric + 'lass_' + side + time_period + '_' + trace_type] = []\n",
    "             #   stats_add[metric + 'las_same_' + side + time_period + '_' + trace_type] = []\n",
    "             #   stats_add[metric + 'las_diff_' + side + time_period + '_' + trace_type] = []\n",
    "            \n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    " #   for trace_type in ['ca', 'deconv']: \n",
    "   #     for time_period in time_periods:\n",
    "        aucs_neu_list = aucs[trace_type][time_period]\n",
    "        aucs_neu_np = np.array(aucs_neu_list)\n",
    "        for n in np.arange(n_neu):\n",
    "            if n % 100 == 0:\n",
    "                print(n, trace_type, time_period)\n",
    "            # select the neuron's aucs\n",
    "            aucs_neu_n = aucs_neu_np[:,n]\n",
    "            # Stats for laser effects (all correct)\n",
    "            # Left\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l0.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_lass_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_lass_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # Right\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r0.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_lass_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_lass_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            '''\n",
    "            # Those fucking oomf lasers\n",
    "            # Left\n",
    "            # same\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_same.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l0_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_same_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_same_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # diff\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l0_diff.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_diff_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_diff_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "\n",
    "            # Right\n",
    "            # same\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_same.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r0_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_same_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_same_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # diff\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r0_diff.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_diff_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_diff_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "    '''\n",
    "\n",
    "    # append everything to the main mouse stats data\n",
    "    for key in stats_add.keys():\n",
    "        data[id]['stats'][key] = stats_add[key]\n",
    "   \n",
    "for id in mouse_ids:\n",
    "    stats_exp = data[id]['stats']\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352814fc-1df8-4424-85f6-2bfa395bc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = {'l': 1, 'r': -1, \n",
    "    #    'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "     #   'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "     #   'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "trace_types = ['deconv'] # HERE ONLY DECONVOLVED FOR NOW< BUT LATER ADD CA AS WELL\n",
    "           \n",
    "# number of permutations to perform; ideally 10000\n",
    "n_permut = 10000\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    '''\n",
    "    if os.path.isfile(path + id + '\\\\stats.csv'):\n",
    "        stats_mouse = pd.read_csv(path + id + '\\\\stats.csv')\n",
    "        data[id]['stats'] = stats_mouse\n",
    "        print(f'stats loaded for {id}')\n",
    "        continue\n",
    "    '''\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    aucs = data_exp['aucs']\n",
    "    n_neu = len(data_exp['ca'])\n",
    "    n_tr = behav.shape[0] \n",
    "   # if 'stats' not in data[id].keys():\n",
    "\n",
    "    # from behav, make the masks for the selection of aucs\n",
    "\n",
    "    las_l = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 1)\n",
    "    las_l0 = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 0)\n",
    "    las_r = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == -1)\n",
    "    las_r0 = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == 0)\n",
    "\n",
    "    las_ll = (behav['side'] == 1) & (behav['laser'] == 1)\n",
    "    las_ll0 = (behav['side'] == 1)  & (behav['laser'] == 0)\n",
    "    las_rr = (behav['side'] == -1)  & (behav['laser'] == -1)\n",
    "    las_rr0 = (behav['side'] == -1) & (behav['laser'] == 0)\n",
    "    \n",
    "    # here goes nothing\n",
    "    las_l_same = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 1) & (behav['prev_reward'] == 1)\n",
    "    las_l0_same = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 0) & (behav['prev_reward'] == 1)\n",
    "    las_l_diff = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 1) & (behav['prev_reward'] == -1)\n",
    "    las_l0_diff = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 0) & (behav['prev_reward'] == -1)\n",
    "    \n",
    "    las_r_same = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == -1)\n",
    "    las_r0_same = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == 0) & (behav['prev_reward'] == -1)\n",
    "    las_r_diff = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == 1)\n",
    "    las_r0_diff = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == 0) & (behav['prev_reward'] == 1)\n",
    "\n",
    "    \n",
    "    stats_add= {}\n",
    "    time_period = 'resp'\n",
    "    for trace_type in trace_types:\n",
    "        for metric in ['p_', 'diff_']:\n",
    "            for side in ['l_', 'r_']:\n",
    "                stats_add[metric + 'lass_' + side + 'post_laser' + '_' + trace_type] = []\n",
    "               # stats_add[metric + 'las_same_' + side + time_period + '_' + trace_type] = []\n",
    "              #  stats_add[metric + 'las_diff_' + side + time_period + '_' + trace_type] = []\n",
    "              #  stats_add[metric + 'las_oomf_' + side + time_period + '_' + trace_type] = []\n",
    "            \n",
    "    for trace_type in trace_types:\n",
    "        aucs_neu_list = aucs[trace_type][time_period]\n",
    "        aucs_neu_np = np.array(aucs_neu_list)\n",
    "        for n in np.arange(n_neu):\n",
    "            if n % 100 == 0:\n",
    "                print(n, trace_type, time_period)\n",
    "            # select the neuron's aucs\n",
    "            aucs_neu_n = aucs_neu_np[:,n]\n",
    "            # Stats for laser effects (all correct)\n",
    "            # Left\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_ll.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_ll0.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_lass_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_lass_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            \n",
    "            # Right\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_rr.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_rr0.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_lass_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_lass_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            '''\n",
    "            # Those fucking oomf lasers\n",
    "            # Left\n",
    "            # same\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_same.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l0_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_same_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_same_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # diff\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l0_diff.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_diff_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_diff_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "\n",
    "            # Right\n",
    "            # same\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_same.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r0_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_same_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_same_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # diff\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r0_diff.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_diff_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_diff_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "\n",
    "            # Those fucking ELABORATE oomf lasers\n",
    "            # Left oomf laser\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_oomf_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_oomf_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # Right oomf laser\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_oomf_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_oomf_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            '''\n",
    "\n",
    "\n",
    "    # append everything to the main mouse stats data\n",
    "    for key in stats_add.keys():\n",
    "        data[id]['stats'][key] = stats_add[key]\n",
    "   \n",
    "for id in mouse_ids:\n",
    "    stats_exp = data[id]['stats']\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b180446-8957-4e66-9ed8-d416837c5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53864974-4849-4966-8921-122352c3f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the laser affected neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8405da-4199-4053-b901-ec0ed6ab12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_add['p_las_oomf_l_' + time_period + '_' + trace_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd4e02-0583-4b73-99fc-3e9cf1858e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### More elaborate laser stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba5a10-3d4c-45cf-821c-0db6ba66ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code = {'l': 1, 'r': -1, \n",
    "    #    'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "     #   'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "     #   'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "trace_types = ['deconv'] # HERE ONLY DECONVOLVED FOR NOW< BUT LATER ADD CA AS WELL\n",
    "           \n",
    "# number of permutations to perform; ideally 10000\n",
    "n_permut = 10000\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    '''\n",
    "    if os.path.isfile(path + id + '\\\\stats.csv'):\n",
    "        stats_mouse = pd.read_csv(path + id + '\\\\stats.csv')\n",
    "        data[id]['stats'] = stats_mouse\n",
    "        print(f'stats loaded for {id}')\n",
    "        continue\n",
    "    '''\n",
    "    data_exp = data[id] \n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    aucs = data_exp['aucs']\n",
    "    n_neu = len(data_exp['ca'])\n",
    "    n_tr = behav.shape[0] \n",
    "   # if 'stats' not in data[id].keys():\n",
    "\n",
    "    # from behav, make the masks for the selection of aucs\n",
    "    \n",
    "    # here goes nothing\n",
    "    las_l_same = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 1) & (behav['prev_reward'] == 1)\n",
    "    las_l_diff = (behav['side'] == 1) & (behav['choice'] == 1) & (behav['laser'] == 1) & (behav['prev_reward'] == -1)    \n",
    "    las_r_same = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == -1)\n",
    "    las_r_diff = (behav['side'] == -1) & (behav['choice'] == -1) & (behav['laser'] == -1) & (behav['prev_reward'] == 1)\n",
    "\n",
    "\n",
    "    \n",
    "    stats_add= {}\n",
    "\n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    "        for metric in ['p_', 'diff_']:\n",
    "            for side in ['l_', 'r_']:\n",
    "                stats_add[metric + 'las_oomf_' + side + time_period + '_' + trace_type] = []\n",
    "            \n",
    "    for trace_type, time_period in itertools.product(trace_types, time_periods):\n",
    " #   for trace_type in ['ca', 'deconv']: \n",
    "   #     for time_period in time_periods:\n",
    "        aucs_neu_list = aucs[trace_type][time_period]\n",
    "        aucs_neu_np = np.array(aucs_neu_list)\n",
    "        for n in np.arange(n_neu):\n",
    "            if n % 100 == 0:\n",
    "                print(n, trace_type, time_period)\n",
    "            # select the neuron's aucs\n",
    "            aucs_neu_n = aucs_neu_np[:,n]\n",
    "\n",
    "            # Those fucking ELABORATE oomf lasers\n",
    "            # Left oomf laser\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_l_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_l_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_oomf_l_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_oomf_l_' + time_period + '_' + trace_type].append(diff_side)\n",
    "            # Right oomf laser\n",
    "            aucs_y = [elem for i, elem in enumerate(aucs_neu_n) if las_r_diff.iloc[i]]\n",
    "            aucs_n = [elem for i, elem in enumerate(aucs_neu_n) if las_r_same.iloc[i]]\n",
    "            p_side = permutation_test(aucs_y, aucs_n, n_permut) \n",
    "            diff_side = np.mean(aucs_y) - np.mean(aucs_n) \n",
    "            stats_add['p_las_oomf_r_' + time_period + '_' + trace_type].append(p_side)\n",
    "            stats_add['diff_las_oomf_r_' + time_period + '_' + trace_type].append(diff_side)\n",
    "        \n",
    "\n",
    "\n",
    "    # append everything to the main mouse stats data\n",
    "    for key in stats_add.keys():\n",
    "        data[id]['stats'][key] = stats_add[key]\n",
    "   \n",
    "for id in mouse_ids:\n",
    "    stats_exp = data[id]['stats']\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07161a-2e0b-4e9b-b27b-1db634c34fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecf813-f734-4584-827b-05a26f66e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats for laser\n",
    "p_thr = 0.05\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "for id in mouse_ids:\n",
    "    ls = []; rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in time_periods:\n",
    "        condition = time_period + '_' + trace_type\n",
    "        neu_l = stats_side[ (stats_side['diff_las_l_' + condition] > 0) &\n",
    "                               (stats_side['p_las_l_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_r = stats_side[(stats_side['diff_las_l_' + condition] < 0) &\n",
    "                               (stats_side['p_las_l_' + condition] < p_thr)  ].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        ls.append(neu_l); rs.append(neu_r)\n",
    "    all_ls.append(ls); all_rs.append(rs); times = range(5)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_rs, times, 'g', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd19b4b-dbea-4366-909b-8230b97e7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bba85-adbc-40f7-9fdd-fecde8432ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats for laser\n",
    "p_thr = 0.05\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "all_dls = []; all_drs = []\n",
    "for id in mouse_ids:\n",
    "    ls = []; rs = []\n",
    "    dls = []; drs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in time_periods:\n",
    "        condition = time_period + '_' + trace_type\n",
    "        neu_l = stats_side[ (stats_side['diff_las_same_r_' + condition] > 0) &\n",
    "                               (stats_side['p_las_same_r_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_r = stats_side[(stats_side['diff_las_same_r_' + condition] < 0) &\n",
    "                               (stats_side['p_las_same_r_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_dl = stats_side[ (stats_side['diff_las_diff_r_' + condition] > 0) &\n",
    "                               (stats_side['p_las_diff_r_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_dr = stats_side[(stats_side['diff_las_diff_r_' + condition] < 0) &\n",
    "                               (stats_side['p_las_diff_r_' + condition] < p_thr)  ].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        ls.append(neu_l); rs.append(neu_r)\n",
    "        dls.append(neu_dl); drs.append(neu_dr)\n",
    "    all_ls.append(ls); all_rs.append(rs)\n",
    "    all_dls.append(dls); all_drs.append(drs)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_rs, times, 'k', linestyle=':', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_dls, times, 'c', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_drs, times, 'g', linestyle=':', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bae590-ff48-4d89-aa69-0adbbfd02412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersections in neurons' properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a10ec8-7b8c-48c9-a994-12f5fa0dac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the laser active neurons are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065c8b6-e2cc-4bed-8ba3-17301e7c187c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All the stats at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23fe57-87d0-4803-b6e0-a96c87fe372f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d042b1-c3a0-42a1-88c3-e1a471871da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code = {'l': 1, 'r': -1, \n",
    "        'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "        'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "        'anticip': [3000, 4000]}\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "# P values to gather\n",
    "stats_all = {'mouse': [], 'neu_n': [], 'usable': []}\n",
    "\n",
    "\n",
    "for trace_type in ['ca', 'deconv']: \n",
    "    stats_all['p_prev_pre_' + trace_type] = [] # for previous reward\n",
    "    stats_all['diff_prev_pre_' + trace_type] = [] \n",
    "    for time_period in time_periods:\n",
    "        stats_all['p_side_' + time_period + '_' + trace_type] = []\n",
    "        stats_all['diff_side_' + time_period + '_' + trace_type] = [] # difference of left - right; positive means selective for left\n",
    "        for side in ['l', 'r']:\n",
    "            stats_all['p_oomf_' + side + '_' + time_period + '_' + trace_type] = []\n",
    "            stats_all['diff_oomf_' + side + '_' + time_period + '_' + trace_type] = [] # positive means oomf, negative - anti-oomf\n",
    "            \n",
    "# number of permutations to perform; ideally 10000\n",
    "n_permut = 10000\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    \n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    print(f\":::============:::\")\n",
    "    data_exp = data[id] \n",
    "    traces = data_exp['ca'] \n",
    "    deconvolveds = data_exp['deconv'] \n",
    "    behav = data_exp['behav'] \n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    aucs = data_exp['aucs']\n",
    "    n_tr = behav.shape[0] \n",
    "    for n in np.arange(traces.shape[0]):\n",
    "        if n % 100 == 0:\n",
    "            print(n)\n",
    "        # get the traces\n",
    "        traces_both  = {'ca': traces[n][:], 'deconv': deconvolveds[n][:]}\n",
    "        stats_all['mouse'].append(id)\n",
    "        stats_all['neu_n'].append(n)\n",
    "        stats_all['usable'].append( (data_exp['fair_neurons'][n] + data_exp['good_neurons'][n]) != 0)\n",
    "        for time_period in time_periods:\n",
    "            for trace_type in ['ca', 'deconv']: \n",
    "                # select all aucs for the relevant neuron, time period trace type\n",
    "                aucs_neu_list = aucs[trace_type][time_period]\n",
    "                aucs_neu = pd.DataFrame(aucs_neu_list)\n",
    "                aucs_neu_n = aucs_neu[n]\n",
    "                # calculate stats for all conditions and fill out the table\n",
    "                # side\n",
    "                aucs_l = aucs_neu[ (behav['side']==1) & (behav['choice']==1) &  (behav['free']==0)]\n",
    "                aucs_r = aucs_neu[ (behav['side']==-1) & (behav['choice']==-1)  &  (behav['free']==0)]\n",
    "                p_side = permutation_test(aucs_l, aucs_r, n_permut) \n",
    "                diff_side = np.mean(aucs_l) - np.mean(aucs_r)         \n",
    "                stats_all['p_side_' + time_period + '_' + trace_type].append(p_side)\n",
    "                stats_all['diff_side_' + time_period + '_' + trace_type].append(diff_side)\n",
    "                # this is ugly but oh well\n",
    "                # add the pre trial activity stats based on prev reward\n",
    "                if time_period == 'pre':\n",
    "                    aucs_l = aucs_neu[ (behav['prev_reward']==1)   ]\n",
    "                    aucs_r = aucs_neu[ (behav['prev_reward']==-1)  ]\n",
    "                    p_side_prev = permutation_test(aucs_l, aucs_r, n_permut) \n",
    "                    diff_side_prev = np.mean(aucs_l) - np.mean(aucs_r)   \n",
    "                    stats_all['p_prev_pre_' + trace_type].append(p_side_prev)\n",
    "                    stats_all['diff_prev_pre_' + trace_type].append(diff_side_prev)\n",
    "                # add the oomfs for left and right\n",
    "                for side in ['l', 'r']:\n",
    "                    s = code[side]\n",
    "                    aucs_same = aucs_neu[ (behav['side']==s) & (behav['choice']==s) & (behav['prev_reward']==s) & \n",
    "                                            (behav['free']==0)]\n",
    "                    aucs_diff = aucs_neu[ (behav['side']==s) & (behav['choice']==s) & (behav['prev_reward']==-s) & \n",
    "                                            (behav['free']==0)]\n",
    "                    p_oomf = permutation_test(aucs_same, aucs_diff, n_permut) \n",
    "                    diff_oomf = np.mean(aucs_diff) - np.mean(aucs_same)   \n",
    "                    stats_all['p_oomf_' + side + '_' + time_period + '_' + trace_type].append(p_oomf)\n",
    "                    stats_all['diff_oomf_' + side + '_' + time_period + '_' + trace_type].append(diff_oomf)\n",
    "    stats_all_df = pd.DataFrame(stats_all)\n",
    "    stats_exp = stats_all_df[stats_all_df['mouse']==id]\n",
    "    data[id]['stats'] = stats_exp\n",
    "    stats_exp.to_csv(path + id + '\\\\stats.csv', index=False)\n",
    "stats_all_df = pd.DataFrame(stats_all)\n",
    "'''\n",
    "print('decided not to do all the stats at once')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24407fbf-520e-46e0-9d61-7ae70c14bc8f",
   "metadata": {},
   "source": [
    "# Main effects, saved stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58643df9-258b-4a3c-88d4-7a684ed49672",
   "metadata": {},
   "source": [
    "### Prev trial aftereffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959971df-f0de-429f-8e79-fa975241b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_permut = 2000\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    # P values to gather\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "   # if 'stats' in data_exp.keys():\n",
    "  #      continue\n",
    "    behav = data_exp['behav'].reset_index(drop=True)\n",
    "    n_tr = behav.shape[0]\n",
    "    trace_type = 'deconv'\n",
    "    aucs_trace_type = data_exp['aucs'][trace_type]\n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    neus = np.arange(neu_n);\n",
    "\n",
    "                         \n",
    "    for time_period in ['pre']:\n",
    "        aucs_period = pd.DataFrame(aucs_trace_type[time_period])\n",
    "        p_vals = []; diffs = []\n",
    "\n",
    "        for n in neus:\n",
    "            aucs_neu = aucs_period[n]\n",
    "            # Select auc subsets for conditions\n",
    "            auc_l = aucs_neu[(behav['prev_reward']==1) ]\n",
    "            auc_r = aucs_neu[(behav['prev_reward']==-1) ]\n",
    "            \n",
    "            p_val = permutation_test(auc_l, auc_r, n_permut)  \n",
    "            diff = np.mean(auc_l) - np.mean(auc_r)\n",
    "            p_vals.append(p_val)\n",
    "            diffs.append(diff)\n",
    "\n",
    "\n",
    "        data[id]['stats']['p_prev_' + time_period + '_' + trace_type] = p_vals\n",
    "        data[id]['stats']['diff_prev_' + time_period + '_' + trace_type] = diffs\n",
    "        # save them stat\n",
    "    with open(path + id + '\\\\stats\\\\stats.pkl', 'wb') as f:\n",
    "        pickle.dump(stats_side_mouse, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd89c3b-7a99-492a-9811-443994bc34e3",
   "metadata": {},
   "source": [
    "## Side preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab969b20-a540-4cd0-a95c-3b1e93a98d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cond = {'l': 1, 'r': -1, 'same': 1, 'diff': -1}\n",
    "time_periods = {'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "                'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "                'anticip': [3000, 4000]}\n",
    "n_permut = 2000\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    # P values to gather\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    \n",
    "    data_exp = data[id]\n",
    "   # if 'stats' in data_exp.keys():\n",
    "  #      continue \n",
    "    behav = data_exp['behav'].reset_index(drop=True)\n",
    "    n_tr = behav.shape[0]\n",
    "    trace_type = 'deconv'\n",
    "    aucs_trace_type = data_exp['aucs'][trace_type]\n",
    "    usable = data_exp['usable_neurons']; \n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    neus = np.arange(neu_n);\n",
    "    stats_side_mouse = pd.DataFrame({ 'neu': neus, 'usable': usable})\n",
    "                         \n",
    "    for time_period in time_periods.keys():\n",
    "        aucs_period = pd.DataFrame(aucs_trace_type[time_period])\n",
    "        p_vals = []; diffs = []\n",
    "        for n in neus:\n",
    "            aucs_neu = aucs_period[n]\n",
    "            # Select auc subsets for conditions\n",
    "            auc_conds = {}\n",
    "            for side in ['l', 'r']:\n",
    "                side_val = code_cond[side]\n",
    "                auc_conds[side] = aucs_neu[(behav['side']==side_val) & \n",
    "                                           (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "            p_val = permutation_test(auc_conds['l'], auc_conds['r'], n_permut)  \n",
    "            diff = np.mean(auc_conds['l']) - np.mean(auc_conds['r'])\n",
    "            p_vals.append(p_val)\n",
    "            diffs.append(diff)\n",
    "\n",
    "        stats_side_mouse['p_side_' + time_period+ '_' + trace_type] = p_vals\n",
    "        stats_side_mouse['diff_' + time_period+ '_' + trace_type] = diffs\n",
    "        # save them stats\n",
    "    with open(path + id + '\\\\stats\\\\stats_side.pkl', 'wb') as f:\n",
    "        pickle.dump(stats_side_mouse, f)\n",
    "    data[id]['stats'] = stats_side_mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d7b48-ef9d-487f-b5a5-6d9e6684e9e7",
   "metadata": {},
   "source": [
    "## Display based on stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71dcfc-1f48-4a37-b127-a803e4d06554",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_type = 'deconv'\n",
    "time_periods = ['post_laser']\n",
    "all_diffs_l = []\n",
    "all_diffs_r = []\n",
    "# For each mouse\n",
    "mice_ids = mouse_ids\n",
    "for id in ['os87']:\n",
    "    print(f\"::: Mouse {id}  :::\")\n",
    "    print(f\":::=============:::\")\n",
    "    data_exp = data[id]\n",
    "    traces = data_exp['ca']\n",
    "    deconvolveds = data_exp['deconv']\n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ts = frame_ts['real_ts'].tolist()\n",
    "    n_tr = behav.shape[0]\n",
    "    correct_l_ts = []\n",
    "    correct_r_ts = []\n",
    "    stats_mouse = data_exp['stats']\n",
    "    n_to_disp = 10\n",
    "    for window in time_periods:\n",
    "        print(f\":::==== {window} ====:::\")\n",
    "        condition = window + '_' + trace_type\n",
    "        pref_l = stats_mouse[stats_mouse['p_las_l_' + condition] < p_thr]\n",
    "        pref_r = stats_mouse[stats_mouse['p_las_r_' + condition] < p_thr]\n",
    "       # pref_l = stats_mouse[stats_mouse['diff_side_' + window + '_deconv'] > 0]\n",
    "      #  pref_r = stats_mouse[stats_mouse['diff_side_' + window + '_deconv'] < 0]\n",
    "        diffs_l = pref_l.nsmallest(n_to_disp, 'p_las_l_' + condition)['diff_las_l_' + condition].tolist()\n",
    "        diffs_r = pref_l.nsmallest(n_to_disp, 'p_las_r_' + condition)['diff_las_r_' + condition].tolist()\n",
    "        all_diffs_l += diffs_l; all_diffs_r += diffs_r;\n",
    "        pref_l_neu = pref_l.nsmallest(n_to_disp, 'p_las_l_' + condition)['neu_n'].tolist()\n",
    "        pref_r_neu = pref_r.nsmallest(n_to_disp, 'p_las_r_' + condition)['neu_n'].tolist()\n",
    "        \n",
    "        pref_l_neu.extend(pref_r_neu)\n",
    "\n",
    "        for n in pref_l_neu:\n",
    "            # prep the figure\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "            \n",
    "            # side\n",
    "          #  deconvolved = traces[n]\n",
    "            deconvolved = deconvolveds[n]\n",
    "            params = ['side',  'laser']\n",
    "            segms_same, segm_ts_same = get_segments(behav, deconvolved, frame_ts, params, [-1,0], span=[1000,4000])\n",
    "            segms_diff, segm_ts_diff = get_segments(behav, deconvolved, frame_ts, params, [-1,-1], span=[1000,4000])\n",
    "            segms_same_r, segm_ts_same_r = get_segments(behav, deconvolved, frame_ts, params, [1,0], span=[1000,4000])\n",
    "            segms_diff_r, segm_ts_diff_r = get_segments(behav, deconvolved, frame_ts, params, [1,1], span=[1000,4000])\n",
    "            \n",
    "            plot_aver_sem(segms_same, segm_ts_same, 'r', ghost_traces=True)\n",
    "            plot_aver_sem(segms_diff, segm_ts_diff, 'r', linestyle=':', ghost_traces=True)\n",
    "            plot_aver_sem(segms_same_r, segm_ts_same_r, 'b', ghost_traces=True)\n",
    "            plot_aver_sem(segms_diff_r, segm_ts_diff_r, 'b', linestyle=':', ghost_traces=True)\n",
    "\n",
    "            goodfont=14\n",
    "            for ax_n in [0,1]:\n",
    "                axs[ax_n].axvline(x=0, linestyle=':')\n",
    "                axs[ax_n].axvline(x=1150, linestyle=':')\n",
    "                axs[ax_n].set_xlabel('time, ms', fontsize=goodfont)\n",
    "                axs[ax_n].set_ylabel('FRE', fontsize=goodfont)\n",
    "                axs[ax_n].set_title(id + ' ' + str(n), fontsize=goodfont)\n",
    "            print(f' mouse {id}, neuron {n} ')\n",
    "            plt.tight_layout()\n",
    "            if n in to_plot_las[id]:\n",
    "                plt.savefig('D:\\\\papers_thesis\\\\figs\\\\' + 'las_effect_' + id + '_' + str(n) + '.png', dpi=300)\n",
    "        \n",
    "            #axs[0].set_yticks(np.arange(0, 3, .5), np.arange(0, 300, 50))\n",
    "\n",
    "          #  plt.ylabel('PC')\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624b891-af65-4c1c-9945-c02029657a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot_las = {'os85a':[141], 'os85b':[], 'os86a':[39, 503, 61], 'os86b':[], 'os87':[], 'os88':[], 'os89':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e89a1d-4339-4123-b3dd-e8fa8beaab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_diffs_l = [a>0 for a in all_diffs_l]\n",
    "pos_diffs_r = [a>0 for a in all_diffs_r]\n",
    "print(sum(pos_diffs_l),sum(pos_diffs_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c6a39-f58f-434e-b913-43e5a553d19a",
   "metadata": {},
   "source": [
    "### Summary of laser effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15464efa-d976-4d00-a69a-ca78e1baa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side['p_las_l_post_laser_deconv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0a128-8efb-463c-9059-b4cbec48d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side[stats_side['usable']!=0] \n",
    "all_diff_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7212269-ad63-4e36-aa09-6f7cc4fa17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_ids = ['os85b', 'os86a', 'os86b', 'os87']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c911a9-7776-4649-a50d-cb0d89cfe50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 2]})\n",
    "width_bar = 0.5\n",
    "labels_2 = ['Left laser', 'Right laser']\n",
    "means_2 = [125, 64] \n",
    "std_1 = [42.2, 36]\n",
    "# Second subplot\n",
    "bars = axes[0].bar(labels_2, means_2,  yerr=std_1, capsize=10, color=['blue', 'red'], width=width_bar)\n",
    "\n",
    "#axes[0].set_title('A', loc='left')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=14)\n",
    "axes[0].set_xlabel('Conditions', fontsize=14)\n",
    "\n",
    "# First subplot\n",
    "labels_1 = ['Left Excit', 'Left Inhib', 'Right Excit', 'Right Inhib']\n",
    "means_1 = [77, 48, 49, 15]\n",
    "bars2 = axes[1].bar(labels_1, means_1, capsize=10, color=['blue', 'blue', 'red', 'red'], width=width_bar)\n",
    "axes[1].set_title('B', loc='left')\n",
    "\n",
    "axes[1].set_xlabel('Conditions', fontsize=14)\n",
    "for ax_n in [0,1]:\n",
    "    axes[ax_n].set_ylabel('Number of neurons', fontsize=14)\n",
    "   # axes[ax_n].set_ylim([0, 1])\n",
    "  #  axes[ax_n].set_xticks(fontsize=12)\n",
    "  #  axes[ax_n].set_yticks(fontsize=12)\n",
    "    axes[ax_n].spines['right'].set_visible(False)\n",
    "    axes[ax_n].spines['top'].set_visible(False)\n",
    "axes[0].set_xticklabels(labels_2, fontsize=14)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\papers_thesis\\\\figs\\\\' + 'laser_accuracy_prev.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b339c2-1510-4c29-af6f-228c3a165da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 2]})\n",
    "width_bar = 0.5\n",
    "labels_2 = ['Left laser', 'Right laser']\n",
    "means_2 = [125, 64] \n",
    "std_1 = [53.2\n",
    "# Second subplot\n",
    "bars = axes[0].bar(labels_2, means_2,  yerr=std_1 capsize=10, color=['blue', 'red'], width=width_bar)\n",
    "\n",
    "axes[0].set_title('A', loc='left')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Conditions')\n",
    "\n",
    "# First subplot\n",
    "labels_1 = ['Left Excit', 'Left Inhib', 'Right Excit', 'Right Inhib']\n",
    "means_1 = [77, 48, 49, 15]\n",
    "bars2 = axes[1].bar(labels_1, means_1, capsize=10, color=['blue', 'blue', 'red', 'red'], width=width_bar)\n",
    "axes[1].set_title('B', loc='left')\n",
    "\n",
    "axes[1].set_xlabel('Conditions')\n",
    "for ax_n in [0,1]:\n",
    "    axes[ax_n].set_ylabel('Number of neurons')\n",
    "   # axes[ax_n].set_ylim([0, 1])\n",
    "    axes[ax_n].spines['right'].set_visible(False)\n",
    "    axes[ax_n].spines['top'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\papers_thesis\\\\figs\\\\' + 'laser_accuracy_prev.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0a452-9e4d-4b50-80f3-a0480fd2fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_diff_ls = [a>0 for a in all_diff_ls]\n",
    "pos_diff_rs = [a>0 for a in all_diff_rs]\n",
    "print(sum(pos_diff_ls), 'of', len(pos_diff_ls), 'left laser positive')\n",
    "print(sum(pos_diff_rs), 'of', len(pos_diff_rs), 'right laser positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d9757-a2bb-4fdf-be48-fab2d653b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "17/(89+36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95011c-a636-40b9-9ba4-cdcfa1686164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476d776-4868-463e-8f3e-7c06b3ecae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []; rs = []\n",
    "for id in mouse_ids:\n",
    "    molas = mouse_las[id]\n",
    "    if id == 'os87':\n",
    "        ls.append(25); rs.append(len(molas['r']))\n",
    "    else:\n",
    "        ls.append(len(molas['l'])); rs.append(len(molas['r']))\n",
    "    print(id, 'l:', len(molas['l']), 'r:', len(molas['r']))\n",
    "print(np.std(ls), np.mean(ls), np.std(rs), np.mean(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e0f6c-192b-421d-a070-0b8199ff39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.05\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "all_diff_ls = []; all_diff_rs = []\n",
    "mouse_las = {}\n",
    "all_side_guys = 0; all_oomf_guys = 0; all_prew_guys = 0\n",
    "for id in mouse_ids:\n",
    "    side_guys = []; oomf_guys = []; prew_guys = []\n",
    "    ls = []; rs = []\n",
    "    mouse_las_l = []\n",
    "    mouse_las_r = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_og = data[id]['stats']\n",
    "    stats_side = stats_og[stats_og['usable']!=0]\n",
    "    for time_period in ['resp', 'resp2']:\n",
    "        condition = time_period + '_' + trace_type\n",
    "        p_neu_l = stats_side['p_las_l_' + condition]\n",
    "        p_neu_r = stats_side['p_las_r_' + condition]\n",
    "        sign_l, adjusted_p_values = fdr_correction(p_neu_l, alpha=p_thr)\n",
    "        sign_r, adjusted_p_values = fdr_correction(p_neu_r, alpha=p_thr)\n",
    "        neu_n_all =  stats_side['neu_n']\n",
    "        neu_n_l = neu_n_all[sign_l].tolist()\n",
    "        neu_n_r = neu_n_all[sign_r].tolist()\n",
    "        stats_l = stats_og.iloc[neu_n_l]\n",
    "        stats_r = stats_og.iloc[neu_n_r]\n",
    "        if stats_l.shape[0] != 0:\n",
    "            for col in stats_l.keys():\n",
    "                if (col[0] == 'p') & (col[-1] == 'v') & ('las' not in col):\n",
    "                    sign_vals = stats_l[stats_l[col]<0.01]\n",
    "                    if sign_vals.shape[0] != 0:\n",
    "                     #   print(col, sign_vals.shape[0], \n",
    "                         #     sign_vals['neu_n'].tolist(), sign_vals[col].tolist())\n",
    "                        if 'side' in col:\n",
    "                            side_guys += sign_vals['neu_n'].tolist()\n",
    "                        elif 'nomf' in col:\n",
    "                            oomf_guys += sign_vals['neu_n'].tolist()\n",
    "                        elif 'prew' in col: \n",
    "                            prew_guys += sign_vals['neu_n'].tolist()\n",
    "            \n",
    "        \n",
    "        p_l = stats_side[stats_side['p_las_l_' + condition]<p_thr].shape[0]\n",
    "        p_r = stats_side[stats_side['p_las_r_' + condition]<p_thr].shape[0]\n",
    "        diffs_l = stats_side['diff_las_l_' + condition][sign_l].tolist()\n",
    "        diffs_r = stats_side['diff_las_r_' + condition][sign_r].tolist()\n",
    "        ls+= diffs_l; rs+= diffs_r; \n",
    "        all_diff_ls += diffs_l; all_diff_rs += diffs_r\n",
    "      #  print(sum(sign_l), sum(sign_r))\n",
    "    side_guys = list(set(side_guys)); all_side_guys += len(side_guys)\n",
    "    oomf_guys = list(set(oomf_guys)); all_oomf_guys += len(oomf_guys)\n",
    "    prew_guys = list(set(prew_guys)); all_prew_guys += len(prew_guys)\n",
    "    print(side_guys, oomf_guys, prew_guys)\n",
    "    mouse_las[id] = {'l': ls, 'r': rs}\n",
    "        #print(p_l, p_r)\n",
    "        #stats_side[sign_l]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "      #  ls.append(neu_l); rs.append(neu_r)\n",
    "  #  all_ls.append(ls); all_rs.append(rs); times = range(5)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "#plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "#                       span = [0,5], sampling_rate = 1)   \n",
    "#plot_aver_sem_canon(all_rs, times, 'r', ghost_traces=True,\n",
    " #                      span = [0,5], sampling_rate = 1)   \n",
    "#axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])    \n",
    "#plt.show()\n",
    "print(all_side_guys, all_oomf_guys,all_prew_guys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eafc0f-e099-43c1-8cd7-39db4d220d63",
   "metadata": {},
   "source": [
    "## Summary oomf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713f0e5-3fcc-460b-b05d-e6c131b58eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### # DIFFERENT WAY\n",
    "p_thr = 0.2\n",
    "oomf_neus_all = {'oomf': {'l': [], 'r':[]}, 'nomf': {'l': [], 'r':[]}}\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "all_nls = []; all_nrs = []\n",
    "#fig, axs = plt.subplots(1, len(mouse_ids), figsize=(15, 2))\n",
    "plot_n = 0\n",
    "times = [np.arange(5)]*len(mouse_ids)\n",
    "oomfs_l = []\n",
    "oomfs_r = []\n",
    "all_o = 0; all_n = 0\n",
    "all_os = []; all_ns = []\n",
    "k=1\n",
    "time_periods = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "oomph = '_oomf_'\n",
    "time_periods = time_periods[1:]\n",
    "for id in mouse_ids:\n",
    "    ls = 0; rs = 0\n",
    "    nls = 0; nrs = 0\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    n_neus = stats_side[stats_side['usable']!=0].shape[0]\n",
    "    stats_side = stats_side[ stats_side['usable']!=0 ]\n",
    "                       #  & (stats_side['p_prew_pre_' + trace_type] > p_thr)\n",
    "                       #  & (stats_side['p_prew_tone_' + trace_type] > p_thr*k)\n",
    "                        # & (stats_side['p_oomf_l_pre_' + trace_type] > p_thr*k)\n",
    "                       #  & (stats_side['p_oomf_r_pre_' + trace_type] > p_thr*k)\n",
    "   #                         ]\n",
    "    for time_period in time_periods:\n",
    "        condition = time_period + '_' + trace_type\n",
    "        p_oomf_l_all = stats_side['p' + oomph + 'l_' + condition] \n",
    "        p_oomf_r_all = stats_side['p' + oomph + 'r_' + condition] \n",
    "        signif_l, p_vals_adj_l = fdr_correction(p_oomf_l_all, alpha=p_thr)\n",
    "        signif_r, p_vals_adj_r = fdr_correction(p_oomf_r_all, alpha=p_thr)\n",
    "        neu_ol = stats_side[ (stats_side['diff' + oomph + 'l_' + condition] > 0) & signif_l ].shape[0]\n",
    "        neu_or = stats_side[ (stats_side['diff' + oomph + 'r_' + condition] > 0) & signif_r ].shape[0]\n",
    "        neu_nl = stats_side[ (stats_side['diff' + oomph + 'l_' + condition] < 0) & signif_l ].shape[0]\n",
    "        neu_nr = stats_side[ (stats_side['diff' + oomph + 'r_' + condition] < 0) & signif_r ].shape[0]\n",
    "        all_os.append(neu_ol); all_os.append(neu_or); \n",
    "        all_ns.append(neu_nl); all_ns.append(neu_nr); \n",
    "        all_o += neu_ol + neu_or; all_n += neu_nl + neu_nr;\n",
    "        print((neu_ol + neu_or), 'vs', (neu_nl + neu_nr))\n",
    "        ls += neu_ol; rs += neu_or; \n",
    "        nls += neu_nl; nrs += neu_nr; \n",
    "\n",
    "    oomf_neus_all['oomf']['l'].append(ls)\n",
    "    oomf_neus_all['oomf']['r'].append(rs)\n",
    "    oomf_neus_all['nomf']['l'].append(nls)\n",
    "    oomf_neus_all['nomf']['r'].append(nrs)\n",
    "\n",
    "      \n",
    "oomf_neus_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f16dd7-76e6-4ea3-835f-24b9512aeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oomf_neus_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31b485-7b84-428c-a884-e6e4d89b8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side[stats_side['usable']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191d70a-03a1-4aa9-84e1-7eb001f015e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.05\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "for id in mouse_ids:\n",
    "    ls = []; rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in time_periods:\n",
    "        condition = time_period + '_' + trace_type\n",
    "        neu_l = stats_side[ (stats_side['diff_' + condition] > 0) &\n",
    "                               (stats_side['p_side_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_r = stats_side[(stats_side['diff_' + condition] < 0) &\n",
    "                               (stats_side['p_side_' + condition] < p_thr)  ].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        ls.append(neu_l); rs.append(neu_r)\n",
    "    all_ls.append(ls); all_rs.append(rs); times = range(5)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_rs, times, 'r', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ccabc-fd81-4094-ab8e-48cf41c67d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laser effects\n",
    "code_cond = {'l': 1, 'r': -1, 'same': 1, 'diff': -1}\n",
    "time_periods = {'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "                'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "                'anticip': [3000, 4000]}\n",
    "n_permut = 2000\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    # P values to gather\n",
    "    stats_side_mouse = {'neu_n': [], 'usable': []}\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    \n",
    "    data_exp = data[id]\n",
    "   # if 'stats' in data_exp.keys():\n",
    "  #      continue\n",
    "    behav = data_exp['behav'].reset_index(drop=True)\n",
    "    n_tr = behav.shape[0]\n",
    "    trace_type = 'deconv'\n",
    "    aucs_trace_type = data_exp['aucs'][trace_type]\n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    neus = np.arange(neu_n);\n",
    "\n",
    "                         \n",
    "    for time_period in time_periods.keys():\n",
    "        aucs_period = pd.DataFrame(aucs_trace_type[time_period])\n",
    "        p_vals = {'l':[],'r':[]}; diffs = {'l':[],'r':[]}\n",
    "\n",
    "        for n in neus:\n",
    "            aucs_neu = aucs_period[n]\n",
    "            # Select auc subsets for conditions\n",
    "            auc_conds = {}\n",
    "            for side in ['l', 'r']:\n",
    "                side_val = code_cond[side]\n",
    "                auc_las = aucs_neu[(behav['side']==side_val) & \n",
    "                                           (behav['missed'] == 0) & (behav['laser']==side_val) ]\n",
    "                auc_nolas = aucs_neu[(behav['side']==side_val) & \n",
    "                                           (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "                \n",
    "                p_val = permutation_test(auc_las, auc_nolas, n_permut)  \n",
    "                diff = np.mean(auc_las) - np.mean(auc_nolas)\n",
    "                p_vals[side].append(p_val)\n",
    "                diffs[side].append(diff)\n",
    "        for side in ['l', 'r']:\n",
    "\n",
    "            data[id]['stats']['p_las_' + side + '_' + time_period + '_' + trace_type] = p_vals[side]\n",
    "            data[id]['stats']['diff_las_' + side + '_' + time_period + '_' + trace_type] = diffs[side]\n",
    "        # save them stats\n",
    "    with open(path + id + '\\\\stats\\\\stats.pkl', 'wb') as f:\n",
    "        pickle.dump(stats_side_mouse, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf0f13-6d98-45aa-8078-375908e9a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.01\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "all_dls = []; all_drs = []\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "for id in mouse_ids:\n",
    "    ls = []; rs = []\n",
    "    dls = []; drs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in time_periods:\n",
    "        condition =  time_period + '_' + trace_type\n",
    "        neu_l = stats_side[ \n",
    "                               (stats_side['p_las_same_l_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_r = stats_side[\n",
    "                               (stats_side['p_las_same_r_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_dl = stats_side[ \n",
    "                               (stats_side['p_las_diff_l_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_dr = stats_side[\n",
    "                               (stats_side['p_las_diff_r_' + condition] < p_thr)  ].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        ls.append(neu_l); rs.append(neu_r)\n",
    "        dls.append(neu_dl); drs.append(neu_dr)\n",
    "    all_ls.append(ls); all_rs.append(rs); times = range(5)\n",
    "    all_dls.append(dls); all_drs.append(drs); times = range(5)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_rs, times, 'r', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_dls, times, 'c', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_drs, times, 'm', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11976cf-5280-420f-a317-f50213325e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.05\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_ls = []; all_rs = []\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "for id in mouse_ids:\n",
    "    ls = []; rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in time_periods:\n",
    "        condition =  time_period + '_' + trace_type\n",
    "        neu_l = stats_side[ \n",
    "                               (stats_side['p_las_same_l_' + condition] < p_thr)  ].shape[0]\n",
    "        neu_r = stats_side[\n",
    "                               (stats_side['p_las_same_r_' + condition] < p_thr)  ].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        ls.append(neu_l); rs.append(neu_r)\n",
    "    all_ls.append(ls); all_rs.append(rs); times = range(5)\n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_ls, times, 'b', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_rs, times, 'r', ghost_traces=True,\n",
    "                       span = [0,5], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62b9cd-be07-497b-8780-0a2d10d1f172",
   "metadata": {},
   "source": [
    "## Oomph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7fe24-0990-4254-b4e2-1d5f624c8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laser effects\n",
    "code_cond = {'l': 1, 'r': -1, 'same': 1, 'diff': -1}\n",
    "time_periods = {'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "                'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "                'anticip': [3000, 4000]}\n",
    "n_permut = 2000\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    # P values to gather\n",
    "    print(f\"::: Mouse  {id} :::\")  \n",
    "    data_exp = data[id]\n",
    "   # if 'stats' in data_exp.keys():\n",
    "  #      continue\n",
    "    behav = data_exp['behav'].reset_index(drop=True)\n",
    "    n_tr = behav.shape[0]\n",
    "    trace_type = 'deconv'\n",
    "    aucs_trace_type = data_exp['aucs'][trace_type]\n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    neus = np.arange(neu_n);\n",
    "                         \n",
    "    for time_period in time_periods.keys():\n",
    "        aucs_period = pd.DataFrame(aucs_trace_type[time_period])\n",
    "        p_vals = {'l':[],'r':[]}; diffs = {'l':[],'r':[]}\n",
    "\n",
    "        for n in neus:\n",
    "            aucs_neu = aucs_period[n]\n",
    "            # Select auc subsets for conditions\n",
    "            auc_conds = {}\n",
    "            for side in ['l', 'r']:\n",
    "                side_val = code_cond[side]\n",
    "                auc_same = aucs_neu[(behav['side']==side_val) & (behav['choice']==side_val) & \n",
    "                                    (behav['prev_reward']==side_val) &\n",
    "                                    (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "                auc_diff = aucs_neu[(behav['side']==side_val) & (behav['choice']==side_val) & \n",
    "                                    (behav['prev_reward']== -side_val) &\n",
    "                                    (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "                \n",
    "                p_val = permutation_test(auc_same, auc_diff, n_permut)  \n",
    "                diff = np.mean(auc_diff) - np.mean(auc_same)\n",
    "                p_vals[side].append(p_val)\n",
    "                diffs[side].append(diff)\n",
    "        for side in ['l', 'r']:\n",
    "            data[id]['stats']['p_oomf_' + side + '_' + time_period + '_' + trace_type] = p_vals[side]\n",
    "            data[id]['stats']['diff_oomf_' + side + '_' + time_period + '_' + trace_type] = diffs[side]\n",
    "        # save them stats\n",
    "    with open(path + id + '\\\\stats\\\\stats_oomph.pkl', 'wb') as f:\n",
    "        pickle.dump(stats_side_mouse, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b942d-4336-4c51-a42d-a5a3d2d73d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laser effects\n",
    "code_cond = {'l': 1, 'r': -1, 'same': 1, 'diff': -1}\n",
    "time_periods = {'pre': [-1000, 0], 'tone': [0, 1000], \n",
    "                'resp': [1000, 2000], 'resp2': [2000, 3000], \n",
    "                'anticip': [3000, 4000]}\n",
    "n_permut = 2000\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    # P values to gather\n",
    "    stats_side_mouse = {'neu_n': [], 'usable': []}\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    \n",
    "    data_exp = data[id]\n",
    "   # if 'stats' in data_exp.keys():\n",
    "  #      continue\n",
    "    behav = data_exp['behav'].reset_index(drop=True)\n",
    "    n_tr = behav.shape[0]\n",
    "    trace_type = 'ca'\n",
    "    aucs_trace_type = data_exp['aucs'][trace_type]\n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    neus = np.arange(neu_n);\n",
    "                         \n",
    "    for time_period in time_periods.keys():\n",
    "        aucs_period = pd.DataFrame(aucs_trace_type[time_period])\n",
    "        p_vals = {'l':[],'r':[]}; diffs = {'l':[],'r':[]}\n",
    "\n",
    "        for n in neus:\n",
    "            aucs_neu = aucs_period[n]\n",
    "            # Select auc subsets for conditions\n",
    "            auc_conds = {}\n",
    "            for side in ['l', 'r']:\n",
    "                side_val = code_cond[side]\n",
    "                auc_same = aucs_neu[(behav['side']==side_val) & (behav['choice']==side_val) & \n",
    "                                    (behav['prev_reward']==side_val) &\n",
    "                                    (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "                auc_diff = aucs_neu[(behav['side']==side_val) & (behav['choice']==side_val) & \n",
    "                                    (behav['prev_reward']== -side_val) &\n",
    "                                    (behav['missed'] == 0) & (behav['laser']==0) ]\n",
    "                \n",
    "                p_val = permutation_test(auc_same, auc_diff, n_permut)  \n",
    "                diff = np.mean(auc_diff) - np.mean(auc_same)\n",
    "                p_vals[side].append(p_val)\n",
    "                diffs[side].append(diff)\n",
    "        for side in ['l', 'r']:\n",
    "            data[id]['stats']['p_oomf_' + side + '_' + time_period + '_' + trace_type] = p_vals[side]\n",
    "            data[id]['stats']['diff_oomf_' + side + '_' + time_period + '_' + trace_type] = diffs[side]\n",
    "        # save them stats\n",
    "    with open(path + id + '\\\\stats\\\\stats_oomph.pkl', 'wb') as f:\n",
    "        pickle.dump(stats_side_mouse, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fd301-f700-4f7a-ba95-0659e6871959",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f8306-a476-4062-a2b7-54a4a6990dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# summary stats\n",
    "p_thr = 0.05\n",
    "tps = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "trace_type = 'deconv'\n",
    "all_oomf_ls = []; all_oomf_rs = []\n",
    "all_nomf_ls = []; all_nomf_rs = []\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "for id in mouse_ids:\n",
    "    oomf_ls = []; oomf_rs = []\n",
    "    nomf_ls = []; nomf_rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    for time_period in tps[1:]:\n",
    "        oomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr) ].shape[0]\n",
    "        nomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr)].shape[0]\n",
    "        oomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) & \n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr)].shape[0]\n",
    "        nomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr)].shape[0]\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        oomf_ls.append(oomf_l); oomf_rs.append(oomf_r)\n",
    "        nomf_ls.append(nomf_l); nomf_rs.append(nomf_r)\n",
    "    all_oomf_ls.append(oomf_ls); all_oomf_rs.append(oomf_rs); \n",
    "    all_nomf_ls.append(nomf_ls); all_nomf_rs.append(nomf_rs); \n",
    "    \n",
    "  #  axs.plot(range(5), ls, 'b')\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plot_aver_sem_canon(all_oomf_ls, times, 'c', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "\n",
    "plot_aver_sem_canon(all_oomf_rs, times, 'm', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_ls, times, 'g', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_rs, times, 'orange', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "                     \n",
    "axs[0].set_xticks(range(4), ['tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288bc941-c00d-4f24-bc4c-da9d162cd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3ccbe-8aa1-4c9f-bc47-c8b382614fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.025\n",
    "\n",
    "# summary stats\n",
    "p_thr = 0.01\n",
    "tps = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "\n",
    "trace_type = 'deconv'\n",
    "all_oomf_ls = []; all_oomf_rs = []\n",
    "all_nomf_ls = []; all_nomf_rs = []\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "fig, axs = plt.subplots(1, len(mouse_ids), figsize=(15, 2))\n",
    "plot_n = 0\n",
    "for id in mouse_ids:\n",
    "    oomf_ls = []; oomf_rs = []\n",
    "    nomf_ls = []; nomf_rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    neu_n = stats_side.shape[0]\n",
    "    for time_period in tps[1:]:\n",
    "        oomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr)  &\n",
    "                             (stats_side['p_prew_tone_deconv'] > p_thr)].shape[0] / neu_n\n",
    "        nomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr) &\n",
    "                             (stats_side['p_prew_tone_deconv'] > p_thr)].shape[0] / neu_n\n",
    "        oomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) & \n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr) &\n",
    "                             (stats_side['p_prew_tone_deconv'] > p_thr)].shape[0] / neu_n\n",
    "        nomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['usable']==1) &\n",
    "                             (stats_side['p_prew_pre_deconv'] > p_thr) &\n",
    "                             (stats_side['p_prew_tone_deconv'] > p_thr)].shape[0] / neu_n\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        oomf_ls.append(oomf_l); oomf_rs.append(oomf_r)\n",
    "        nomf_ls.append(nomf_l); nomf_rs.append(nomf_r)\n",
    "    all_oomf_ls.append(oomf_ls); all_oomf_rs.append(oomf_rs); \n",
    "    all_nomf_ls.append(nomf_ls); all_nomf_rs.append(nomf_rs); \n",
    "    \n",
    "    axs[plot_n].plot(range(4), oomf_ls, 'c')\n",
    "    axs[plot_n].plot(range(4), oomf_rs, 'm')\n",
    "    axs[plot_n].plot(range(4), nomf_ls, 'g')\n",
    "    axs[plot_n].plot(range(4), nomf_rs, 'darkorange')\n",
    "    axs[plot_n].set_xticks(range(4), ['tone', 'resp', 'resp2', 'anticip'])\n",
    "    \n",
    "    plot_n += 1\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "plot_aver_sem_canon(all_oomf_ls, times, 'c', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "\n",
    "plot_aver_sem_canon(all_oomf_rs, times, 'm', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_ls, times, 'g', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_rs, times, 'orange', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(4), ['tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dc759-8f69-4956-8d82-56b743eac1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "p_thr = 0.025\n",
    "\n",
    "# summary stats\n",
    "p_thr = 0.02\n",
    "tps = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "\n",
    "trace_type = 'ca'\n",
    "all_oomf_ls = []; all_oomf_rs = []\n",
    "all_nomf_ls = []; all_nomf_rs = []\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "fig, axs = plt.subplots(1, len(mouse_ids), figsize=(15, 2))\n",
    "plot_n = 0\n",
    "for id in mouse_ids:\n",
    "    oomf_ls = []; oomf_rs = []\n",
    "    nomf_ls = []; nomf_rs = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    neu_n = data_exp['ca'].shape[0]\n",
    "    for time_period in tps[1:]:\n",
    "        oomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "        (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > stats_side['diff_oomf_l_pre_' + trace_type]) &\n",
    "                             (stats_side['p_side_pre_deconv'] > p_thr) ].shape[0] / neu_n\n",
    "        nomf_l = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "        (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < stats_side['diff_oomf_l_pre_' + trace_type]) &\n",
    "                             (stats_side['p_side_pre_deconv'] > p_thr)].shape[0] / neu_n\n",
    "        oomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) & \n",
    "        (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > stats_side['diff_oomf_r_pre_' + trace_type]) &\n",
    "                             (stats_side['p_side_pre_deconv'] > p_thr)].shape[0] / neu_n\n",
    "        nomf_r = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) &\n",
    "        (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < stats_side['diff_oomf_r_pre_' + trace_type]) &\n",
    "                             (stats_side['p_side_pre_deconv'] > p_thr)].shape[0] / neu_n\n",
    "      #  print(f'{time_period} L: {neu_l}, R: {neu_r}')\n",
    "        oomf_ls.append(oomf_l); oomf_rs.append(oomf_r)\n",
    "        nomf_ls.append(nomf_l); nomf_rs.append(nomf_r)\n",
    "    all_oomf_ls.append(oomf_ls); all_oomf_rs.append(oomf_rs); \n",
    "    all_nomf_ls.append(nomf_ls); all_nomf_rs.append(nomf_rs); \n",
    "    \n",
    "    axs[plot_n].plot(range(4), oomf_ls, 'c')\n",
    "    axs[plot_n].plot(range(4), oomf_rs, 'm')\n",
    "    axs[plot_n].plot(range(4), nomf_ls, 'g')\n",
    "    axs[plot_n].plot(range(4), nomf_rs, 'darkorange')\n",
    "    axs[plot_n].set_xticks(range(4), ['tone', 'resp', 'resp2', 'anticip'])\n",
    "    \n",
    "    plot_n += 1\n",
    "   # axs.plot(range(5), rs, 'r')\n",
    "  #  axs.set_xticks(range(5), ['pre', 'tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "plot_aver_sem_canon(all_oomf_ls, times, 'c', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "\n",
    "plot_aver_sem_canon(all_oomf_rs, times, 'm', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_ls, times, 'g', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "plot_aver_sem_canon(all_nomf_rs, times, 'orange', ghost_traces=True,\n",
    "                       span = [0,4], sampling_rate = 1)   \n",
    "axs[0].set_xticks(range(4), ['tone', 'resp', 'resp2', 'anticip'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1142b-a312-419a-a801-a087a4378f82",
   "metadata": {},
   "source": [
    "### Plot the oomfs and nomfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328f777-03bd-4c89-a287-557ec5c8f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summary stats\n",
    "p_thr = 0.01\n",
    "tps = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "trace_type = 'deconv'\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "plot_n = 0\n",
    "for id in mouse_ids:\n",
    "    oomf_l_neus = []; oomf_r_neus = []\n",
    "    nomf_l_neus = []; nomf_r_neus = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    frame_ts = data[id]['frame_ts']\n",
    "    behav =  data[id]['behav']\n",
    "    for time_period in tps[1:]:\n",
    "        oomf_l_neu = stats_side[  (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr) \n",
    "        ]['neu'].to_numpy().tolist()\n",
    "        nomf_l_neu = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu']\n",
    "        oomf_r_neu = stats_side[ # (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) & \n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu'].to_numpy().tolist()\n",
    "        nomf_r_neu = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu']\n",
    "        oomf_l_neus.extend(oomf_l_neu); oomf_r_neus.extend(oomf_r_neu)\n",
    "        nomf_l_neus.extend(nomf_l_neu); nomf_r_neus.extend(nomf_r_neu)\n",
    "    oomf_l_neus = list(set(oomf_l_neus)); oomf_r_neus = list(set(oomf_r_neus))\n",
    "    nomf_l_neus = list(set(nomf_l_neus)); nomf_r_neus = list(set(nomf_r_neus))\n",
    "    print(f\"====================\")\n",
    "    print(f\"::: OOMF NEURONS :::\")\n",
    "    for n in oomf_r_neus:\n",
    "        if data[id]['usable_neurons'][n] == False:\n",
    "            continue\n",
    "       # trace = data[id]['smoothies'][n]\n",
    "        trace = data[id]['deconv'][n]\n",
    "        # prep the figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        \n",
    "        colors = {'same': {1:'b', -1:'r'},\n",
    "                  'diff': {1:'c', -1:'m'} }\n",
    "        for side in [1]:\n",
    "            params = ['side', 'choice', 'prev_side', 'missed']\n",
    "            ts_same = get_behav_ts(behav, params, [side, side, side, 0])\n",
    "            ts_diff = get_behav_ts(behav, params, [side, side, -side, 0])\n",
    "\n",
    "            segms_same, times_same = get_segments_canon(trace, ts_same, frame_ts)\n",
    "            segms_diff, times_diff = get_segments_canon(trace, ts_diff, frame_ts)\n",
    "\n",
    "            plot_aver_sem_canon(segms_same, times_same, colors['same'][side], ghost_traces=True)\n",
    "            plot_aver_sem_canon(segms_diff, times_diff, colors['diff'][side], ghost_traces=True)\n",
    "            '''\n",
    "\n",
    "            ts_same = get_behav_ts(behav, params, [side, side, side, 0, side])\n",
    "            ts_diff = get_behav_ts(behav, params, [side, side, -side, 0, side])\n",
    "\n",
    "            segms_same, times_same = get_segments_canon(trace, ts_same, frame_ts)\n",
    "            segms_diff, times_diff = get_segments_canon(trace, ts_diff, frame_ts)\n",
    "\n",
    "            plot_aver_sem_canon(segms_same, times_same, colors['same'][side], ghost_traces=True, linestyle=':')\n",
    "            plot_aver_sem_canon(segms_diff, times_diff, colors['diff'][side], ghost_traces=True, linestyle=':')\n",
    "            '''\n",
    "\n",
    "            for ax_n in [0,1]:\n",
    "                axs[ax_n].axvline(x=0)\n",
    "                axs[ax_n].axvline(x=955, linestyle=':')\n",
    "                axs[ax_n].axvline(x=1150)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da578f-c7eb-47e5-ab4b-636f7f7be73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summary stats\n",
    "p_thr = 0.01\n",
    "tps = ['pre', 'tone', 'resp', 'resp2', 'anticip']\n",
    "trace_type = 'deconv'\n",
    "times = [range(4)]*len(mouse_ids)\n",
    "plot_n = 0\n",
    "for id in mouse_ids:\n",
    "    oomf_l_neus = []; oomf_r_neus = []\n",
    "    nomf_l_neus = []; nomf_r_neus = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    stats_side = data[id]['stats']\n",
    "    frame_ts = data[id]['frame_ts']\n",
    "    behav =  data[id]['behav']\n",
    "    for time_period in tps[1:]:\n",
    "        oomf_l_neu = stats_side[ # (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr) \n",
    "        ]['neu'].to_numpy().tolist()\n",
    "        nomf_l_neu = stats_side[ (stats_side['diff_oomf_l_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_l_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu']\n",
    "        oomf_r_neu = stats_side[ # (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] > 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) & \n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu'].to_numpy().tolist()\n",
    "        nomf_r_neu = stats_side[ (stats_side['diff_oomf_r_' + time_period + '_' + trace_type] < 0) &\n",
    "                             (stats_side['p_oomf_r_' + time_period + '_' + trace_type] < p_thr) &\n",
    "                             (stats_side['p_side_pre_' + trace_type] > p_thr)]['neu']\n",
    "        oomf_l_neus.extend(oomf_l_neu); oomf_r_neus.extend(oomf_r_neu)\n",
    "        nomf_l_neus.extend(nomf_l_neu); nomf_r_neus.extend(nomf_r_neu)\n",
    "    oomf_l_neus = list(set(oomf_l_neus)); oomf_r_neus = list(set(oomf_r_neus))\n",
    "    nomf_l_neus = list(set(nomf_l_neus)); nomf_r_neus = list(set(nomf_r_neus))\n",
    "    print(f\"====================\")\n",
    "    print(f\"::: OOMF NEURONS :::\")\n",
    "    for n in oomf_r_neus:\n",
    "        if data[id]['usable_neurons'][n] == False:\n",
    "            continue\n",
    "        trace = data[id]['ca'][n]\n",
    "        # prep the figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        \n",
    "        colors = {'same': {1:'b', -1:'r'},\n",
    "                  'diff': {1:'c', -1:'m'} }\n",
    "        for side in [-1]:\n",
    "            params = ['side', 'choice', 'prev_side', 'missed', 'laser']\n",
    "            ts_same = get_behav_ts(behav, params, [side, side, side, 0, 0])\n",
    "            ts_diff = get_behav_ts(behav, params, [side, side, -side, 0, 0])\n",
    "\n",
    "            segms_same, times_same = get_segments_canon(trace, ts_same, frame_ts)\n",
    "            segms_diff, times_diff = get_segments_canon(trace, ts_diff, frame_ts)\n",
    "\n",
    "            plot_aver_sem_canon(segms_same, times_same, colors['same'][side], ghost_traces=True)\n",
    "            plot_aver_sem_canon(segms_diff, times_diff, colors['diff'][side], ghost_traces=True)\n",
    "\n",
    "            for ax_n in [0,1]:\n",
    "                axs[ax_n].axvline(x=0)\n",
    "                axs[ax_n].axvline(x=955, linestyle=':')\n",
    "                axs[ax_n].axvline(x=1150)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569818a-3c7d-4375-8b64-06cb447a02c2",
   "metadata": {},
   "source": [
    "## YEAH let's do SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfd353-0cfa-4823-bd3a-0cf2b7192b6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Population activity analysis\n",
    "* Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097a7cb-c02d-4cd7-ae87-d391f6c2716e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ec8a8-d753-440c-a095-c8c2a8b34b28",
   "metadata": {},
   "source": [
    "## Run PCA for all mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2f74a-cdf8-479a-bc52-790da7c364e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_n = 16\n",
    "trace_type = 'ca'\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    usable = [ data_exp['good_neurons'][n]==1 or data_exp['fair_neurons'][n]==1 for n in np.arange(len(data_exp['good_neurons']))]\n",
    "    traces = data_exp[trace_type]\n",
    "    traces = traces[np.array(usable)]\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces = traces.T\n",
    "    # Perform PCA on the reshaped data\n",
    "    pca = PCA(n_components=pca_n)\n",
    "    pca.fit(traces)\n",
    "\n",
    "    # Get the variance explained by each component\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    # To see the cumulative explained variance:\n",
    "    cumulative_explained_variance = explained_variance.cumsum()\n",
    "    pca_result = pca.fit_transform(traces)\n",
    "    print(\"Variance explained by each component:\", explained_variance)\n",
    "    print(\"Cumulative variance explained:\", cumulative_explained_variance)\n",
    "    \n",
    "    # Create a DataFrame for easier handling\n",
    "    columns = ['PC' + str(n+1) for n in np.arange(pca_n)]\n",
    "    pca_df_time_points = pd.DataFrame(pca_result, columns=columns)\n",
    "    data[id]['PCA'] = pca_df_time_points\n",
    "    data[id]['PCA_explained'] = explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d939f6-9f58-4379-9854-f8e73c8426e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    traces = data_exp['ca']\n",
    "    if id == 'os89':\n",
    "        start_bad = 6108; end_bad = 7224\n",
    "        traces = np.hstack((traces[:, :start_bad], traces[:, end_bad:]))\n",
    "    usable_neurons = data_exp['usable_neurons']\n",
    "    traces = [traces[n] for n in np.arange(traces.shape[0]) if usable_neurons[n] == 1]\n",
    "    traces = np.array(traces)\n",
    "    behav = data_exp['behav']  \n",
    "\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces = traces.T\n",
    "    \n",
    "    # Perform PCA on the reshaped data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(traces)\n",
    "\n",
    "\n",
    "    \n",
    "    if id == 'os89':\n",
    "        # Create a new array with the original shape (15110, 6)\n",
    "        new_data = np.zeros((15110, 6))\n",
    "        new_data[:start_bad, :] = pca_result[:start_bad, :]\n",
    "        new_data[end_bad:, :] = pca_result[start_bad:, :]\n",
    "        pca_result = new_data\n",
    "    \n",
    "    # Create a DataFrame for easier handling\n",
    "    columns = ['PC' + str(n+1) for n in np.arange(n_components)]\n",
    "    pca_df_time_points = pd.DataFrame(pca_result, columns=columns)\n",
    "    data[id]['PCA'] = pca_df_time_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde6f52-8317-401c-a9ba-c8a754ee9d05",
   "metadata": {},
   "source": [
    "### Add explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bff43-bd9f-43e3-a0e9-84ef8c13064a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c57b9-ad6b-4e16-baa8-6ae5a4a0c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    traces = data_exp['ca']\n",
    "    if id == 'os89':\n",
    "        start_bad = 6108; end_bad = 7224\n",
    "        traces = np.hstack((traces[:, :start_bad], traces[:, end_bad:]))\n",
    "    usable_neurons = data_exp['usable_neurons']\n",
    "    traces = [traces[n] for n in np.arange(traces.shape[0]) if usable_neurons[n] == 1]\n",
    "    traces = np.array(traces)\n",
    "    behav = data_exp['behav']  \n",
    "\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces = traces.T\n",
    "    \n",
    "    # Perform PCA on the reshaped data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(traces)\n",
    "\n",
    "    # Get the variance explained by each component\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    # To see the cumulative explained variance:\n",
    "    cumulative_explained_variance = explained_variance.cumsum()\n",
    "    print(\"Variance explained by each component:\", explained_variance)\n",
    "    print(\"Cumulative variance explained:\", cumulative_explained_variance)\n",
    "\n",
    "    \n",
    "    pca_result = pca.fit_transform(traces)\n",
    "\n",
    "\n",
    "    \n",
    "    if id == 'os89':\n",
    "        # Create a new array with the original shape (15110, 6)\n",
    "        new_data = np.zeros((15110, n_components))\n",
    "        new_data[:start_bad, :] = pca_result[:start_bad, :]\n",
    "        new_data[end_bad:, :] = pca_result[start_bad:, :]\n",
    "        pca_result = new_data\n",
    "    \n",
    "    # Create a DataFrame for easier handling\n",
    "    columns = ['PC' + str(n+1) for n in np.arange(n_components)]\n",
    "    pca_df_time_points = pd.DataFrame(pca_result, columns=columns)\n",
    "    data[id]['PCA'] = pca_df_time_points\n",
    "    data[id]['PCA_explained'] = explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8a337-3cf5-4d89-8d75-5220cd066510",
   "metadata": {},
   "source": [
    "## Classsify the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75621b3-7155-4a74-9b6f-9b195d273f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb86c1-abd4-469b-a1e4-b8916c4eb69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664db497-0cc0-483a-a671-d383138b37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [], 'os85b': [], 'os86a': [], 'os86b': [], \n",
    "                     'os87': [], 'os88': [], 'os89': []}\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "comps_prev = {}\n",
    "comps_resp = {}\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    comps = data[id]['ICA']\n",
    "    comp_cols = comps.keys()\n",
    "    params = [ 'side', 'choice', 'missed', 'free']\n",
    "    params_prev = ['prev_reward']\n",
    "    t1 = 1200; t2 = 3000\n",
    "    t_pr1 =  -1000; t_pr2 = 0\n",
    "    all_aucs_prev = []\n",
    "    all_aucs_resp = []\n",
    "    behav_l = get_behav_ts(behav, params, [1, 1, 0, 0])\n",
    "    behav_r = get_behav_ts(behav, params, [-1, -1, 0, 0])\n",
    "    behav_l_prev = get_behav_ts(behav, params_prev, [1])\n",
    "    behav_r_prev = get_behav_ts(behav, params_prev, [-1])\n",
    "    for comp_n in comp_cols:\n",
    "        compon = comps[comp_n]\n",
    "        get_behav_ts(behav, [], [])\n",
    "        auc_l = get_auc(behav_l, compon, frame_ts, t1,  t2)\n",
    "        auc_r = get_auc(behav_r, compon, frame_ts, t1,  t2)\n",
    "        all_aucs_resp.append(auc_l+auc_r)\n",
    "        auc_l_pr = get_auc(behav_l_prev, compon, frame_ts, t_pr1,  t_pr2)\n",
    "        auc_r_pr = get_auc(behav_r_prev, compon, frame_ts, t_pr1,  t_pr2)\n",
    "        all_aucs_prev.append(auc_l_pr+auc_r_pr)\n",
    "    labels_resp = [1]*len(auc_l) + [-1]*len(auc_r)\n",
    "    labels_prev = [1]*len(auc_l_pr) + [-1]*len(auc_r_pr)\n",
    "    \n",
    "    # For response\n",
    "    y = np.array(labels_resp)\n",
    "    all_aucs_resp = np.array(all_aucs_resp)\n",
    "    X = all_aucs_resp.T\n",
    "    # Initialize LogisticRegression\n",
    "    log_reg = LogisticRegression()\n",
    "    # Fit the model\n",
    "    log_reg.fit(X, y)\n",
    "    # Get the coefficients (weights) assigned to each component\n",
    "    coefficients = log_reg.coef_[0]\n",
    "    # Sort components by their absolute coefficient value to find the most important ones\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    sorted_components = coefficients[sorted_indices]\n",
    "    \n",
    "    print(\"Most important components in separating the RESPONSE:\", sorted_indices+1)\n",
    "    cross_pcs[id].append(sorted_indices[0]+1)\n",
    "    print(\"Corresponding coefficients:\", sorted_components)\n",
    "    comps_resp[id] = sorted_indices+1\n",
    "\n",
    "    # for prev \n",
    "    y = np.array(labels_prev)\n",
    "    all_aucs_prev = np.array(all_aucs_prev)\n",
    "    X = all_aucs_prev.T\n",
    "    # Initialize LogisticRegression\n",
    "    log_reg = LogisticRegression()\n",
    "    # Fit the model\n",
    "    log_reg.fit(X, y)\n",
    "    # Get the coefficients (weights) assigned to each component\n",
    "    coefficients = log_reg.coef_[0]\n",
    "    # Sort components by their absolute coefficient value to find the most important ones\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    sorted_components = coefficients[sorted_indices]\n",
    "    \n",
    "    print(\"Most important components in separating the PREV:\", sorted_indices+1)\n",
    "    if sorted_indices[0]+1!=cross_pcs[id][0]:\n",
    "        cross_pcs[id].append(sorted_indices[0]+1)\n",
    "    else:\n",
    "        cross_pcs[id].append(sorted_indices[1]+1)\n",
    "    print(\"Corresponding coefficients:\", sorted_components)\n",
    "    comps_prev[id] = sorted_indices+1\n",
    "\n",
    "\n",
    "cross_pcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316e87a-2b76-4015-b119-9b71122c0abc",
   "metadata": {},
   "source": [
    "## Plot components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fc51d-9f1f-439a-ba62-5100c6400483",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Side and choice across components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5618a1d-81c8-492c-9b04-6b90f6a7137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = columns\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    behav = data_exp['behav']\n",
    "\n",
    "    # go through the 1st n components\n",
    "    for pca_comp in pca_cols:\n",
    "        n=0\n",
    "        pc = pcas[pca_comp]\n",
    "        params = ['side', 'choice', 'missed', 'laser']\n",
    "        ts_l = get_behav_ts(behav, params, [1, 1, 0, 0])\n",
    "        ts_r = get_behav_ts(behav, params, [-1, -1, 0, 0])\n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "        # prep figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'b', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'r', ghost_traces=True)\n",
    "    \n",
    "        for ax_n in [0,1]:\n",
    "            axs[ax_n].axvline(x=-200)\n",
    "            axs[ax_n].axvline(x=950)\n",
    "    \n",
    "        plt.title(pca_comp)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('au')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f2930-d618-4221-b2c0-f6b770576958",
   "metadata": {},
   "source": [
    "## Prev choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36d8e8-5b0a-4d88-b0b9-c8cb2b894a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = columns\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    behav = data_exp['behav']\n",
    "\n",
    "    # go through the 1st n components\n",
    "    for pca_comp in pca_cols:\n",
    "        n=0\n",
    "        pc = pcas[pca_comp]\n",
    "        params = ['prev_reward']\n",
    "        ts_l = get_behav_ts(behav, params, [1, 1, 0, 0])\n",
    "        ts_r = get_behav_ts(behav, params, [-1, -1, 0, 0])\n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "        # prep figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'b', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'r', ghost_traces=True)\n",
    "    \n",
    "        for ax_n in [0,1]:\n",
    "            axs[ax_n].axvline(x=-200)\n",
    "            axs[ax_n].axvline(x=950)\n",
    "    \n",
    "        plt.title(pca_comp)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('au')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14983469-1e9d-482e-b83c-114c61e5daa3",
   "metadata": {},
   "source": [
    "### Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e62e7d-b4af-4ea7-91a0-77c6ef9a25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = columns\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    behav = data_exp['behav']\n",
    "\n",
    "    # go through the 1st n components\n",
    "    for pca_comp in pca_cols:\n",
    "        n=0\n",
    "        pc = pcas[pca_comp]\n",
    "        params = ['side', 'choice', 'missed', 'laser']\n",
    "        ts_l = get_behav_ts(behav, params, [1, 1, 0, 0])\n",
    "        ts_r = get_behav_ts(behav, params, [-1, -1, 0, 0])\n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "        # prep figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'b', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'r', ghost_traces=True)\n",
    "        \n",
    "        # LASER \n",
    "        ts_l = get_behav_ts(behav, params, [1, 1, 0, 1])\n",
    "        ts_r = get_behav_ts(behav, params, [-1, -1, 0, -1])\n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "        # add to figure\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'b', linestyle=':', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'r', linestyle=':', ghost_traces=True)\n",
    "    \n",
    "        for ax_n in [0,1]:\n",
    "            axs[ax_n].axvline(x=-200)\n",
    "            axs[ax_n].axvline(x=950)\n",
    "    \n",
    "        plt.title(pca_comp)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('au')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325349c-ff09-41db-b41c-78266083a269",
   "metadata": {},
   "source": [
    "### OOMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00f29c-9954-4866-b926-8f1fd8385df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = columns\n",
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,3], 'os89': [1,2]}\n",
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    behav = data_exp['behav']\n",
    "    pca_ns = cross_pcs[id]\n",
    "    pca_cols = ['PC' + str(n) for n in pca_ns]\n",
    "    pca_cols = columns\n",
    "\n",
    "    # go through the 1st n components\n",
    "    for pca_comp in pca_cols:\n",
    "        n=0\n",
    "        pc = pcas[pca_comp]\n",
    "        params = ['prev_side', 'side', 'choice', 'missed', 'laser']\n",
    "        # Same\n",
    "        ts_l = get_behav_ts(behav, params, [1, 1, 1, 0, 0])\n",
    "        ts_r = get_behav_ts(behav, params, [-1,-1, -1, 0, 0])      \n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "\n",
    "        # prep figure\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'b', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'r', ghost_traces=True)\n",
    "        \n",
    "        # DIFFERENT \n",
    "        ts_l = get_behav_ts(behav, params, [-1, 1, 1, 0, 0])\n",
    "        ts_r = get_behav_ts(behav, params, [1,-1, -1, 0, 0])\n",
    "        segms_l, times_l = get_segments_canon(pc, ts_l, frame_ts)\n",
    "        segms_r, times_r = get_segments_canon(pc, ts_r, frame_ts)\n",
    "        # add to figure\n",
    "        plot_aver_sem_canon(segms_l, times_l, 'c', ghost_traces=True)\n",
    "        plot_aver_sem_canon(segms_r, times_r, 'm', ghost_traces=True)\n",
    "    \n",
    "        for ax_n in [0,1]:\n",
    "            axs[ax_n].axvline(x=-200)\n",
    "            axs[ax_n].axvline(x=950)\n",
    "        axs[0].set_title(id)\n",
    "        plt.title(pca_comp)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('au')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490790f-b7b8-44c8-bcef-9691317b97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# left same vs different\n",
    "\n",
    "    \n",
    "pc = pca_df_time_points['PC3']\n",
    "n=99\n",
    "params = ['side', 'laser']\n",
    "traces_l1 = get_segments_old(data_exp, params, [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r1 = get_segments_old(data_exp, params, [1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = pca_df_time_points['PC4']\n",
    "traces_l2 = get_segments_old(data_exp, params, [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r2 = get_segments_old(data_exp, params, [1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 3))\n",
    "ax_n = 0\n",
    "\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left \n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*')\n",
    "        \n",
    "    # plot all the right\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'c*')\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    \n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a192fc-4fcb-4b96-98f0-6f432ad82f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the 1st n components\n",
    "for pca_comp in ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6']:\n",
    "    n=0\n",
    "    pc = pca_df_time_points[pca_comp]\n",
    "    traces_l = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "    # side  \n",
    "    plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=0)\n",
    "\n",
    "    # choice\n",
    "    traces_l = get_segments_old(data_exp, ['choice', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r = get_segments_old(data_exp, ['choice', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_0 = get_segments_old(data_exp, ['choice', 'laser'], [0,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_0, 'k',ghost_traces=False, axn=1)\n",
    "\n",
    "    for ax_n in [0,1]:\n",
    "        axs[ax_n].axvline(x=-200)\n",
    "        axs[ax_n].axvline(x=950)\n",
    "\n",
    "    plt.title(pca_comp)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('au')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae6e3f-3b10-4244-9c07-35cadf8ee5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ab6cdd-c433-4fe7-b360-7dd27b040149",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Distances with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c8af0-2d5e-4bc3-b3a4-ff0986acad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distances for 2 selected components\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca']\n",
    "        behav = data_exp['behav']\n",
    "        pca_df_time_points = data[id][date]['PCA']\n",
    "    \n",
    "        pc = pca_df_time_points['PC2']\n",
    "        n=99\n",
    "        params = ['side', 'prev_reward', 'laser']\n",
    "        span=[20,40]\n",
    "        traces_l_same_1 = get_segments_old(data_exp, params, [1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_same_1 = get_segments_old(data_exp, params,[-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_l_diff_1 = get_segments_old(data_exp, params, [1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_diff_1 = get_segments_old(data_exp, params,[-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        pc = pca_df_time_points['PC3']\n",
    "        traces_l_same_2 = get_segments_old(data_exp, params, [1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_same_2 = get_segments_old(data_exp, params,[-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_l_diff_2 = get_segments_old(data_exp, params, [1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_diff_2 = get_segments_old(data_exp, params,[-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        \n",
    "        # t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "        window_width = 10\n",
    "        t_windows = [ ]\n",
    "        for t in np.arange(0,55,window_width):\n",
    "            t_windows.append([t,t+window_width-1])\n",
    "        # setup the plot\n",
    "        fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "        ax_n = 0\n",
    "        \n",
    "        for w in t_windows:\n",
    "            # plot all the left same\n",
    "            segms_l_same_1 = []\n",
    "            segms_l_same_2 = []\n",
    "            for segment_n in np.arange(len(traces_l_same_1)):\n",
    "                segment_pc1 = traces_l_same_1[segment_n]\n",
    "                segment_pc2 = traces_l_same_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_l_same_1.append(av_pc1)\n",
    "                segms_l_same_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'b*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the left diff\n",
    "            segms_l_diff_1 = []\n",
    "            segms_l_diff_2 = []\n",
    "            for segment_n in np.arange(len(traces_l_diff_1)):\n",
    "                segment_pc1 = traces_l_diff_1[segment_n]\n",
    "                segment_pc2 = traces_l_diff_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_l_diff_1.append(av_pc1)\n",
    "                segms_l_diff_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'c*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the right same\n",
    "            segms_r_same_1 = []\n",
    "            segms_r_same_2 = []\n",
    "            for segment_n in np.arange(len(traces_r_same_1)):\n",
    "                segment_pc1 = traces_r_same_1[segment_n]\n",
    "                segment_pc2 = traces_r_same_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_r_same_1.append(av_pc1)\n",
    "                segms_r_same_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'r*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the right diff\n",
    "            segms_r_diff_1 = []\n",
    "            segms_r_diff_2 = []\n",
    "            for segment_n in np.arange(len(traces_r_diff_1)):\n",
    "                segment_pc1 = traces_r_diff_1[segment_n]\n",
    "                segment_pc2 = traces_r_diff_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_r_diff_1.append(av_pc1)\n",
    "                segms_r_diff_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'm*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            av_segms_l_same_1 = np.mean(segms_l_same_1)\n",
    "            av_segms_l_same_2 = np.mean(segms_l_same_2)\n",
    "            av_segms_l_diff_1 = np.mean(segms_l_diff_1)\n",
    "            av_segms_l_diff_2 = np.mean(segms_l_diff_2)\n",
    "            av_segms_r_same_1 = np.mean(segms_r_same_1)\n",
    "            av_segms_r_same_2 = np.mean(segms_r_same_2)\n",
    "            av_segms_r_diff_1 = np.mean(segms_r_diff_1)\n",
    "            av_segms_r_diff_2 = np.mean(segms_r_diff_2)\n",
    "        \n",
    "            axs[ax_n].plot(av_segms_l_same_1, av_segms_l_same_2, color='b', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_l_diff_1, av_segms_l_diff_2, color='c', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_r_same_1, av_segms_r_same_2, color='r', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_r_diff_1, av_segms_r_diff_2, color='m', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "        \n",
    "            ax_n += 1\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7365c2-7ae1-49e6-91d6-c1fd441b79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distances for 2 selected components\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca']\n",
    "        behav = data_exp['behav']\n",
    "        pca_df_time_points = data[id][date]['PCA']\n",
    "    \n",
    "        pc = pca_df_time_points['PC2']\n",
    "        n=99\n",
    "        params = ['side', 'prev_reward', 'laser']\n",
    "        span=[10,40]\n",
    "        traces_l_same_1 = get_segments_old(data_exp, params, [1,1,1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_same_1 = get_segments_old(data_exp, params,[-1,-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_l_diff_1 = get_segments_old(data_exp, params, [1,-1,1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_diff_1 = get_segments_old(data_exp, params,[-1,1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        pc = pca_df_time_points['PC3']\n",
    "        traces_l_same_2 = get_segments_old(data_exp, params, [1,1,1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_same_2 = get_segments_old(data_exp, params,[-1,-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_l_diff_2 = get_segments_old(data_exp, params, [1,-1,1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        traces_r_diff_2 = get_segments_old(data_exp, params,[-1,1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "        \n",
    "        # t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "        window_width = 10\n",
    "        t_windows = [ ]\n",
    "        for t in np.arange(0,45,window_width):\n",
    "            t_windows.append([t,t+window_width-1])\n",
    "        # setup the plot\n",
    "        fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 3))\n",
    "        ax_n = 0\n",
    "        \n",
    "        for w in t_windows:\n",
    "            # plot all the left same\n",
    "            segms_l_same_1 = []\n",
    "            segms_l_same_2 = []\n",
    "            for segment_n in np.arange(len(traces_l_same_1)):\n",
    "                segment_pc1 = traces_l_same_1[segment_n]\n",
    "                segment_pc2 = traces_l_same_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_l_same_1.append(av_pc1)\n",
    "                segms_l_same_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'b*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the left diff\n",
    "            segms_l_diff_1 = []\n",
    "            segms_l_diff_2 = []\n",
    "            for segment_n in np.arange(len(traces_l_diff_1)):\n",
    "                segment_pc1 = traces_l_diff_1[segment_n]\n",
    "                segment_pc2 = traces_l_diff_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_l_diff_1.append(av_pc1)\n",
    "                segms_l_diff_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'c*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the right same\n",
    "            segms_r_same_1 = []\n",
    "            segms_r_same_2 = []\n",
    "            for segment_n in np.arange(len(traces_r_same_1)):\n",
    "                segment_pc1 = traces_r_same_1[segment_n]\n",
    "                segment_pc2 = traces_r_same_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_r_same_1.append(av_pc1)\n",
    "                segms_r_same_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'r*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            # plot all the right diff\n",
    "            segms_r_diff_1 = []\n",
    "            segms_r_diff_2 = []\n",
    "            for segment_n in np.arange(len(traces_r_diff_1)):\n",
    "                segment_pc1 = traces_r_diff_1[segment_n]\n",
    "                segment_pc2 = traces_r_diff_2[segment_n]\n",
    "                av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "                av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "                segms_r_diff_1.append(av_pc1)\n",
    "                segms_r_diff_2.append(av_pc2)\n",
    "                axs[ax_n].plot(av_pc1, av_pc2, 'm*', markersize=3, alpha=0.2)\n",
    "        \n",
    "            av_segms_l_same_1 = np.mean(segms_l_same_1)\n",
    "            av_segms_l_same_2 = np.mean(segms_l_same_2)\n",
    "            av_segms_l_diff_1 = np.mean(segms_l_diff_1)\n",
    "            av_segms_l_diff_2 = np.mean(segms_l_diff_2)\n",
    "            av_segms_r_same_1 = np.mean(segms_r_same_1)\n",
    "            av_segms_r_same_2 = np.mean(segms_r_same_2)\n",
    "            av_segms_r_diff_1 = np.mean(segms_r_diff_1)\n",
    "            av_segms_r_diff_2 = np.mean(segms_r_diff_2)\n",
    "        \n",
    "            axs[ax_n].plot(av_segms_l_same_1, av_segms_l_same_2, color='b', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_l_diff_1, av_segms_l_diff_2, color='c', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_r_same_1, av_segms_r_same_2, color='r', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].plot(av_segms_r_diff_1, av_segms_r_diff_2, color='m', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "            axs[ax_n].set_ylabel('PC2')\n",
    "            axs[ax_n].set_xlabel('PC1')\n",
    "        \n",
    "            ax_n += 1\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc2312-b543-4ea1-aaa6-898224f8928e",
   "metadata": {},
   "source": [
    "## trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6976ed4-2995-4b70-8139-af8468cc6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa26c8f-df9d-4f29-aabb-fbaca8c1fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,4], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "sides_code = {'l': 1, 'r': -1, 1: 'l', -1: 'r', 'same':1, 'diff':-1}\n",
    "#mice_ids = ['os85a',  'os86a',  'os87', 'os88', 'os89']\n",
    "pc_sets = \n",
    "for id in mouse_ids[1:2]:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    pc1 = pcas['PC' + str(comp_ns[0])]; pc2 = pcas['PC' + str(comp_ns[1])]\n",
    "    params = ['prev_side', 'side', 'choice', 'missed', 'laser']\n",
    "    span = [0, 4000]\n",
    "    mouse_ts = {'same': {}, 'diff': {}}\n",
    "    mouse_max_vals = {'same': {}, 'diff': {}}\n",
    "    for sameness in ['same', 'diff']:\n",
    "        for side in ['l', 'r']:\n",
    "            side_val = sides_code[side]\n",
    "            modif = sides_sode[sameness]\n",
    "            peak_ts = []; max_vals = []\n",
    "            # same left \n",
    "            segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [modif*side_val,side_val,side_val,0,0], span=span)\n",
    "            segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,side_val,0,0], span=span)\n",
    "            # each segment has to start from 0 and end at the peak\n",
    "            for s_n in np.arange(len(segms1)):\n",
    "                segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "                segm1 = segm1.tolist(); segm2 = segm2.tolist() \n",
    "                # Calculate the distance from the start (first point)\n",
    "                distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "                # Find the index of the maximum distance\n",
    "                max_distance_idx = np.argmax(distances)\n",
    "                # The time when the line is furthest away   \n",
    "                peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "                \n",
    "                #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "                axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "               # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "                # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "                segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "                # Calculate the Euclidean distance\n",
    "                distance = np.linalg.norm(segm2 - segm1); # dist_same.append(distance)\n",
    "                # our values\n",
    "                peak_ts.append(peak_t); max_vals.append(max(distances))\n",
    "            mouse_ts[sameness][side] = peak_ts\n",
    "            mouse_max_vals[sameness][side] = max_vals\n",
    "        ax_n+=1\n",
    "    data[id]['peak_ts'] = mouse_ts\n",
    "    data[id]['max_vals'] = mouse_max_vals\n",
    "\n",
    "\n",
    "\n",
    "    all_same_ts = mouse_ts['same']['l'] + mouse_ts['same']['r']\n",
    "    all_diff_ts = mouse_ts['diff']['l'] + mouse_ts['diff']['r']\n",
    "    all_same_maxs = mouse_max_vals['same']['l'] + mouse_max_vals['same']['r']\n",
    "    all_diff_maxs = mouse_max_vals['diff']['l'] + mouse_max_vals['diff']['r']\n",
    "    print('ts same: ', round(np.mean(all_same_ts),2), \n",
    "          'diff: ', round(np.mean(all_diff_ts),2)) \n",
    "    stat, p_val = stats.ttest_ind(all_same_ts, all_diff_ts)    \n",
    "    print('p for time to peak', p_val)\n",
    "    print('max vals same: ', round(np.mean(all_same_maxs),2), \n",
    "          'diff: ', round(np.mean(all_diff_maxs),2)) \n",
    "    stat, p_val = stats.ttest_ind(all_same_maxs, all_diff_maxs)    \n",
    "    print('p for time to peak', p_val)\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52498866-61c6-4fb1-a65f-3a15bd1d7e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58a2ba-a21e-4d57-a37f-b4a4b325cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472dff4b-dd5d-4637-9e6e-6d23905a21fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6263a0-0552-45a7-ba34-f27088a2344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "400f1977-5e8f-4eb2-8273-5ba5b3342d67",
   "metadata": {},
   "source": [
    "### Peak value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f4924-80a3-4ee7-bbdd-7aa9127fe769",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [5,3], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "comps_resp\n",
    "all_max_same = []\n",
    "all_max_diff = []\n",
    "for id in mouse_ids:\n",
    "    mouse_max_same = []\n",
    "    mouse_max_diff = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_resp_mouse = comps_resp[id]\n",
    "    comp_prev_mouse = comps_prev[id]\n",
    "    c1 = comp_resp_mouse[0]\n",
    "    if c1 == comp_prev_mouse[0]:\n",
    "        c2 = comp_prev_mouse[1]\n",
    "    else:\n",
    "        c2 =  comp_prev_mouse[0]\n",
    "        \n",
    "    \n",
    "    pc1 = pcas['PC' + str(c1)]; pc2 = pcas['PC' + str(c2)]\n",
    "    params = ['prev_side', 'side', 'missed', 'laser', 'choice']\n",
    "    span = [0, 3000]\n",
    "    # ==== LEFT ====\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "    print('p for max val', p_val)\n",
    "    all_max_same += peak_vals_same\n",
    "    all_max_diff += peak_vals_diff\n",
    "    mouse_max_same += peak_vals_same\n",
    "    mouse_max_diff += peak_vals_diff\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "    print('p for max val', p_val)\n",
    "    all_max_same += peak_vals_same\n",
    "    all_max_diff += peak_vals_diff\n",
    "    mouse_max_same += peak_vals_same\n",
    "    mouse_max_diff += peak_vals_diff\n",
    "    data[id]['max_comp'] = {'same': mouse_max_same, 'diff': mouse_max_diff}\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80a7a4-a477-4ee3-b6ac-5186b6bd58a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abd714-8d80-4dbc-a5e0-bc187af99263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for id in mouse_ids:\n",
    "    peak_ts_same = data[id]['max_comp']['same']\n",
    "    peak_ts_diff = data[id]['max_comp']['diff']\n",
    "    \n",
    "    # Combine data for boxplot\n",
    "    to_plot = [peak_ts_same, peak_ts_diff]\n",
    "    # Create boxplot\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    \n",
    "    u_stat, p_value = mannwhitneyu(peak_ts_same, peak_ts_diff)\n",
    "    print(f\"Mann-Whitney U test p-value: {p_value}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(to_plot, patch_artist=True, showmeans=True)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xticks([1, 2], ['Peak TS Same', 'Peak TS Diff'])\n",
    "   # plt.yticks(np.arange (10, 40, 5), np.arange (1000, 4000, 500))\n",
    "    plt.title('Peak Times (Previous Same vs. Diff)')\n",
    "    plt.ylabel('Peak Times')\n",
    "    \n",
    "    # Add standard deviation (as text) for each group\n",
    "    same_std = np.std(peak_ts_same)\n",
    "    diff_std = np.std(peak_ts_diff)\n",
    "    plt.text(1, np.max(peak_ts_same), f'Std: {same_std:.2f}', ha='center')\n",
    "    plt.text(2, np.max(peak_ts_diff), f'Std: {diff_std:.2f}', ha='center')\n",
    "    \n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2503d-7be2-4b71-a16d-3fe43603c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_stat, p_value = mannwhitneyu(all_max_same, all_max_diff)\n",
    "print(f\"Mann-Whitney U test p-value: {p_value}, stats: {u_stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9948832-8aeb-4432-8c9c-359d8639d039",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Just for the beauty, PC1 and PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db669d1-046d-41ee-b42e-3f858be3209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    pc1 = pcas['PC3']; pc2 = pcas['PC2']\n",
    "    params = ['prev_side', 'side', 'missed']\n",
    "    span = [0, 2600]\n",
    "    # ==== LEFT ====\n",
    "    peak_ts_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_ts_same.append(peak_t)\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_ts_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_ts_diff.append(peak_t)\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_ts_same), np.mean(peak_ts_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_ts_same, peak_ts_diff)    \n",
    "    print('p for time to peak', p_val)\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_ts_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_ts_same.append(peak_t)\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_ts_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_ts_diff.append(peak_t)\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_ts_same), np.mean(peak_ts_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_ts_same, peak_ts_diff)    \n",
    "    print('p for time to peak', p_val)\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d64d27-8c82-4db1-a5da-a2ace3d12387",
   "metadata": {},
   "source": [
    "### Same but for laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50270a5-7862-4811-a444-de4ea5a582bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "comps_resp\n",
    "all_max_same = []\n",
    "all_max_diff = []\n",
    "for id in mouse_ids:\n",
    "    mouse_max_same = []\n",
    "    mouse_max_diff = []\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_resp_mouse = comps_resp[id]\n",
    "    comp_prev_mouse = comps_prev[id]\n",
    "    c1 = comp_resp_mouse[0]\n",
    "    if c1 == comp_prev_mouse[0]:\n",
    "        c2 = comp_prev_mouse[1]\n",
    "    else:\n",
    "        c2 =  comp_prev_mouse[0]\n",
    "        \n",
    "    \n",
    "    pc1 = pcas['PC' + str(c1)]; pc2 = pcas['PC' + str(c2)]\n",
    "    params = ['prev_side', 'side', 'missed', 'laser', 'choice']\n",
    "    span = [0, 3000]\n",
    "    # ==== LEFT ====\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "    print('p for max val', p_val)\n",
    "    all_max_same += peak_vals_same\n",
    "    all_max_diff += peak_vals_diff\n",
    "    mouse_max_same += peak_vals_same\n",
    "    mouse_max_diff += peak_vals_diff\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "    print('p for max val', p_val)\n",
    "    all_max_same += peak_vals_same\n",
    "    all_max_diff += peak_vals_diff\n",
    "    mouse_max_same += peak_vals_same\n",
    "    mouse_max_diff += peak_vals_diff\n",
    "    data[id]['max_comp_laser'] = {'same': mouse_max_same, 'diff': mouse_max_diff}\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6477bde-88e2-428e-b5b7-2f9ffbd3e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for id in mouse_ids:\n",
    "    peak_ts_same = data[id]['max_comp_laser']['same']\n",
    "    peak_ts_diff = data[id]['max_comp_laser']['diff']\n",
    "    \n",
    "    # Combine data for boxplot\n",
    "    to_plot = [peak_ts_same, peak_ts_diff]\n",
    "    # Create boxplot\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    \n",
    "    u_stat, p_value = mannwhitneyu(peak_ts_same, peak_ts_diff)\n",
    "    print(f\"Mann-Whitney U test p-value: {p_value}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(to_plot, patch_artist=True, showmeans=True)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xticks([1, 2], ['Peak TS Same', 'Peak TS Diff'])\n",
    "   # plt.yticks(np.arange (10, 40, 5), np.arange (1000, 4000, 500))\n",
    "    plt.title('Peak Times (Previous Same vs. Diff)')\n",
    "    plt.ylabel('Peak Times')\n",
    "    \n",
    "    # Add standard deviation (as text) for each group\n",
    "    same_std = np.std(peak_ts_same)\n",
    "    diff_std = np.std(peak_ts_diff)\n",
    "    plt.text(1, np.max(peak_ts_same), f'Std: {same_std:.2f}', ha='center')\n",
    "    plt.text(2, np.max(peak_ts_diff), f'Std: {diff_std:.2f}', ha='center')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cf60e-13ae-4ffb-b3ee-34403d39f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "all_las = []; all_nolas = []\n",
    "all_same_las = []; all_same_nolas = []\n",
    "all_diff_las = []; all_diff_nolas = []\n",
    "for id in mouse_ids[:-2]:\n",
    "    peak_ts_diff = data[id]['max_comp_laser']['diff'] + data[id]['max_comp_laser']['same']\n",
    "    peak_ts_same = data[id]['max_comp']['diff'] + data[id]['max_comp']['same']\n",
    "    all_las+=peak_ts_diff; all_nolas+=peak_ts_same\n",
    "    all_same_las += data[id]['max_comp_laser']['same']\n",
    "    all_same_nolas += data[id]['max_comp']['same']\n",
    "    all_diff_las += data[id]['max_comp_laser']['diff']\n",
    "    all_diff_nolas += data[id]['max_comp']['diff']\n",
    "    # Combine data for boxplot\n",
    "    to_plot = [peak_ts_same, peak_ts_diff]\n",
    "    # Create boxplot\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    \n",
    "    u_stat, p_value = mannwhitneyu(peak_ts_same, peak_ts_diff)\n",
    "    print(f\"Mann-Whitney U test p-value: {p_value}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(to_plot, patch_artist=True, showmeans=True)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xticks([1, 2], ['Peak TS Same', 'Peak TS Diff'])\n",
    "   # plt.yticks(np.arange (10, 40, 5), np.arange (1000, 4000, 500))\n",
    "    plt.title('Peak Times (Previous Same vs. Diff)')\n",
    "    plt.ylabel('Peak Times')\n",
    "    \n",
    "    # Add standard deviation (as text) for each group\n",
    "    same_std = np.std(peak_ts_same)\n",
    "    diff_std = np.std(peak_ts_diff)\n",
    "    plt.text(1, np.max(peak_ts_same), f'Std: {same_std:.2f}', ha='center')\n",
    "    plt.text(2, np.max(peak_ts_diff), f'Std: {diff_std:.2f}', ha='center')\n",
    "    \n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391dd56-7a39-45a2-8f0d-02ff5856daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_stat, p_value = mannwhitneyu(all_diff_las, all_diff_nolas)\n",
    "print(f\"Mann-Whitney U test p-value: {p_value}, {u_stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b81e04-29b7-42d5-be30-7e990699310a",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f09c6-731d-4cce-b314-462f39c52cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "cross_pcs = {'os85a': [3,4], 'os85b': [3,6], 'os86a': [1,5], 'os86b': [2,7], \n",
    "  #                   'os87': [2,5], 'os88': [1,2], 'os89': [5,10]}\n",
    "# ================ LASER NOW ===================\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 3))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    pc1 = pcas['PC' + str(comp_ns[0])]; pc2 = pcas['PC' + str(comp_ns[1])]\n",
    "    params = ['prev_side', 'side', 'missed', 'laser', 'choice']\n",
    "    span = [-700, 4000]\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # ==== LEFT ====\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    table_means = {'side': [], 'laser': [], 'is_same': [], 'mean': []}\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "   # print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "   # print('p for max val L', p_val)\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    \n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "  #  print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    " #   print('p for max val R', p_val)\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # ==== LEFT ====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "  #  print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "  #  print('p for max val L laser', p_val)\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx \n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "   # print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "   # print('p for max val R laser', p_val)\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    table_means = pd.DataFrame(table_means)\n",
    "  #  print(table_means)\n",
    "    data[id]['table_means'] = table_means\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad0245-1165-45e0-ba57-0f874b55ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_s = []\n",
    "all_d = []\n",
    "for id in mouse_ids:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_s.append(same_l); all_s.append(same_r); \n",
    "    all_d.append(diff_l); all_d.append(diff_r); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_s, axis=0), 'k', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_d, axis=0), 'y', linewidth=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfeb9bb-157e-4776-b34c-3679319b4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_s = []\n",
    "all_d = []\n",
    "for id in mouse_ids:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_s.append(same_l); all_s.append(same_r); \n",
    "    all_d.append(diff_l); all_d.append(diff_r); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_s, axis=0), 'k', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_d, axis=0), 'y', linewidth=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a125920-4797-47e6-8b56-ef94ccd0df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "\n",
    "\n",
    "for id in mouse_ids[:-1]:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca']\n",
    "        behav = data_exp['behav']\n",
    "        pca_df_time_points = data[id][date]['PCA']\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax_n = 0\n",
    "        for conditions in condition_pairs:\n",
    "            print(conditions)\n",
    "            params = param_val_keys[conditions[0]]['params']\n",
    "            vals1 = param_val_keys[conditions[0]]['vals']\n",
    "            vals2 = param_val_keys[conditions[1]]['vals']\n",
    "    \n",
    "            pc = pca_df_time_points['PC2']\n",
    "            n=99\n",
    "            span=[10,25]\n",
    "            traces_l_diff_x = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_x = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            pc = pca_df_time_points['PC3']\n",
    "            traces_l_diff_y = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_y = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            \n",
    "\n",
    "            colors = [param_val_keys[conditions[0]]['color'], param_val_keys[conditions[1]]['color']]\n",
    "            for tr_n in np.arange(15): #len(traces_l_diff_x)):\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n], -traces_l_diff_y[tr_n], color=colors[0], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][0], -traces_l_diff_y[tr_n][0], color=colors[0], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][-1], -traces_l_diff_y[tr_n][-1], color=colors[0], marker='D', alpha=0.5)\n",
    "          #  ax_n += 1\n",
    "            for trace_n in np.arange(15): #len(traces_r_diff_x)):    \n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n], -traces_r_diff_y[trace_n], color=colors[1], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][0], -traces_r_diff_y[trace_n][0], color=colors[1], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][-1], -traces_r_diff_y[trace_n][-1], color=colors[1], marker='D', alpha=0.5)\n",
    "\n",
    "      \n",
    "            \n",
    "        ax_n += 1\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99363104-fadc-49a1-bb12-47acb71226f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same_las', 'left_side_diff_las'],\n",
    "                   ['right_side_same_las', 'right_side_diff_las'] ]\n",
    "\n",
    "\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca']\n",
    "        behav = data_exp['behav']\n",
    "        pca_df_time_points = data[id][date]['PCA']\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax_n = 0\n",
    "        for conditions in condition_pairs:\n",
    "            print(conditions)\n",
    "            params = param_val_keys[conditions[0]]['params']\n",
    "            vals1 = param_val_keys[conditions[0]]['vals']\n",
    "            vals2 = param_val_keys[conditions[1]]['vals']\n",
    "    \n",
    "            pc = pca_df_time_points['PC2']\n",
    "            n=99\n",
    "            span=[-5,25]\n",
    "            traces_l_diff_x = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_x = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            pc = pca_df_time_points['PC3']\n",
    "            traces_l_diff_y = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_y = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            \n",
    "\n",
    "            colors = [param_val_keys[conditions[0]]['color'], param_val_keys[conditions[1]]['color']]\n",
    "            for tr_n in np.arange(len(traces_l_diff_x)):\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n], -traces_l_diff_y[tr_n], color=colors[0], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][0], -traces_l_diff_y[tr_n][0], color=colors[0], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][-1], -traces_l_diff_y[tr_n][-1], color=colors[0], marker='D', alpha=0.5)\n",
    "          #  ax_n += 1\n",
    "            for trace_n in np.arange(len(traces_r_diff_x)):    \n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n], -traces_r_diff_y[trace_n], color=colors[1], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][0], -traces_r_diff_y[trace_n][0], color=colors[1], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][-1], -traces_r_diff_y[trace_n][-1], color=colors[1], marker='D', alpha=0.5)\n",
    "\n",
    "      \n",
    "            \n",
    "        ax_n += 1\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023962d-d009-4c49-81ec-e8a78fc36521",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traces_l_diff_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04054835-d0ca-4aba-ac7c-1fae1095b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6a668-c6f8-4e94-a9b7-2e5ed4cb4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse 86 on 2024-05-26\n",
    "# For prev. conrtast laser vs no laser\n",
    "condtions_pairs = [\n",
    "                    ['left_side', 'right_side'],\n",
    "                    ['left_side_las', 'right_side_las'],\n",
    "     ['left_side_diff', 'right_side_diff'],\n",
    "\n",
    "                  ]\n",
    "condtions_pairs2 = [\n",
    "                    ['left_side_same', 'right_side_same'],\n",
    "                    ['left_side_same_las', 'right_side_same_las'],\n",
    "                  ]\n",
    "condtions_pairs3 = [\n",
    "                    ['left_side_diff', 'right_side_diff'],\n",
    "                    ['left_side_diff_las', 'right_side_diff_las'],\n",
    "                  ]\n",
    "\n",
    "t_windows = []\n",
    "window_width = 2\n",
    "for t in np.arange(0,30,window_width):\n",
    "    t_windows.append([t,t+window_width-1])\n",
    "\n",
    "\n",
    "# ok lets do ica for all the mice\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print('=== ' + id + ' ' + date + ' ===')\n",
    "        data_exp = data[id][date]\n",
    "        ca_df_time_points = data_exp['PCA']\n",
    "        # setup the plot\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 2))\n",
    "        ax_n = 0\n",
    "        for conditions in condtions_pairs:\n",
    "            dist = []\n",
    "            for w in t_windows:\n",
    "                distance_t = distance_btw_comp(conditions, data_exp, ca_df_time_points, w=w, span=[0,50])\n",
    "                dist.append(distance_t)\n",
    "            axs[ax_n].plot(dist)\n",
    "        ax_n = ax_n+1\n",
    "        for conditions in condtions_pairs2:\n",
    "            dist = []\n",
    "            for w in t_windows:\n",
    "                distance_t = distance_btw_comp(conditions, data_exp, ca_df_time_points, w=w, span=[0,50])\n",
    "                dist.append(distance_t)\n",
    "            axs[ax_n].plot(dist)\n",
    "        ax_n = ax_n+1\n",
    "        for conditions in condtions_pairs3:\n",
    "            dist = []\n",
    "            for w in t_windows:\n",
    "                distance_t = distance_btw_comp(conditions, data_exp, ca_df_time_points, w=w, span=[0,50])\n",
    "                dist.append(distance_t)\n",
    "            axs[ax_n].plot(dist)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482ed55-89ce-43c5-9f6b-e3e8d4fe2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd3771-370a-426d-a6f3-b24315dc71c4",
   "metadata": {},
   "source": [
    "# ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a081c1-b41a-4e32-b717-73f0cb034643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace_type = 'ca'\n",
    "# ok lets do ica for all the mice\n",
    "for id in mouse_ids:\n",
    "    print('=== ' + id + ' ===')\n",
    "    data_exp = data[id]\n",
    "    n_components = 12 #n_comps[id]\n",
    "    usable = [ data_exp['good_neurons'][n]==1 or data_exp['fair_neurons'][n]==1 for n in np.arange(len(data_exp['good_neurons']))]\n",
    "    traces = data_exp[trace_type]\n",
    "    traces = traces[np.array(usable)]\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces_t = traces.T\n",
    "    # Perform ICA on the entire dataset\n",
    "    \n",
    "    ica = FastICA(n_components=n_components, random_state=0)\n",
    "    ica_result = ica.fit_transform(traces_t)\n",
    "    \n",
    "    # Independent components (mixing matrix)\n",
    "    components = ica.mixing_\n",
    "    \n",
    "    # Create a DataFrame for easier handling\n",
    "    columns = ['IC' + str(n+1) for n in np.arange(n_components)]\n",
    "    ica_df_time_points = pd.DataFrame(ica_result, columns=columns)\n",
    "\n",
    "    data[id]['ICA'] = ica_df_time_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f10ca-5011-49da-8b70-21d86491e1fa",
   "metadata": {},
   "source": [
    "## Browse ICAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f7019-b49a-43d7-8a78-c6cb2ea1ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace_type = 'ca'\n",
    "# ok lets do ica for all the mice\n",
    "for id in mouse_ids:\n",
    "    print('=== ' + id + ' ===')\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    n_components = 16\n",
    "    usable = [ data_exp['good_neurons'][n]==1 or data_exp['fair_neurons'][n]==1 for n in np.arange(len(data_exp['good_neurons']))]\n",
    "    traces = data_exp[trace_type]\n",
    "    traces = traces[np.array(usable)]\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces_t = traces.T\n",
    "    # Perform ICA on the entire dataset\n",
    "    for n_components in [12]:\n",
    "        print('=== ' + str(n_components) + ' ===')\n",
    "        ica = FastICA(n_components=n_components, random_state=0)\n",
    "        ica_result = ica.fit_transform(traces_t)\n",
    "        # Independent components (mixing matrix)\n",
    "        mixing_matrix = ica.mixing_\n",
    "        # Create a DataFrame for easier handling\n",
    "        ica_cols = ['IC' + str(n+1) for n in np.arange(n_components)]\n",
    "        comps = pd.DataFrame(ica_result, columns=ica_cols)\n",
    "        # This is A * S\n",
    "        mixing_matrix_abs = np.abs(mixing_matrix)\n",
    "        normalized_mixing = mixing_matrix_abs / mixing_matrix_abs.max(axis=0)\n",
    "        \n",
    "        # Create a DataFrame for easier visualization\n",
    "        neuron_contributions = pd.DataFrame(\n",
    "            normalized_mixing, \n",
    "            columns=['IC' + str(i+1) for i in range(n_components)],\n",
    "            index=['Neuron' + str(i+1) for i in range(mixing_matrix.shape[0])]\n",
    "        )\n",
    "        '''\n",
    "        # Optionally, sort each column by contribution to see which neurons contribute the most to each IC\n",
    "        for ic in neuron_contributions.columns:\n",
    "            print(f\"\\nTop contributors to {ic}:\")\n",
    "            print(neuron_contributions[ic].sort_values(ascending=False).head(10))\n",
    "            '''\n",
    "\n",
    "       \n",
    "       # data[id]['ICA'] = ica_df_time_points\n",
    "        # prep the figure\n",
    "        n_cols_fig = 5\n",
    "        rows_fig = math.ceil(n_components/n_cols_fig)\n",
    "        fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = ['prev_reward', 'side', 'choice', 'missed', 'free']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,-1,-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "            '''\n",
    "            # diff\n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1.1,1,-1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [2.2,-1,1,0,0], span=span)\n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "            '''\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [-1,1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [1,-1,-1,0,0], span=span)\n",
    "            \n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'c', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'm', ghost_traces=False, ax_n=ax)\n",
    "            '''\n",
    "            # diff\n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [-1,1,-1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [1,-1,1,0,0], span=span)\n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'c', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'm', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "            '''\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "            axs[ax].set_title(comp_n)\n",
    "        \n",
    "            plt.title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        plt.show()\n",
    "        # just left vs right\n",
    "        fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = [ 'side', 'choice', 'missed', 'free']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "            axs[ax].set_title(comp_n)\n",
    "        \n",
    "            plt.title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        plt.show()\n",
    "\n",
    "        # prev trial left over\n",
    "        fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = [ 'prev_reward', 'missed', 'free']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "            axs[ax].set_title(comp_n)\n",
    "        \n",
    "            plt.title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce44e9e-aa71-4bac-8b9b-c882849edbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    comps = data[id]['PCA']\n",
    "    comp_cols = comps.keys()\n",
    "    params = [ 'side', 'choice', 'missed', 'free']\n",
    "    params_prev = ['prev_reward']\n",
    "    t1 = -1200; t2 = 3000\n",
    "    t_pr1 =  1000; t_pr2 =  1000\n",
    "    all_aucs_prev = []\n",
    "    all_aucs_resp = []\n",
    "    for comp_n in comp_cols:\n",
    "        compon = comps[comp_n]\n",
    "        behav_l = get_behav_ts(behav, params, [1, 1, 0, 0])\n",
    "        behav_r = get_behav_ts(behav, params, [-1, -1, 0, 0])\n",
    "        auc_l = get_auc(behav_l, compon, frame_ts, t1,  t2)\n",
    "        auc_r = get_auc(behav_r, compon, frame_ts, t1,  t2)\n",
    "        all_aucs_resp.append(auc_l+auc_r)\n",
    "        behav_l = get_behav_ts(behav, params_prev, [1])\n",
    "        behav_r = get_behav_ts(behav, params_prev, [-1])\n",
    "        auc_l_pr = get_auc(behav_l, compon, frame_ts, t_pr1,  t_pr2)\n",
    "        auc_r_pr = get_auc(behav_r, compon, frame_ts, t_pr1,  t_pr2)\n",
    "        all_aucs_prev.append(auc_l_pr+auc_r_pr)\n",
    "    labels_resp = [1]*len(auc_l) + [-1]*len(auc_r)\n",
    "    labels_prev = [1]*len(auc_l_pr) + [-1]*len(auc_r_pr)\n",
    "    \n",
    "    # For response\n",
    "    y = np.array(labels_resp)\n",
    "    all_aucs_resp = np.array(all_aucs_resp)\n",
    "    X = all_aucs_resp.T\n",
    "    # Initialize LogisticRegression\n",
    "    log_reg = LogisticRegression()\n",
    "    # Fit the model\n",
    "    log_reg.fit(X, y)\n",
    "    # Get the coefficients (weights) assigned to each component\n",
    "    coefficients = log_reg.coef_[0]\n",
    "    # Sort components by their absolute coefficient value to find the most important ones\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    sorted_components = coefficients[sorted_indices]\n",
    "    \n",
    "    print(\"Most important components in separating the RESPONSE:\", sorted_indices+1)\n",
    "    print(\"Corresponding coefficients:\", sorted_components)\n",
    "\n",
    "    # for prev \n",
    "    y = np.array(labels_prev)\n",
    "    all_aucs_prev = np.array(all_aucs_prev)\n",
    "    X = all_aucs_prev.T\n",
    "    # Initialize LogisticRegression\n",
    "    log_reg = LogisticRegression()\n",
    "    # Fit the model\n",
    "    log_reg.fit(X, y)\n",
    "    # Get the coefficients (weights) assigned to each component\n",
    "    coefficients = log_reg.coef_[0]\n",
    "    # Sort components by their absolute coefficient value to find the most important ones\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    sorted_components = coefficients[sorted_indices]\n",
    "    \n",
    "    print(\"Most important components in separating the PREV:\", sorted_indices+1)\n",
    "    print(\"Corresponding coefficients:\", sorted_components)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9ebc3-5837-4fb6-9699-80e304b0d6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6200c-7261-4a37-98f4-0aa6182ddcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace_type = 'ca'\n",
    "# ok lets do ica for all the mice\n",
    "for id in mouse_ids:\n",
    "    print('=== ' + id + ' ===')\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    n_components = 12 #n_comps[id]\n",
    "    usable = [ data_exp['good_neurons'][n]==1 or data_exp['fair_neurons'][n]==1 for n in np.arange(len(data_exp['good_neurons']))]\n",
    "    traces = data_exp[trace_type]\n",
    "    traces = traces[np.array(usable)]\n",
    "    # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "    traces_t = traces.T\n",
    "    # Perform ICA on the entire dataset\n",
    "    for n_components in [16]: # np.arange(8,15):\n",
    "        print('=== ' + str(n_components) + ' ===')\n",
    "        ica = FastICA(n_components=n_components, random_state=0)\n",
    "        ica_result = ica.fit_transform(traces_t)\n",
    "        # Independent components (mixing matrix)\n",
    "        mixing_matrix = ica.mixing_\n",
    "        # Create a DataFrame for easier handling\n",
    "        ica_cols = ['IC' + str(n+1) for n in np.arange(n_components)]\n",
    "        comps = pd.DataFrame(ica_result, columns=ica_cols)\n",
    "        # This is A * S\n",
    "        mixing_matrix_abs = np.abs(mixing_matrix)\n",
    "        normalized_mixing = mixing_matrix_abs / mixing_matrix_abs.max(axis=0)\n",
    "        \n",
    "        # Create a DataFrame for easier visualization\n",
    "        neuron_contributions = pd.DataFrame(\n",
    "            normalized_mixing, \n",
    "            columns=['IC' + str(i+1) for i in range(n_components)],\n",
    "            index=['Neuron' + str(i+1) for i in range(mixing_matrix.shape[0])]\n",
    "        )\n",
    "        '''\n",
    "        # Optionally, sort each column by contribution to see which neurons contribute the most to each IC\n",
    "        for ic in neuron_contributions.columns:\n",
    "            print(f\"\\nTop contributors to {ic}:\")\n",
    "            print(neuron_contributions[ic].sort_values(ascending=False).head(10))\n",
    "            '''\n",
    "\n",
    "       \n",
    "        data[id]['ICA'] = comps\n",
    "        # prep the figure\n",
    "        n_cols_fig = 4\n",
    "        rows_fig = math.ceil(n_components/n_cols_fig)\n",
    "      #  fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        '''\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = ['prev_reward', 'side', 'choice', 'missed', 'laser']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,-1,-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [-1,1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [1,-1,-1,0,0], span=span)\n",
    "               \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'c', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'm', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "        \n",
    "            plt.title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        plt.show()\n",
    "        '''\n",
    "        # LASER VS NO LASER\n",
    "        fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = [ 'side', 'choice', 'missed', 'laser']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,1,0,1], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,-1,0,-1], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', linestyle=':', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "            axs[ax].set_title(comp_n)\n",
    "        \n",
    "            plt.title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        plt.show()\n",
    "        '''\n",
    "        # prev trial left over\n",
    "        fig, axs = plt.subplots(rows_fig, n_cols_fig, figsize=(15, rows_fig*3))\n",
    "        ax_n=0\n",
    "        pl_n = 0\n",
    "        # go through the components\n",
    "        for comp_n in ica_cols:\n",
    "            ax_r = pl_n // n_cols_fig; ax_c = pl_n % n_cols_fig\n",
    "            ax = ax_r, ax_c\n",
    "            pl_n += 1\n",
    "            comp = comps[comp_n]\n",
    "            params = [ 'prev_reward', 'missed', 'free']\n",
    "            span = [1000,4000]\n",
    "            \n",
    "            segms_l, segm_ts_l = get_segments(behav, comp, frame_ts, params, [1,0,0], span=span)\n",
    "            segms_r, segm_ts_r = get_segments(behav, comp, frame_ts, params, [-1,0,0], span=span)\n",
    "     \n",
    "            # side  \n",
    "            plot_aver_sem(segms_l, segm_ts_l, 'b', ghost_traces=False, ax_n=ax)\n",
    "            plot_aver_sem(segms_r, segm_ts_r, 'r', ghost_traces=False, ax_n=ax)\n",
    "\n",
    "            axs[ax].axvline(x=0)\n",
    "            axs[ax].axvline(x=1150)\n",
    "        \n",
    "            axs[ax].title(comp_n)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('IC')\n",
    "        \n",
    "        plt.show()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f439dfd-bb28-4b33-b6bc-88bb252a33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    dates = data[id]\n",
    "    # and date\n",
    "    \n",
    "    print(f\"::: Mouse  {id},  :::\")\n",
    "    data_exp = data[id][date]\n",
    "    ica_df_time_points = data[id]['ICA']\n",
    "    ica_cols = ica_df_time_points.keys()\n",
    "\n",
    "    # go through the 1st n components\n",
    "    for ica_comp in ica_cols:\n",
    "        n=0\n",
    "        pc = ica_df_time_points[ica_comp]\n",
    "        \n",
    "        traces_l = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "        traces_r = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "        # side  \n",
    "        plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=0)\n",
    "        plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=0)\n",
    "    \n",
    "        # choice\n",
    "        traces_l = get_segments_old(data_exp, ['choice', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "        traces_r = get_segments_old(data_exp, ['choice', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "      #  traces_0 = get_segments_old(data_exp, ['choice', 'laser'], [0,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "        plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=1)\n",
    "        plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=1)\n",
    "     #   plot_aver_se_old(traces_0, 'k',ghost_traces=False, axn=1)\n",
    "    \n",
    "        for ax_n in [0,1]:\n",
    "            axs[ax_n].axvline(x=0)\n",
    "            axs[ax_n].axvline(x=1150)\n",
    "    \n",
    "        plt.title(ica_comp)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('au')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4b3c3-1472-47a4-b062-181d05f15fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_cols = ica_columns\n",
    "# For each mouse\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        ica_df_time_points = data[id][date]['ICA']\n",
    "\n",
    "        # go through the 1st n components\n",
    "        for ica_comp in ica_cols:\n",
    "            n=0\n",
    "            pc = ica_df_time_points[ica_comp]\n",
    "            params = ['side', 'choice', 'prev_reward', 'laser']\n",
    "            traces_l_same = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_l_diff = get_segments_old(data_exp, params, [1,1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_same = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_diff = get_segments_old(data_exp, params, [-1,-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "            # side  \n",
    "            plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=0)\n",
    "        \n",
    "            # same but with laser\n",
    "            params = ['side', 'choice', 'prev_reward', 'laser']\n",
    "            traces_l_same = get_segments_old(data_exp, params, [1,1,1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_l_diff = get_segments_old(data_exp, params, [1,1,-1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_same = get_segments_old(data_exp, params, [-1,-1,-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_diff = get_segments_old(data_exp, params, [-1,-1,1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            \n",
    "\n",
    "            # side  \n",
    "            plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=1, linestyle=':')\n",
    "            plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=1, linestyle=':')\n",
    "            plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=1, linestyle=':')\n",
    "            plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=1, linestyle=':')\n",
    "         #   plot_aver_se_old(traces_0, 'k',ghost_traces=False, axn=1)\n",
    "        \n",
    "            for ax_n in [0,1]:\n",
    "                axs[ax_n].axvline(x=-200)\n",
    "                axs[ax_n].axvline(x=950)\n",
    "        \n",
    "            plt.title(ica_comp)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('au')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631993b-23fe-4ad9-95b2-f12e4fbe1f40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## test the optimal number of ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4aaf6-1795-4794-98c5-2d6f693e002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38259a2c-73ef-40cf-bcbd-468b8ea5ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print('mouse_id = [\\'' + id + '\\']; dates = [\\'' + date + '\\']')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a9f93-d0ad-45d1-9e24-d86d79b50a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mouse_id = ['os85']; dates = ['2024-06-05']\n",
    "#mouse_id = ['os85']; dates = ['2024-06-12']\n",
    "#mouse_id = ['os86']; dates = ['2024-05-26']\n",
    "mouse_id = ['os86']; dates = ['2024-06-03']\n",
    "#mouse_id = ['os87']; dates = ['2024-06-12']\n",
    "#mouse_id = ['os88']; dates = ['2024-06-04']\n",
    "for id in mouse_id:\n",
    "   # dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print('=== ' + id + ' ' + date + ' ===')\n",
    "        \n",
    "\n",
    "\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca'] \n",
    "        usable_neurons = data_exp['usable_neurons']\n",
    "        traces_clean = [traces[n] for n in np.arange(traces.shape[0]) if usable_neurons[n] == 1]\n",
    "        traces_clean = np.array(traces_clean)\n",
    "        # Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "        traces_t = traces.T\n",
    "        traces_clean_t = traces_clean.T\n",
    "        # Perform ICA on the entire dataset\n",
    "        n_components = 12\n",
    "        ica = FastICA(n_components=n_components, random_state=0)\n",
    "        ica_result = ica.fit_transform(traces_t)\n",
    "        ica_result_clean = ica.fit_transform(traces_clean_t)\n",
    "        \n",
    "        # Independent components (mixing matrix)\n",
    "        components = ica.mixing_\n",
    "        \n",
    "        \n",
    "        # Create a DataFrame for easier handling\n",
    "        ica_columns = ['IC' + str(n+1) for n in np.arange(n_components)]\n",
    "        ica_df_time_points = pd.DataFrame(ica_result, columns=ica_columns)\n",
    "        ica_df_time_points_clean = pd.DataFrame(ica_result_clean, columns=ica_columns)\n",
    "\n",
    "      #  data[id][date]['ICA'] = ica_df_time_points\n",
    "\n",
    "        ica_cols = ica_columns\n",
    "\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "\n",
    "\n",
    "        # go through the 1st n components\n",
    "        for ica_comp in ica_cols:\n",
    "            n=0\n",
    "            pc = ica_df_time_points[ica_comp]\n",
    "            params = ['side', 'choice', 'prev_reward', 'laser']\n",
    "            traces_l_same = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_l_diff = get_segments_old(data_exp, params, [1,1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_same = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_diff = get_segments_old(data_exp, params, [-1,-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "            # side  \n",
    "            plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=0)\n",
    "        \n",
    "            # same but with clean components\n",
    "            pc = ica_df_time_points_clean[ica_comp]\n",
    "            params = ['side', 'choice', 'prev_reward', 'laser']\n",
    "            traces_l_same = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_l_diff = get_segments_old(data_exp, params, [1,1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_same = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_diff = get_segments_old(data_exp, params, [-1,-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            \n",
    "\n",
    "            # side  \n",
    "            plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=1)\n",
    "            plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=1)\n",
    "            plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=1)\n",
    "            plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=1)\n",
    "         #   plot_aver_se_old(traces_0, 'k',ghost_traces=False, axn=1)\n",
    "        \n",
    "            for ax_n in [0,1]:\n",
    "                axs[ax_n].axvline(x=-200)\n",
    "                axs[ax_n].axvline(x=950)\n",
    "        \n",
    "            plt.title(ica_comp)\n",
    "            plt.xlabel('time')\n",
    "            plt.ylabel('au')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200e46c-a1c8-434d-bc76-870cd1a2fa98",
   "metadata": {},
   "source": [
    "## Test the idea with the inter trial intervals\n",
    "For now, only Mouse  os86, 2024-05-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e42d8-7070-44d0-9077-7985586e1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ica_cols = ['IC2', 'IC3']\n",
    "# For each mouse\n",
    "for id in ['os88']:\n",
    "    dates = ['2024-06-04']\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        behav = data[id][date]['behav']\n",
    "        ica_df_time_points = data[id][date]['ICA']\n",
    "\n",
    "        # go through the 1st n components\n",
    "        for ica_comp in ica_cols:\n",
    "            n=0\n",
    "            pc = ica_df_time_points[ica_comp]\n",
    "            params = ['side', 'choice', 'prev_reward', 'laser']\n",
    "            traces_l_same = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_l_diff = get_segments_old(data_exp, params, [1,1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_same = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            traces_r_diff = get_segments_old(data_exp, params, [-1,-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "            # side  \n",
    "            plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=0)\n",
    "            plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=0)\n",
    "        \n",
    "            for ax_n in [0]:\n",
    "                axs[ax_n].axvline(x=0)\n",
    "                axs[ax_n].axvline(x=1150)\n",
    "\n",
    "            # plot the mean value of IC within 800 to 2500 ms window\n",
    "            \n",
    "            add_las=0\n",
    "            for tr_n in np.arange(behav.shape[0]):\n",
    "                if behav['laser'][tr_n] == 0:\n",
    "                    if (behav['side'][tr_n] == 1) & (behav['choice'][tr_n] == 1):\n",
    "                        if (behav['prev_reward'][tr_n] == 1):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                       #     axs[1].plot(iti_tr, ic_segm_av, 'b*')\n",
    "                        elif (behav['prev_reward'][tr_n] == -1):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                            axs[1].plot(iti_tr, ic_segm_av, 'c*')\n",
    "                        elif (behav['prev_reward'][tr_n] == 0):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                        #    axs[1].plot(iti_tr, ic_segm_av, 'k*')\n",
    "                     # now, left side\n",
    "                    if (behav['side'][tr_n] == -1) & (behav['choice'][tr_n] == -1):\n",
    "                   \n",
    "                        if (behav['prev_reward'][tr_n] == -1):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                      #      axs[1].plot(iti_tr, ic_segm_av, 'r*')\n",
    "                        elif (behav['prev_reward'][tr_n] == 1):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                            axs[1].plot(iti_tr, ic_segm_av, 'm*')\n",
    "                        elif (behav['prev_reward'][tr_n] == 0):\n",
    "                            t = behav['frame_tone'][tr_n]\n",
    "                            ic_segm_av = np.mean(pc[t+15:t+25])\n",
    "                            iti_tr = behav['ITI'][tr_n]\n",
    "                           # axs[1].plot(iti_tr, ic_segm_av, 'y*')\n",
    "                    \n",
    "                \n",
    "        \n",
    "        #    plt.title(ica_comp)\n",
    "         #   plt.xlabel('time')\n",
    "         #   plt.ylabel('au')\n",
    "            plt.show()\n",
    "print(add_las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3171b3-77fd-41bb-b00f-86020488997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1st, do the analysis for only 1 mouse on 1 date\n",
    "id = 'os86'; date = '2024-05-26' # seems the best in terms of good neurons\n",
    "data_exp = data[id][date]\n",
    "traces = data_exp['ca'] \n",
    "behav = data_exp['behav']\n",
    "# Reshape data for PCA (each row is a time point, each column is a neuron)\n",
    "traces = traces.T\n",
    "# Perform ICA on the entire dataset\n",
    "n_components =  10\n",
    "ica = FastICA(n_components=n_components, random_state=0)\n",
    "ica_result = ica.fit_transform(traces)\n",
    "\n",
    "# Independent components (mixing matrix)\n",
    "components = ica.mixing_\n",
    "\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "columns = ['IC' + str(n+1) for n in np.arange(n_components)]\n",
    "ica_df_time_points = pd.DataFrame(ica_result, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb432426-7bef-4aa6-b490-ed245dc4c351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821806ab-0648-4c74-bfc2-75229a7b6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the 1st n components\n",
    "for ica_comp in columns:\n",
    "    n=0\n",
    "    ic = ica_df_time_points[ica_comp]\n",
    "    traces_l = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=ic)\n",
    "    traces_r = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=ic)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n",
    "    # side  \n",
    "    plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=0)\n",
    "\n",
    "    # choice\n",
    "    traces_l = get_segments_old(data_exp, ['choice', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=ic)\n",
    "    traces_r = get_segments_old(data_exp, ['choice', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=ic)\n",
    "    traces_0 = get_segments_old(data_exp, ['choice', 'laser'], [0,0], n, frame_type='frame_tone', is_pca=True, pc=ic)\n",
    "    plot_aver_se_old(traces_l, 'b',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_r, 'r',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_0, 'k',ghost_traces=False, axn=1)\n",
    "\n",
    "    for ax_n in [0,1]:\n",
    "        axs[ax_n].axvline(x=-200)\n",
    "        axs[ax_n].axvline(x=950)\n",
    "\n",
    "    plt.title(ica_comp)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('au')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5291b29-0046-423d-a2f6-9284b8496867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for prev chocie\n",
    "# go through the 1st n components\n",
    "for pca_comp in columns:\n",
    "    n=0\n",
    "    pc = ica_df_time_points[pca_comp]\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "    # all sides, no laser\n",
    "    params = ['side', 'prev_side', 'prev_choice', 'laser']\n",
    "    traces_l_same = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_l_diff = get_segments_old(data_exp, params, [1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_same = get_segments_old(data_exp, params,[-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff = get_segments_old(data_exp, params,[-1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_l_diff, 'c',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r_diff, 'm',ghost_traces=False, axn=0)\n",
    "\n",
    "    # only left side, laser effects\n",
    "    params = ['side', 'prev_side', 'prev_choice', 'laser']\n",
    "    traces_l_same_nolas = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_l_diff_nolas = get_segments_old(data_exp, params, [1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_l_same_las = get_segments_old(data_exp, params, [1,1,1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_l_diff_las = get_segments_old(data_exp, params, [1,-1,-1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    plot_aver_se_old(traces_l_same_nolas, 'b',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_diff_nolas, 'c',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_same_las, 'b',linestyle=':',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_diff_las, 'c',linestyle=':',ghost_traces=False, axn=1)\n",
    "\n",
    "    # only left side, laser effects\n",
    "    params = ['side', 'prev_choice', 'prev_side', 'laser']\n",
    "    traces_r_same_nolas = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff_nolas = get_segments_old(data_exp, params, [-1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_same_las = get_segments_old(data_exp, params, [-1,-1,-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff_las = get_segments_old(data_exp, params, [-1,1,1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    plot_aver_se_old(traces_r_same_nolas, 'r',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_diff_nolas, 'm',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_same_las, 'r',linestyle=':',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_diff_las, 'm',linestyle=':',ghost_traces=False, axn=2)\n",
    "\n",
    "    for ax_n in [0,1,2]:\n",
    "        axs[ax_n].axvline(x=-200)\n",
    "        axs[ax_n].axvline(x=950)\n",
    "\n",
    "    plt.title(pca_comp)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('au')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c6dec-79a0-498b-8c18-0a32595ad9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the 1st n components\n",
    "for pca_comp in columns:\n",
    "    n=0\n",
    "    pc = ica_df_time_points[pca_comp]\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "    # all sides, no laser\n",
    "    params = ['side',  'laser']\n",
    "    traces_l_same = get_segments_old(data_exp, params, [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_l_diff = get_segments_old(data_exp, params, [1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_same = get_segments_old(data_exp, params,[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff = get_segments_old(data_exp, params,[-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    plot_aver_se_old(traces_l_same, 'b',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_l_diff, 'b',linestyle=':',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r_same, 'r',ghost_traces=False, axn=0)\n",
    "    plot_aver_se_old(traces_r_diff, 'r',linestyle=':',ghost_traces=False, axn=0)\n",
    "    '''\n",
    "\n",
    "    # only left side, laser effects\n",
    "    params = ['side', 'laser']\n",
    "    traces_l_same_nolas = get_segments_old(data_exp, params, [1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "    traces_l_same_las = get_segments_old(data_exp, params, [1,1,1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "    \n",
    "    plot_aver_se_old(traces_l_same_nolas, 'b',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_diff_nolas, 'c',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_same_las, 'b',linestyle=':',ghost_traces=False, axn=1)\n",
    "    plot_aver_se_old(traces_l_diff_las, 'c',linestyle=':',ghost_traces=False, axn=1)\n",
    "\n",
    "    # only left side, laser effects\n",
    "    params = ['side', 'prev_choice', 'prev_side', 'laser']\n",
    "    traces_r_same_nolas = get_segments_old(data_exp, params, [-1,-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff_nolas = get_segments_old(data_exp, params, [-1,1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_same_las = get_segments_old(data_exp, params, [-1,-1,-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    traces_r_diff_las = get_segments_old(data_exp, params, [-1,1,1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "    \n",
    "    plot_aver_se_old(traces_r_same_nolas, 'r',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_diff_nolas, 'm',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_same_las, 'r',linestyle=':',ghost_traces=False, axn=2)\n",
    "    plot_aver_se_old(traces_r_diff_las, 'm',linestyle=':',ghost_traces=False, axn=2)\n",
    "'''\n",
    "    for ax_n in [0,1,2]:\n",
    "        axs[ax_n].axvline(x=-200)\n",
    "        axs[ax_n].axvline(x=950)\n",
    "\n",
    "    plt.title(pca_comp)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('au')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079efe9-8981-4a93-9c68-55208f2218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC3']\n",
    "n=99\n",
    "traces_l1 = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r1 = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = ica_df_time_points['IC2']\n",
    "traces_l2 = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r2 = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [ ]\n",
    "for t in np.arange(0,30,4):\n",
    "    t_windows.append([t,t+3])\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "for w in t_windows:\n",
    "    segms_l1 = []\n",
    "    segms_l2 = []\n",
    "    # plot all the left \n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_l1.append(av_pc1)\n",
    "        segms_l2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*', markersize=3, alpha=0.2)\n",
    "        \n",
    "    # plot all the right\n",
    "    segms_r1 = []\n",
    "    segms_r2 = []\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_r1.append(av_pc1)\n",
    "        segms_r2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'r*', markersize=3, alpha=0.2)\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    av_segms_l1 = np.mean(segms_l1)\n",
    "    av_segms_l2 = np.mean(segms_l2)\n",
    "    av_segms_r1 = np.mean(segms_r1)\n",
    "    av_segms_r2 = np.mean(segms_r2)\n",
    "    axs[ax_n].plot(av_segms_l1,av_segms_l2, color='b', marker='o', markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_r1,av_segms_r2, color='r', marker='o', markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f914ed7-7f99-4616-97f6-345fd3e71aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but with prev choice\n",
    "    \n",
    "pc = ica_df_time_points['IC3']\n",
    "n = 99\n",
    "params = ['side', 'prev_reward', 'laser']\n",
    "traces_pc1 = {\n",
    "    'l_same': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'r_same': get_segments_old(data_exp, params, [-1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'r_diff': get_segments_old(data_exp, params, [-1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "pc = ica_df_time_points['IC5']\n",
    "traces_pc2 = {\n",
    "    'l_same': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'r_same': get_segments_old(data_exp, params, [-1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'r_diff': get_segments_old(data_exp, params, [-1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "marker_specs = {'l_same':'b','l_diff':'c','r_same':'r','r_diff':'m'}\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [[t, t + 1] for t in np.arange(0, 30, 5)]\n",
    "\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "for w in t_windows:\n",
    "    for key in traces_pc1.keys():\n",
    "        segms_pc1 = traces_pc1[key]\n",
    "        segms_pc2 = traces_pc2[key]\n",
    "        avs_pc1 = []\n",
    "        avs_pc2 = []\n",
    "    \n",
    "        for segment_n in np.arange(len(segms_pc1)):\n",
    "            segm_pc1 = traces_pc1[key][segment_n]\n",
    "            segm_pc2 = traces_pc2[key][segment_n]\n",
    "            av_pc1 = np.mean(segm_pc1[w[0]:w[1]])\n",
    "            av_pc2 = np.mean(segm_pc2[w[0]:w[1]])\n",
    "            avs_pc1.append(av_pc1)\n",
    "            avs_pc2.append(av_pc2)\n",
    "            color = marker_specs[key]\n",
    "            style = '*'\n",
    "            axs[ax_n].plot(av_pc1, av_pc2, color + style, markersize=3, alpha=0.2)\n",
    "        av_segms_1 = np.mean(avs_pc1)\n",
    "        av_segms_2 = np.mean(avs_pc2)\n",
    "        axs[ax_n].plot(av_segms_1,av_segms_2, color=color, marker='o', markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "\n",
    "    ax_n += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7c05e-6d7a-42be-9080-4f75a41fa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same_las', 'left_side_diff_las'],\n",
    "                   ['right_side_same_las', 'right_side_diff_las'] ]\n",
    "\n",
    "\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    # and date\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca']\n",
    "        behav = data_exp['behav']\n",
    "        pca_df_time_points = data[id][date]['ICA']\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax_n = 0\n",
    "        for conditions in condition_pairs:\n",
    "            print(conditions)\n",
    "            params = param_val_keys[conditions[0]]['params']\n",
    "            vals1 = param_val_keys[conditions[0]]['vals']\n",
    "            vals2 = param_val_keys[conditions[1]]['vals']\n",
    "    \n",
    "            pc = pca_df_time_points['IC1']\n",
    "            n=99\n",
    "            span=[-5,25]\n",
    "            traces_l_diff_x = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_x = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            pc = pca_df_time_points['IC3']\n",
    "            traces_l_diff_y = get_segments_old(data_exp, params, vals1, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            traces_r_diff_y = get_segments_old(data_exp, params, vals2, n, frame_type='frame_tone', is_pca=True, pc=pc, span=span)\n",
    "            \n",
    "\n",
    "            colors = [param_val_keys[conditions[0]]['color'], param_val_keys[conditions[1]]['color']]\n",
    "            for tr_n in np.arange(len(traces_l_diff_x)):\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n], -traces_l_diff_y[tr_n], color=colors[0], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][0], -traces_l_diff_y[tr_n][0], color=colors[0], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_l_diff_x[tr_n][-1], -traces_l_diff_y[tr_n][-1], color=colors[0], marker='D', alpha=0.5)\n",
    "          #  ax_n += 1\n",
    "            for trace_n in np.arange(len(traces_r_diff_x)):    \n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n], -traces_r_diff_y[trace_n], color=colors[1], alpha=0.2)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][0], -traces_r_diff_y[trace_n][0], color=colors[1], marker='o', alpha=0.5)\n",
    "                axs[ax_n].plot(traces_r_diff_x[trace_n][-1], -traces_r_diff_y[trace_n][-1], color=colors[1], marker='D', alpha=0.5)\n",
    "\n",
    "      \n",
    "            \n",
    "        ax_n += 1\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3411dad-dbe9-497e-bd47-0575408dac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but with laser\n",
    "    \n",
    "pc = ica_df_time_points['IC4']\n",
    "n = 99\n",
    "params = ['side', 'prev_reward', 'laser']\n",
    "traces_pc1 = {\n",
    "    'l_same_nolas': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_nolas': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_same_las': get_segments_old(data_exp, params, [1, 1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_las': get_segments_old(data_exp, params, [1, -1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "pc = ica_df_time_points['IC7']\n",
    "traces_pc2 = {\n",
    "    'l_same_nolas': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_nolas': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_same_las': get_segments_old(data_exp, params, [1, 1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_las': get_segments_old(data_exp, params, [1, -1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "marker_specs = {'l_same_nolas': {'color':'b', 'marker':'o'},\n",
    "                'l_diff_nolas':{'color':'c', 'marker':'o'},\n",
    "                'l_same_las': {'color':'b', 'marker':'D'},\n",
    "                'l_diff_las': {'color':'c', 'marker':'D'}}\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [[t, t + 1] for t in np.arange(0, 30, 5)]\n",
    "\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "for w in t_windows:\n",
    "    for key in traces_pc1.keys():\n",
    "        segms_pc1 = traces_pc1[key]\n",
    "        segms_pc2 = traces_pc2[key]\n",
    "        avs_pc1 = []\n",
    "        avs_pc2 = []\n",
    "        color = marker_specs[key]['color']\n",
    "        marker = marker_specs[key]['marker']\n",
    "    \n",
    "        for segment_n in np.arange(len(segms_pc1)):\n",
    "            segm_pc1 = traces_pc1[key][segment_n]\n",
    "            segm_pc2 = traces_pc2[key][segment_n]\n",
    "            av_pc1 = np.mean(segm_pc1[w[0]:w[1]])\n",
    "            av_pc2 = np.mean(segm_pc2[w[0]:w[1]])\n",
    "            avs_pc1.append(av_pc1)\n",
    "            avs_pc2.append(av_pc2)\n",
    "            \n",
    "            axs[ax_n].plot(av_pc1, av_pc2, color=color, marker=marker, markersize=3, alpha=0.2)\n",
    "        av_segms_1 = np.mean(avs_pc1)\n",
    "        av_segms_2 = np.mean(avs_pc2)\n",
    "        axs[ax_n].plot(av_segms_1,av_segms_2, color=color, marker=marker, markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "\n",
    "    ax_n += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05817e4-2ca1-4fe5-971b-8a0a161d1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Same but with prev choice\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC3']\n",
    "n=99\n",
    "params = ['side', 'prev_reward', 'laser']\n",
    "traces_l_same_1 = get_segments_old(data_exp, params, [1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r_same_1 = get_segments_old(data_exp, params,[-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_l_diff_1 = get_segments_old(data_exp, params, [1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r_diff_1 = get_segments_old(data_exp, params,[-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = ica_df_time_points['IC2']\n",
    "traces_l_same_2 = get_segments_old(data_exp, params, [1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r_same_2 = get_segments_old(data_exp, params,[-1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_l_diff_2 = get_segments_old(data_exp, params, [1,-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r_diff_2 = get_segments_old(data_exp, params,[-1,1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "titles = [0, 1150, 2000]\n",
    "t_windows = [ ]\n",
    "window_width = 10\n",
    "for t in np.arange(0,30,window_width):\n",
    "    t_windows.append([t,t+window_width-1])\n",
    "t_windows = [ [5,10], [15,20], [25,30] ]\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 4))\n",
    "ax_n = 0\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left same\n",
    "    segms_l_same_1 = []\n",
    "    segms_l_same_2 = []\n",
    "    for segment_n in np.arange(len(traces_l_same_1)):\n",
    "        segment_pc1 = traces_l_same_1[segment_n]\n",
    "        segment_pc2 = traces_l_same_2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_l_same_1.append(av_pc1)\n",
    "        segms_l_same_2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1, av_pc2, 'b*', markersize=3, alpha=0.3)\n",
    "\n",
    "    # plot all the left diff\n",
    "    segms_l_diff_1 = []\n",
    "    segms_l_diff_2 = []\n",
    "    for segment_n in np.arange(len(traces_l_diff_1)):\n",
    "        segment_pc1 = traces_l_diff_1[segment_n]\n",
    "        segment_pc2 = traces_l_diff_2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_l_diff_1.append(av_pc1)\n",
    "        segms_l_diff_2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1, av_pc2, 'c*', markersize=3, alpha=0.3)\n",
    "\n",
    "    # plot all the right same\n",
    "    segms_r_same_1 = []\n",
    "    segms_r_same_2 = []\n",
    "    for segment_n in np.arange(len(traces_r_same_1)):\n",
    "        segment_pc1 = traces_r_same_1[segment_n]\n",
    "        segment_pc2 = traces_r_same_2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_r_same_1.append(av_pc1)\n",
    "        segms_r_same_2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1, av_pc2, 'r*', markersize=3, alpha=0.3)\n",
    "\n",
    "    # plot all the right diff\n",
    "    segms_r_diff_1 = []\n",
    "    segms_r_diff_2 = []\n",
    "    for segment_n in np.arange(len(traces_r_diff_1)):\n",
    "        segment_pc1 = traces_r_diff_1[segment_n]\n",
    "        segment_pc2 = traces_r_diff_2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_r_diff_1.append(av_pc1)\n",
    "        segms_r_diff_2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1, av_pc2, 'm*', markersize=3, alpha=0.3)\n",
    "\n",
    "    av_segms_l_same_1 = np.mean(segms_l_same_1)\n",
    "    av_segms_l_same_2 = np.mean(segms_l_same_2)\n",
    "    av_segms_l_diff_1 = np.mean(segms_l_diff_1)\n",
    "    av_segms_l_diff_2 = np.mean(segms_l_diff_2)\n",
    "    av_segms_r_same_1 = np.mean(segms_r_same_1)\n",
    "    av_segms_r_same_2 = np.mean(segms_r_same_2)\n",
    "    av_segms_r_diff_1 = np.mean(segms_r_diff_1)\n",
    "    av_segms_r_diff_2 = np.mean(segms_r_diff_2)\n",
    "\n",
    "    axs[ax_n].plot(av_segms_l_same_1, av_segms_l_same_2, color='b', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_l_diff_1, av_segms_l_diff_2, color='c', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_r_same_1, av_segms_r_same_2, color='r', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_r_diff_1, av_segms_r_diff_2, color='m', marker='o', markersize=12, markeredgewidth=2, fillstyle='none')\n",
    "    axs[ax_n].set_title(f'{titles[ax_n]} ms')\n",
    "    axs[ax_n].set_ylabel(f'IC2')\n",
    "    axs[ax_n].set_xlabel(f'IC3')\n",
    "    ax_n += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a958d-e3cd-4307-88f5-534382355830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC1']\n",
    "n=99\n",
    "traces_l1 = get_segments_old(data_exp, ['side', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r1 = get_segments_old(data_exp, ['side', 'laser'],[-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = ica_df_time_points['IC2']\n",
    "traces_l2 = get_segments_old(data_exp, ['side', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r2 = get_segments_old(data_exp, ['side', 'laser'],[-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [ ]\n",
    "for t in np.arange(6,27,4):\n",
    "    t_windows.append([t,t+1])\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left \n",
    "    segms_l1 = []\n",
    "    segms_l2 = []\n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_l1.append(av_pc1)\n",
    "        segms_l2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*', markersize=3, alpha=0.2)\n",
    "        \n",
    "    # plot all the right\n",
    "    segms_r1 = []\n",
    "    segms_r2 = []\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_r1.append(av_pc1)\n",
    "        segms_r2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'c*', markersize=3, alpha=0.2)\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    av_segms_l1 = np.mean(segms_l1)\n",
    "    av_segms_l2 = np.mean(segms_l2)\n",
    "    av_segms_r1 = np.mean(segms_r1)\n",
    "    av_segms_r2 = np.mean(segms_r2)\n",
    "    axs[ax_n].plot(av_segms_l1,av_segms_l2, color='blue', marker='o', markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_r1,av_segms_r2, color='c', marker='o', markersize=12,fillstyle='none')\n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00063e-7b65-47f9-95b0-9ccd0c9bebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC3']\n",
    "n=99\n",
    "traces_l1 = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=[3,50])\n",
    "traces_r1 = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=[3,50])\n",
    "pc = ica_df_time_points['IC2']\n",
    "traces_l2 = get_segments_old(data_exp, ['side', 'laser'], [1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=[3,50])\n",
    "traces_r2 = get_segments_old(data_exp, ['side', 'laser'],[-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc, span=[3,50])\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [ ]\n",
    "for t in np.arange(0,50,6):\n",
    "    t_windows.append([t,t+1])\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left \n",
    "    segms_l1 = []\n",
    "    segms_l2 = []\n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_l1.append(av_pc1)\n",
    "        segms_l2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*', markersize=3, alpha=0.2)\n",
    "        \n",
    "    # plot all the right\n",
    "    segms_r1 = []\n",
    "    segms_r2 = []\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        segms_r1.append(av_pc1)\n",
    "        segms_r2.append(av_pc2)\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'r*', markersize=3, alpha=0.2)\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    av_segms_l1 = np.mean(segms_l1)\n",
    "    av_segms_l2 = np.mean(segms_l2)\n",
    "    av_segms_r1 = np.mean(segms_r1)\n",
    "    av_segms_r2 = np.mean(segms_r2)\n",
    "    axs[ax_n].plot(av_segms_l1,av_segms_l2, color='blue', marker='o', markersize=12,fillstyle='none')\n",
    "    axs[ax_n].plot(av_segms_r1,av_segms_r2, color='r', marker='o', markersize=12,fillstyle='none')\n",
    "    axs[ax_n].set_title(f'{w[0]*100} - {w[1]*100} ms', fontsize=8)\n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2d998-4d9e-4233-a93e-916a5c52ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC1']\n",
    "n=99\n",
    "traces_l1 = get_segments_old(data_exp, ['side', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r1 = get_segments_old(data_exp, ['side', 'laser'],[-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = ica_df_time_points['IC2']\n",
    "traces_l2 = get_segments_old(data_exp, ['side', 'laser'], [-1,0], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r2 = get_segments_old(data_exp, ['side', 'laser'],[-1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [ ]\n",
    "for t in np.arange(4,35,4):\n",
    "    t_windows.append([t,t+1])\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left \n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*')\n",
    "        \n",
    "    # plot all the right\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'c*')\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    \n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e82eb7-2958-4e7a-bdac-006d94a75277",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# left same vs different\n",
    "\n",
    "    \n",
    "pc = ica_df_time_points['IC3']\n",
    "n=99\n",
    "params = ['side', 'prev_reward']\n",
    "traces_l1 = get_segments_old(data_exp, params, [1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r1 = get_segments_old(data_exp, params, [1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "pc = ica_df_time_points['IC6']\n",
    "traces_l2 = get_segments_old(data_exp, params, [1,1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "traces_r2 = get_segments_old(data_exp, params, [1,-1], n, frame_type='frame_tone', is_pca=True, pc=pc)\n",
    "\n",
    "t_windows = [ [0,5], [6,9], [10,13], [14,17], [18,21], [22,25], [26,29]]\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, 7, figsize=(15, 3))\n",
    "ax_n = 0\n",
    "\n",
    "\n",
    "for w in t_windows:\n",
    "    # plot all the left \n",
    "    for segment_n in np.arange(len(traces_l1)):\n",
    "        segment_pc1 = traces_l1[segment_n]\n",
    "        segment_pc2 = traces_l2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'b*')\n",
    "        \n",
    "    # plot all the right\n",
    "    for segment_n in np.arange(len(traces_r1)):\n",
    "        segment_pc1 = traces_r1[segment_n]\n",
    "        segment_pc2 = traces_r2[segment_n]\n",
    "        av_pc1 = np.mean(segment_pc1[w[0]:w[1]])\n",
    "        av_pc2 = np.mean(segment_pc2[w[0]:w[1]])\n",
    "        axs[ax_n].plot(av_pc1,av_pc2, 'c*')\n",
    " #   axs[ax_n].set_title(f't window {str(w[0]*100)} to {str(w[1]*100)} ms')\n",
    "   #axs[ax_n].xlabel('PC1')\n",
    "  #  axs[ax_n].ylabel('PC2')\n",
    "    \n",
    "    ax_n = ax_n+1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1977273-83f0-429c-baf7-715e01bf7285",
   "metadata": {},
   "source": [
    "## Trajectories ICA!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef92f6-c934-4b3c-b405-8f1889bbbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs ={'os85a': [13, 15],\n",
    " 'os85b': [5, 16],\n",
    " 'os86a': [16, 11],\n",
    " 'os86b': [5, 7],\n",
    " 'os87': [8, 14],\n",
    " 'os88': [15, 1],\n",
    " 'os89': [5, 1]}\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "sides_code = {'l': 1, 'r': -1, 1: 'l', -1: 'r', 'same':1, 'diff':-1}\n",
    "#mice_ids = ['os85a',  'os86a',  'os87', 'os88', 'os89']\n",
    "\n",
    "#for try1 in np.arange(1,17):\n",
    "#    print(try1)\n",
    "  #  for try2 in np.arange(1,17):\n",
    "comps_ns = [12,5,2,7]\n",
    "for id in mouse_ids[:1]:\n",
    "   # print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['ICA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    ax_n = 0\n",
    "    comp_ns = [try1, try2] # cross_pcs[id]\n",
    "  #  pc1 = pcas['PC' + str(comp_ns[0])]; pc2 = pcas['PC' + str(comp_ns[1])]\n",
    "    comps_all = [pcas['IC' + str(n)] for n in comps_ns]\n",
    "    params = ['prev_side', 'side', 'missed', 'laser']\n",
    "    span = [0, 4000]\n",
    "\n",
    "    distances_traveled = {'same': {'l': [], 'r': []}, 'diff': {'l': [], 'r': []}}\n",
    "    for sameness in ['same', 'diff']:\n",
    "        for side in ['l', 'r']:\n",
    "            side_val = sides_code[side]\n",
    "            modif = sides_sode[sameness]\n",
    "            peak_ts = []; max_vals = []\n",
    "            # same left \n",
    "            segms_all = []\n",
    "            for each_comp in comps_all:\n",
    "                segms1, segm_ts1 = get_segments(behav, each_comp, frame_ts, params, [modif*side_val,side_val,0,0], span=span)\n",
    "                segms_all.append(segms1)\n",
    "            #segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,side_val,0,0], span=span)\n",
    "            # each segment has to start from 0 and end at the peak\n",
    "            for s_n in np.arange(len(segms1)):\n",
    "                # Calculate differences between consecutive points\n",
    "                dx = np.diff(segms_all[0][s_n])\n",
    "                dy = np.diff(segms_all[1][s_n])\n",
    "                dz = np.diff(segms_all[2][s_n])\n",
    "                dw = np.diff(segms_all[3][s_n])\n",
    "\n",
    "\n",
    "                # Calculate the Euclidean distance in 4D between consecutive points\n",
    "                distances = np.sqrt(dx**2 + dy**2 + dz**2 + dw**2)\n",
    "\n",
    "                # Sum the distances to get the total length of the trajectory in 4D\n",
    "                total_length = np.sum(distances)\n",
    "\n",
    "                distances_traveled[sameness][side].append(total_length)\n",
    "\n",
    "    data[id]['travels'] = distances_traveled\n",
    "    print(np.mean(distances_traveled['same']['l']))\n",
    "    print(np.mean(distances_traveled['diff']['l']))\n",
    "    stat, p_value_l= ttest_ind(distances_traveled['same']['l'], distances_traveled['diff']['l'])\n",
    "    \n",
    "    \n",
    "    stat, p_value = ttest_ind(distances_traveled['same']['r'], distances_traveled['diff']['r'])\n",
    "\n",
    "    \n",
    "    print(f\"Statistic L: {stat}, P-value: {p_value_l}\")\n",
    "    print(f\"Statistic R: {stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8cdab-663f-4014-9fb7-4859322ff356",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([distances_traveled['same']['l'], distances_traveled['diff']['l'], distances_traveled['same']['r'], distances_traveled['diff']['r']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b4995-497a-4248-8c6c-b445949a32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([distances_traveled['same']['l'], distances_traveled['diff']['l'], distances_traveled['same']['r'], distances_traveled['diff']['r']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94f393-e2be-4ad8-8d6b-0de31789565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[id]['ICA'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e6e91-e404-4b79-836f-44f7500c4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [4,6], 'os85b': [3,5], 'os86a': [7,12], 'os86b': [5,3], \n",
    "                     'os87': [8,14], 'os88': [2,1], 'os89': [12,5]}\n",
    "\n",
    "\n",
    "cross_pcs = {'os85a': [13, 6],\n",
    " 'os85b': [3, 15],\n",
    " 'os86a': [16, 11],\n",
    " 'os86b': [12, 7],\n",
    " 'os87': [3, 5],\n",
    " 'os88': [7, 8],\n",
    " 'os89': [5, 12]}\n",
    "\n",
    "'''\n",
    "cross_pcs ={'os85a': [13, 15],\n",
    " 'os85b': [5, 16],\n",
    " 'os86a': [16, 11],\n",
    " 'os86b': [5, 7],\n",
    " 'os87': [8, 14],\n",
    " 'os88': [15, 1],\n",
    " 'os89': [5, 1]}\n",
    " '''\n",
    "# demure\n",
    "cross_pcs = {'os85a': [4,15],\n",
    " 'os85b': [6, 11],\n",
    " 'os86a': [4, 16],\n",
    " 'os86b': [13, 5],\n",
    " 'os87': [8, 1],\n",
    " 'os88': [1, 13],\n",
    " 'os89': [13, 14]}\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "all_peak_ts_same = []\n",
    "all_peak_ts_diff = []\n",
    "max_comp_mice = {}\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Generate all combinations of 2 different numbers between 1 and 16 (inclusive)\n",
    "combinations = list(itertools.combinations(range(1, 17), 2))\n",
    "\n",
    "t_to_peak_mice = {} \n",
    "max_distances_mice = {}\n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    mouse_peak_ts_same = []\n",
    "    mouse_peak_ts_diff = []\n",
    "    \n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['ICA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    " #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    pc1 = pcas['IC' + str(comp_ns[0])]; pc2 = pcas['IC' + str(comp_ns[1])]\n",
    "    #pc1 = pcas['PC1']; pc2 = pcas['PC2']\n",
    "    params = ['prev_side', 'side',  'missed',  'laser']\n",
    "    span = [0, 4000]\n",
    "    max_distances = {'same': {'l': [], 'r': []}, 'diff': {'l': [], 'r': []}}\n",
    "    peak_ts = {'same': {'l': [], 'r': []}, 'diff': {'l': [], 'r': []}}\n",
    "    for sameness in ['same', 'diff']:\n",
    "        for side in ['l', 'r']:\n",
    "            side_val = sides_code[side]\n",
    "            modif = sides_sode[sameness]\n",
    "            max_ts = []; max_vals = []\n",
    "            # same left \n",
    "            segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [modif*side_val,side_val,0,0], span=span)\n",
    "            segms2, segm_ts1 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,0,0], span=span)\n",
    "            #segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,side_val,0,0], span=span)\n",
    "            # each segment has to start from 0 and end at the peak\n",
    "            for s_n in np.arange(len(segms1)):\n",
    "                segm1 = np.array(segms1[s_n]); segm2 = np.array(segms2[s_n])\n",
    "                ref_x, ref_y = segm1[0], segm2[0]\n",
    "                distance = np.sqrt((segm1 - ref_x)**2 + (segm2 - ref_y)**2).tolist()\n",
    "                max_t = np.argmax(distance)\n",
    "                max_distance = distance[max_t]\n",
    "                max_ts.append(max_t)\n",
    "                max_vals.append(max_distance)\n",
    "            max_distances[sameness][side] = max_vals\n",
    "            peak_ts[sameness][side] = max_ts\n",
    "    \n",
    "    \n",
    "    stat, p_val = stats.ttest_ind(max_distances['same']['l']+max_distances['same']['r'],\n",
    "                                  max_distances['diff']['l']+max_distances['diff']['r']) \n",
    "    stat, p_val_t = stats.ttest_ind(peak_ts['same']['l']+peak_ts['same']['r'],\n",
    "                                  peak_ts['diff']['l']+peak_ts['diff']['r']) \n",
    "    '''\n",
    "       # stat, p_val = stats.ttest_ind(peak_ts['same'][side], peak_ts['diff'][side]) \n",
    "    p_thr = 0.05\n",
    "    if (p_val < p_thr) & (p_val_t < p_thr):\n",
    "        print(combo)\n",
    "        print('dist: ', \n",
    "              round(np.mean(max_distances['same']['l']+max_distances['same']['r']),2), \n",
    "              round(np.mean(max_distances['diff']['l']+max_distances['diff']['r']),2), \n",
    "              p_val)\n",
    "        print('time: ', \n",
    "              round(np.mean(peak_ts['same']['l']+peak_ts['same']['r']),2), \n",
    "              round(np.mean(peak_ts['diff']['l']+peak_ts['diff']['r']),2), \n",
    "              p_val_t)\n",
    "              '''\n",
    "\n",
    "    data[id]['max_distances'] = max_distances\n",
    "    data[id]['peak_ts'] = peak_ts\n",
    "    t_to_peak_mice[id] = peak_ts\n",
    "    max_distances_mice[id] = max_distances\n",
    "\n",
    "            \n",
    "           # plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6723f32-5f4d-431d-b72f-fa03fbc742bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_comp_mice = {}\n",
    "         \n",
    "for id in mouse_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    mouse_peak_ts_same = []\n",
    "    mouse_peak_ts_diff = []\n",
    "    \n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['ICA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    " #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    pc1 = pcas['IC' + str(comp_ns[0])]; pc2 = pcas['IC' + str(comp_ns[1])]\n",
    "    #pc1 = pcas['PC1']; pc2 = pcas['PC2']\n",
    "    params = ['prev_side', 'side',   'missed',  'laser']\n",
    "    span = [0, 4000]\n",
    "    max_distances = {'same': {'l': [], 'r': []}, 'diff': {'l': [], 'r': []}}\n",
    "    peak_ts = {'same': {'l': [], 'r': []}, 'diff': {'l': [], 'r': []}}\n",
    "    for sameness in ['same', 'diff']:\n",
    "        for side in ['l', 'r']:\n",
    "            side_val = sides_code[side]\n",
    "            modif = sides_sode[sameness]\n",
    "            max_ts = []; max_vals = []\n",
    "            # same left \n",
    "            segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [modif*side_val,side_val,0,side_val], span=span)\n",
    "            segms2, segm_ts1 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,0,side_val], span=span)\n",
    "            #segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [modif*side_val,side_val,side_val,0,0], span=span)\n",
    "            # each segment has to start from 0 and end at the peak\n",
    "            for s_n in np.arange(len(segms1)):\n",
    "                segm1 = np.array(segms1[s_n]); segm2 = np.array(segms2[s_n])\n",
    "                ref_x, ref_y = segm1[0], segm2[0]\n",
    "                distance = np.sqrt((segm1 - ref_x)**2 + (segm2 - ref_y)**2).tolist()\n",
    "                max_t = np.argmax(distance)\n",
    "                max_distance = distance[max_t]\n",
    "                max_ts.append(max_t)\n",
    "                max_vals.append(max_distance)\n",
    "            max_distances[sameness][side] = max_vals\n",
    "            peak_ts[sameness][side] = max_ts\n",
    "    \n",
    "    \n",
    "    stat, p_val = stats.ttest_ind(max_distances['same']['l']+max_distances['same']['r'],\n",
    "                                  max_distances['diff']['l']+max_distances['diff']['r']) \n",
    "    stat, p_val_t = stats.ttest_ind(peak_ts['same']['l']+peak_ts['same']['r'],\n",
    "                                  peak_ts['diff']['l']+peak_ts['diff']['r']) \n",
    "    '''\n",
    "       # stat, p_val = stats.ttest_ind(peak_ts['same'][side], peak_ts['diff'][side]) \n",
    "    p_thr = 0.05\n",
    "    if (p_val < p_thr) & (p_val_t < p_thr):\n",
    "        print(combo)\n",
    "        print('dist: ', \n",
    "              round(np.mean(max_distances['same']['l']+max_distances['same']['r']),2), \n",
    "              round(np.mean(max_distances['diff']['l']+max_distances['diff']['r']),2), \n",
    "              p_val)\n",
    "        print('time: ', \n",
    "              round(np.mean(peak_ts['same']['l']+peak_ts['same']['r']),2), \n",
    "              round(np.mean(peak_ts['diff']['l']+peak_ts['diff']['r']),2), \n",
    "              p_val_t)\n",
    "              '''\n",
    "\n",
    "    data[id]['max_distances']['same_l'] = max_distances['same']\n",
    "    data[id]['max_distances']['diff_l'] = max_distances['diff']\n",
    "    data[id]['peak_ts']['same_l'] = peak_ts['same']\n",
    "    data[id]['peak_ts']['diff_l'] = peak_ts['diff']\n",
    "\n",
    "    t_to_peak_mice[id]['same_l'] = peak_ts['same']\n",
    "    t_to_peak_mice[id]['diff_l'] = peak_ts['diff']\n",
    "    max_distances_mice[id]['same_l'] = max_distances['same']\n",
    "    max_distances_mice[id]['diff_l'] = max_distances['diff']\n",
    "\n",
    "            \n",
    "           # plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b3f41-8f3d-4ac8-8ccf-84bda084530a",
   "metadata": {},
   "source": [
    "### Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d4b26-c1b8-4629-b6a6-84cd21b60f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, combine_pvalues\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "stats_to_check = t_to_peak_mice\n",
    "same_all = []\n",
    "diff_all = []\n",
    "median_same = []\n",
    "median_diff = []\n",
    "for id in mouse_ids:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    same_all.extend(mouse_values['same']['r'])\n",
    "    diff_all.extend(mouse_values['diff']['r'])\n",
    "\n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(mouse_values['same']['r']))\n",
    "    median_diff.append(np.median(mouse_values['diff']['r']))\n",
    "\n",
    "\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "p_values = []\n",
    "for id in mouse_ids:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    same = mouse_values['same']['r']\n",
    "    diff = mouse_values['diff']['r']\n",
    "    stat, p_value = mannwhitneyu(same, diff, alternative='two-sided')\n",
    "    print(f'mannwhitneyu: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "\n",
    "# Step 3: Plot the boxplot for 'same' and 'diff' conditions\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Diff']\n",
    "box = ax.boxplot([same_all, diff_all], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'purple']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add one line for each experiment (median values for same and diff)\n",
    "for i in range(len(median_same)):\n",
    "    ax.plot([1, 2], [median_same[i], median_diff[i]], color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Time to Peak')\n",
    "ax.set_title('Comparison of Same vs Diff Conditions')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ad185-14a7-410a-9c9c-c6f10cc43b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bef2ad-56fc-4ccb-83dd-3322903375aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, combine_pvalues\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "stats_to_check = t_to_peak_mice\n",
    "same_all = []\n",
    "diff_all = []\n",
    "median_same = []\n",
    "median_diff = []\n",
    "for id in mouse_ids:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    same_all.extend(mouse_values['same']['l'])\n",
    "    diff_all.extend(mouse_values['diff_l']['l'])\n",
    "\n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(mouse_values['same']['l']))\n",
    "    median_diff.append(np.median(mouse_values['same_l']['l']))\n",
    "\n",
    "\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "p_values = []\n",
    "for id in mouse_ids:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    same = mouse_values['same']['l']\n",
    "    diff = mouse_values['same_l']['l']\n",
    "    stat, p_value = mannwhitneyu(same, diff, alternative='two-sided')\n",
    "    print(f'mannwhitneyu: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "\n",
    "# Step 3: Plot the boxplot for 'same' and 'diff' conditions\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Diff']\n",
    "box = ax.boxplot([same_all, diff_all], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'purple']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add one line for each experiment (median values for same and diff)\n",
    "for i in range(len(median_same)):\n",
    "    ax.plot([1, 2], [median_same[i], median_diff[i]], color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Time to Peak')\n",
    "ax.set_title('Comparison of Same vs Diff Conditions')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e12886-6890-41ce-8ef7-a1b94ff57ba6",
   "metadata": {},
   "source": [
    "### My Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048b18e-ae81-4c37-b40c-3c926e5bc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, combine_pvalues\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "stats_to_check = max_distances_mice # max_distances_mice # t_to_peak_mice\n",
    "cond1s = []\n",
    "cond2s = []\n",
    "cond3s = []\n",
    "cond4s = []\n",
    "median_cond1s = []\n",
    "median_cond2s = []\n",
    "p_values = []\n",
    "side = 'l'\n",
    "for id in mouse_ids[:-1]:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    cond1 = mouse_values['same'][side] \n",
    "    cond2 = mouse_values['same_l'][side]\n",
    "    cond1s.extend(cond1)\n",
    "    cond2s.extend(cond2)\n",
    "    cond3 = mouse_values['diff'][side] \n",
    "    cond4 = mouse_values['diff_l'][side]\n",
    "    cond3s.extend(cond3)\n",
    "    cond4s.extend(cond4)\n",
    "\n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(cond1))\n",
    "    median_diff.append(np.median(cond2))\n",
    "    # Perform one-tailed t-test (assuming condition1 > condition2)\n",
    "    t_stat, p_value = stats.ttest_ind(cond3, cond4, alternative='greater')\n",
    "\n",
    "    #stat, p_value = mannwhitneyu(cond1, cond2, alternative='two-sided')\n",
    "  #  stat, p_value = stats.ttest_ind(cond1, cond2)\n",
    "    print(f'mannwhitneyu: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "stat, p_value = mannwhitneyu(cond1s, cond2s, alternative='two-sided')\n",
    "print(f'AAAmannwhitneyu: {p_value}')\n",
    "# Step 3: Plot the boxplot for 'same' and 'diff' conditions\n",
    "fig, axs = plt.subplots(1,2, figsize=(9, 6))\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Same+stim', 'Diff', 'Diff+stim']\n",
    "box = axs[0].boxplot([cond1s, cond2s, cond3s, cond4s], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'lime', 'purple', 'pink']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add one line for each experiment (median values for same and diff)\n",
    "for i in range(len(median_cond1s)):\n",
    "    ax.plot([1, 2], [median_cond1s[i], median_cond2s[i]], color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "\n",
    "cond1s = []\n",
    "cond2s = []\n",
    "cond3s = []\n",
    "cond4s = []\n",
    "median_cond1s = []\n",
    "median_cond2s = []\n",
    "p_values = []\n",
    "side = 'r'\n",
    "for id in mouse_ids[:-1]:\n",
    "    mouse_values = stats_to_check[id]\n",
    "    cond1 = mouse_values['same'][side] \n",
    "    cond2 = mouse_values['same_l'][side]\n",
    "    cond1s.extend(cond1)\n",
    "    cond2s.extend(cond2)\n",
    "    cond3 = mouse_values['diff'][side] \n",
    "    cond4 = mouse_values['diff_l'][side]\n",
    "    cond3s.extend(cond3)\n",
    "    cond4s.extend(cond4)\n",
    "\n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(cond1))\n",
    "    median_diff.append(np.median(cond2))\n",
    "    # Perform one-tailed t-test (assuming condition1 > condition2)\n",
    "    t_stat, p_value = stats.ttest_ind(cond2, cond1, alternative='greater')\n",
    "\n",
    "    #stat, p_value = mannwhitneyu(cond1, cond2, alternative='two-sided')\n",
    "  #  stat, p_value = stats.ttest_ind(cond1, cond2)\n",
    "    print(f'mannwhitneyu: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "stat, p_value = mannwhitneyu(cond1s, cond2s, alternative='two-sided')\n",
    "print(f'AAAmannwhitneyu: {p_value}')\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Same+stim', 'Diff', 'Diff+stim']\n",
    "box = axs[1].boxplot([cond1s, cond2s, cond3s, cond4s], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'lime', 'purple', 'pink']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axs[0].set_title('Left laser', fontsize=16)\n",
    "axs[1].set_title('Right laser', fontsize=16)\n",
    "\n",
    "# Add labels and title\n",
    "for ax_n in [0,1]:\n",
    "    axs[ax_n].set_ylabel('Maximum value in IC space', fontsize=14)\n",
    "\n",
    "    # Remove top and right spines for cleaner look\n",
    "    axs[ax_n].spines['right'].set_visible(False)\n",
    "    axs[ax_n].spines['top'].set_visible(False)\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\papers_thesis\\\\figs\\\\' + 'laser_comp_summaryBB.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b04ee-2404-49ea-ad92-e9e2732c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37fda4-5613-427d-8db3-0de65f476fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_pcs = {'os85a': [4,6], 'os85b': [3,5], 'os86a': [7,12], 'os86b': [5,3], \n",
    "  #                   'os87': [8,14], 'os88': [2,1], 'os89': [12,5]}\n",
    "\n",
    "'''\n",
    "cross_pcs = {'os85a': [13, 6],\n",
    " 'os85b': [3, 15],\n",
    " 'os86a': [16, 11],\n",
    " 'os86b': [12, 7],\n",
    " 'os87': [3, 5],\n",
    " 'os88': [7, 8],\n",
    " 'os89': [5, 12]}\n",
    " '''\n",
    "# Trajectories for 2 selected components\n",
    "# For each mouse\n",
    "condition_pairs = [ ['left_side_same', 'left_side_diff'],\n",
    "                   ['right_side_same', 'right_side_diff'] ]\n",
    "all_peak_ts_same = []\n",
    "all_peak_ts_diff = []\n",
    "max_comp_mice_las = {}\n",
    "\n",
    "            \n",
    "for id in mouse_ids:\n",
    "    mouse_peak_ts_same = []\n",
    "    mouse_peak_ts_diff = []\n",
    "#    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    frame_ts = data_exp['frame_ts']\n",
    " #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "   # pc1 = pcas['IC' + str(comp_ns[0])]; pc2 = pcas['IC' + str(comp_ns[1])]\n",
    "    pc1 = pcas['PC1']; pc2 = pcas['PC2']\n",
    "    params = ['prev_side', 'side', 'missed', 'free', 'choice', 'laser']\n",
    "    span = [0, 4000]\n",
    "    # ==== LEFT ====\n",
    "    peak_ts_same = []; dist_same = []\n",
    "    dist_max_same = []; dist_max_diff = []\n",
    "    max_comp_vals = {'same': [], 'diff': []}\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    \n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_ts_same.append(peak_t)\n",
    "        dist_max_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "     #   axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "    #    axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "        \n",
    "    max_comp_vals['same'].append(dist_same)\n",
    "    # same left \n",
    "    peak_ts_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_ts_diff.append(peak_t)\n",
    "        dist_max_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "      #  axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "     #   axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "#    print(np.mean(peak_ts_same), np.mean(peak_ts_diff)) \n",
    "    left_info = [np.mean(peak_ts_same), np.mean(peak_ts_diff)]\n",
    "    all_peak_ts_same += peak_ts_same\n",
    "    all_peak_ts_diff += peak_ts_diff\n",
    "    mouse_peak_ts_same += peak_ts_same\n",
    "    mouse_peak_ts_diff += peak_ts_diff\n",
    "    stat, p_val_l_t = stats.ttest_ind(peak_ts_same, peak_ts_diff)  \n",
    "\n",
    "    \n",
    "    data[id]['t_to_peak_L'] = {'same': peak_ts_same, 'diff': peak_ts_diff}\n",
    "    max_vals_l = {'same': peak_ts_same, 'diff': peak_ts_diff}\n",
    "    max_comp_vals['same'].append(dist_same)\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_ts_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        dist_max_same.append(max(distances))\n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_ts_same.append(peak_t)\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "      #  axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "      #  axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_ts_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_ts_diff.append(peak_t)\n",
    "        dist_max_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "      #  axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "      #  axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "    \n",
    "    stat, p_val_r_t = stats.ttest_ind(peak_ts_same, peak_ts_diff)    \n",
    "    \n",
    "   # print(np.mean(peak_ts_same), np.mean(peak_ts_diff)) \n",
    "   # print('p for time to peak', p_val)\n",
    "    \n",
    "  #  print(np.mean(dist_max_same), np.mean(dist_max_diff)) \n",
    "    stat, p_val_m = stats.ttest_ind(dist_max_diff, dist_max_same)  \n",
    "    p_thr = 0.01\n",
    "    if (p_val_m < p_thr): \n",
    "        print(p_val_m)\n",
    "   #     print(np.mean(peak_ts_same), np.mean(peak_ts_diff)) \n",
    "        print(np.mean(dist_max_same), np.mean(dist_max_diff)) \n",
    "  #  print('max value p', p_val)\n",
    "    all_peak_ts_same += peak_ts_same\n",
    "    all_peak_ts_diff += peak_ts_diff\n",
    "    mouse_peak_ts_same += peak_ts_same\n",
    "    mouse_peak_ts_diff += peak_ts_diff\n",
    "    data[id]['t_to_peak_R'] = {'same': peak_ts_same, 'diff': peak_ts_diff}\n",
    "    data[id]['t_to_peak'] = {'same': mouse_peak_ts_same, 'diff': mouse_peak_ts_diff}\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    max_comp_vals = {'same': dist_max_same, 'diff': dist_max_diff}\n",
    "    max_comp_mice_las[id] = max_comp_vals\n",
    "\n",
    "            \n",
    "           # plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc498f2-54d8-4a67-b4f6-cb60fbeb0156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8088f-8e99-4f24-8dc2-a0bc430b3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon, combine_pvalues\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ttest_ind\n",
    "# Example data for multiple mice\n",
    "t_to_peak_mice = max_comp_mice_las\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "p_values = []\n",
    "all_same = []; all_diff = []\n",
    "for mouse, mouse_values in t_to_peak_mice.items():\n",
    "    same = mouse_values['same']\n",
    "    diff = mouse_values['diff']\n",
    "    all_same += same; all_diff += diff\n",
    "    # Perform Mann-Whitney U test\n",
    "    print(f' mean same {round(np.mean(same),2)} std same {round(np.std(same),2)}')\n",
    "    print(f' mean diff {round(np.mean(diff),2)} std diff {round(np.std(diff),2)}')\n",
    "    stat, p_value = mannwhitneyu(same, diff, alternative='two-sided')\n",
    "    stat, p_value = ttest_ind(same, diff) #, alternative='two-sided')\n",
    "    p_values.append(p_value)\n",
    "    print(f'{mouse}: Mann-Whitney U p-value = {p_value}')\n",
    "\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "\n",
    "# Step 3: Output the combined p-value\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "print(f' mean same {round(np.mean(all_same),2)} std same {round(np.std(all_same),2)}')\n",
    "print(f' mean diff {round(np.mean(all_diff),2)} std diff {round(np.std(all_diff),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce35473-c7aa-4121-b1f9-6e1f9f3a9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, combine_pvalues\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "same_all = []\n",
    "diff_all = []\n",
    "median_same = []\n",
    "median_diff = []\n",
    "for mouse_values in t_to_peak_mice.values():\n",
    "    same_all.extend(mouse_values['same'])\n",
    "    diff_all.extend(mouse_values['diff'])\n",
    "    \n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(mouse_values['same']))\n",
    "    median_diff.append(np.median(mouse_values['diff']))\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "same_alll = []\n",
    "diff_alll = []\n",
    "median_samel = []\n",
    "median_diffl = []\n",
    "for mouse_values in max_comp_mice_las.values():\n",
    "    same_alll.extend(mouse_values['same'])\n",
    "    diff_alll.extend(mouse_values['diff'])\n",
    "    \n",
    "    # Compute median for each mouse\n",
    "    median_samel.append(np.median(mouse_values['same']))\n",
    "    median_diffl.append(np.median(mouse_values['diff']))\n",
    "\n",
    "# Step 1: Perform Mann-Whitney U test for each mouse\n",
    "p_values = []\n",
    "for id in mouse_ids:\n",
    "#for mouse, mouse_values in max_comp_mice.items():\n",
    "    same = max_comp_mice[id]['diff']\n",
    "    same_l = max_comp_mice_las[id]['diff']\n",
    "    stat, p_value = mannwhitneyu(same, same_l, alternative='two-sided')\n",
    "    print(f'mannwhitneyu: {p_value}')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Combine p-values using Fisher's method\n",
    "stat_combined, p_value_combined = combine_pvalues(p_values, method='fisher')\n",
    "print(f'Combined p-value across all mice (Fisher\\'s method): {p_value_combined}')\n",
    "\n",
    "# Step 3: Plot the boxplot for 'same' and 'diff' conditions\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Diff']\n",
    "box = ax.boxplot([same_all, same_alll], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'purple']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add one line for each experiment (median values for same and diff)\n",
    "for i in range(len(median_same)):\n",
    "    ax.plot([1, 2], [median_same[i], median_diff[i]], color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Time to Peak')\n",
    "ax.set_title('Comparison of Same vs Diff Conditions')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366ce0d-d4b3-45f3-b1af-c09080db4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, combine_pvalues\n",
    "\n",
    "# Aggregate data for 'same' and 'diff'\n",
    "same_all = []\n",
    "diff_all = []\n",
    "median_same = []\n",
    "median_diff = []\n",
    "same_alll = []\n",
    "diff_alll = []\n",
    "median_samel = []\n",
    "median_diffl = []\n",
    "for mouse_values in t_to_peak_mice.values():\n",
    "    same_alll.extend(mouse_values['same'])\n",
    "    diff_alll.extend(mouse_values['diff'])\n",
    "    \n",
    "    # Compute median for each mouse\n",
    "    median_samel.append(np.median(mouse_values['same']))\n",
    "    median_diffl.append(np.median(mouse_values['diff']))\n",
    "for mouse_values in t_to_peak_mice_las.values():\n",
    "    same_all.extend(mouse_values['same'])\n",
    "    diff_all.extend(mouse_values['diff'])\n",
    "    \n",
    "    # Compute median for each mouse\n",
    "    median_same.append(np.median(mouse_values['same']))\n",
    "    median_diff.append(np.median(mouse_values['diff']))\n",
    "\n",
    "\n",
    "# Step 3: Plot the boxplot for 'same' and 'diff' conditions\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create boxplots\n",
    "box_labels = ['Same', 'Same l',  'Diff','Diff l']\n",
    "box = ax.boxplot([same_all, same_alll, diff_all, diff_alll], labels=box_labels, patch_artist=True, notch=True)\n",
    "\n",
    "# Customize colors\n",
    "colors = ['green', 'lime', 'purple', 'pink']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add one line for each experiment (median values for same and diff)\n",
    "#for i in range(len(median_same)):\n",
    " #   ax.plot([1, 2, 3, 4], [median_same[i], median_diff[i]], color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Time to Peak')\n",
    "ax.set_title('Comparison of Same vs Diff Conditions')\n",
    "\n",
    "# Remove top and right spines for cleaner look\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f03426-1dcc-48c7-bc35-11d758bfdc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unburden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213cd73-fe7a-4791-84a0-c5f15801371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,4], 'os89': [1,2]}\n",
    "cross_pcs = {'os85a': [1,2], 'os85b': [1,3], 'os86a': [2,5], 'os86b': [1,2], \n",
    "                     'os87': [1,2], 'os88': [1,3], 'os89': [1,2]}\n",
    "'''\n",
    "\n",
    "# side\n",
    "# 12 comps\n",
    "cross_pcs = {'os85a': [3,2], 'os85b': [8,5], 'os86a': [1,4], 'os86b': [12,9], \n",
    "                     'os87': [7,6], 'os88': [1,8], 'os89': [7,8]}\n",
    "                     '''\n",
    "# 16 comps\n",
    "cross_pcs = {'os85a': [13,4], 'os85b': [2,5], 'os86a': [2,3], 'os86b': [5,3], \n",
    "                     'os87': [8,14], 'os88': [2,1], 'os89': [12,5]}\n",
    "                     \n",
    "# laser\n",
    "#cross_pcs = {'os85a': [12,2], 'os85b': [8,9], 'os86a': [1,10], 'os86b': [2,5], \n",
    "         #            'os87': [7,6], 'os88': [6,9], 'os89': [12,3]}\n",
    "# ================ LASER NOW ===================\n",
    "for id in mice_ids:\n",
    "    print(f\"::: Mouse  {id} :::\")\n",
    "    data_exp = data[id]\n",
    "    behav = data_exp['behav']\n",
    "    pcas = data[id]['PCA']\n",
    "    pc1 = pcas['PC1']; pc2 = pcas['PC2']\n",
    "    pc1 = pcas['PC' + str(comp_ns[0])]; pc2 = pcas['PC' + str(comp_ns[1])]\n",
    "  #  pcas = data[id]['ICA']\n",
    "  #  pc1 = pcas['IC' + str(comp_ns[0])]; pc2 = pcas['IC' + str(comp_ns[1])]\n",
    "    frame_ts = data_exp['frame_ts']\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 3))\n",
    "    ax_n = 0\n",
    "    comp_ns = cross_pcs[id]\n",
    "    \n",
    "    params = ['prev_side', 'side', 'missed', 'laser', 'choice']\n",
    "    span = [0, 4000]\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # ==== LEFT ====\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,0,1], span=span)\n",
    "    table_means = {'side': [], 'laser': [], 'is_same': [], 'mean': []}\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,0,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "   # print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "    print('p for max val L', p_val)\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    \n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,0,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "  #  print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    " #   print('p for max val R', p_val)\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(False)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # ==== LEFT ====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "       # segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]     \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        #segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'b', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[0], segm2[0], 'b', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'b', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,1,0,1,1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[0] for s in segm1]\n",
    "      #  segm2 = [s-segm2[0] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'c', alpha=0.5)\n",
    "        #axs[ax_n].plot(segm1[0], segm2[0], 'c', marker='o', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[-1], segm2[-1], 'c', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "  #  print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "  #  print('p for max val L laser', p_val)\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    # ==== RIGHT =====\n",
    "    ax_n += 1\n",
    "    peak_vals_same = []; dist_same = []\n",
    "    # same left \n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [-1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "      #  segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "     #   time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx; # abs_segm.index(max(abs_segm))\n",
    "        peak_vals_same.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'r', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'r', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'r', marker='D', alpha=0.5)\n",
    "        # Assuming segm1 and segm2 are lists or arrays of coordinates [x1, y1] and [x2, y2]\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_same.append(distance)\n",
    "\n",
    "    # same left \n",
    "    #ax_n += 1\n",
    "    peak_vals_diff = []; dist_diff = []\n",
    "    segms1, segm_ts1 = get_segments(behav, pc1, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    segms2, segm_ts2 = get_segments(behav, pc2, frame_ts, params, [1,-1,0,-1,-1], span=span)\n",
    "    # each segment has to start from 0 and end at the peak\n",
    "    for s_n in np.arange(len(segms1)):\n",
    "        segm1 = segms1[s_n]; segm2 = segms2[s_n]\n",
    "        segm1 = segm1.tolist(); segm2 = segm2.tolist()\n",
    "     #   segm1 = [s-segm1[-1] for s in segm1]\n",
    "      #  segm2 = [s-segm2[-1] for s in segm2]\n",
    "        # Assuming segm1 is an array of x coordinates and segm2 is an array of y coordinates\n",
    "        # And time is an array of corresponding time steps\n",
    "\n",
    "        # Calculate the distance from the start (first point)\n",
    "        distances = np.sqrt((np.array(segm1) - segm1[0])**2 + (np.array(segm2) - segm2[0])**2)\n",
    "\n",
    "        # Find the index of the maximum distance\n",
    "        max_distance_idx = np.argmax(distances)\n",
    "        \n",
    "        # The time when the line is furthest away\n",
    "      #  time_furthest_away = time[max_distance_idx]\n",
    "\n",
    "        \n",
    "        peak_t = max_distance_idx #abs_segm.index(max(abs_segm))\n",
    "        peak_vals_diff.append(max(distances))\n",
    "        segm1 = segm1[:peak_t]; segm2 = segm2[:peak_t]\n",
    "        axs[ax_n].plot(segm1, segm2, 'm', alpha=0.5)\n",
    "        axs[ax_n].plot(segm1[0], segm2[0], 'm', marker='o', alpha=0.5)\n",
    "       # axs[ax_n].plot(segm1[-1], segm2[-1], 'm', marker='D', alpha=0.5)\n",
    "        segm1 = np.array(segm1); segm2 = np.array(segm2)\n",
    "        # Calculate the Euclidean distance\n",
    "        distance = np.linalg.norm(segm2 - segm1); dist_diff.append(distance)\n",
    "    \n",
    "   # print(np.mean(peak_vals_same), np.mean(peak_vals_diff)) \n",
    "    stat, p_val = stats.ttest_ind(peak_vals_same, peak_vals_diff)    \n",
    "   # print('p for max val R laser', p_val)\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(True)\n",
    "    table_means['mean'].append(np.mean(peak_vals_same))\n",
    "    table_means['side'].append(-1)\n",
    "    table_means['laser'].append(True)\n",
    "    table_means['is_same'].append(False)\n",
    "    table_means['mean'].append(np.mean(peak_vals_diff))\n",
    "    '''\n",
    "    print(np.mean(dist_same), np.mean(dist_diff)) \n",
    "    stat, p_val = stats.ttest_ind(dist_same, dist_diff)    \n",
    "    print('p for distances', p_val)\n",
    "    '''\n",
    "    table_means = pd.DataFrame(table_means)\n",
    "  #  print(table_means)\n",
    "    data[id]['table_means'] = table_means\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81273e07-5dbf-4d21-b4be-23f1a2010df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl = []\n",
    "all_dl = []\n",
    "all_sr = []\n",
    "all_dr = []\n",
    "same_nolas = []; same_las = []\n",
    "diff_nolas = []; diff_las = []\n",
    "for id in mice_ids:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_sl.append(same_l); all_sr.append(same_r); \n",
    "    all_dl.append(diff_l); all_dr.append(diff_r); \n",
    "    same_nolas.append(same_l[0]); same_nolas.append(same_r[0]); \n",
    "    same_las.append(same_l[1]); same_las.append(same_r[1]); \n",
    "    diff_nolas.append(diff_l[0]); diff_nolas.append(diff_r[0]); \n",
    "    diff_las.append(diff_l[1]); diff_las.append(diff_r[1]); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_sl, axis=0), 'b', linewidth=6)\n",
    "plt.plot([0,1], np.mean(all_sr, axis=0), 'r', linewidth=6)\n",
    "\n",
    "plt.plot([2,3], np.mean(all_dl, axis=0), 'c', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_dr, axis=0), 'm', linewidth=6)\n",
    "plt.show()\n",
    "# do the ttest\n",
    "stat, p_val = stats.ttest_ind(same_nolas, same_las)    \n",
    "print('p for ', p_val)\n",
    "stat, p_val = stats.ttest_ind(diff_nolas, diff_las)    \n",
    "print('p for ', p_val)\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test\n",
    "stat, p_val = wilcoxon(same_nolas, same_las)\n",
    "print(f\"Wilcoxon signed-rank test results: statistic = {stat}, p-value = {round(p_val,7)}\")\n",
    "# Perform Wilcoxon signed-rank test\n",
    "stat, p_val = wilcoxon(diff_nolas, diff_las)\n",
    "print(f\"Wilcoxon signed-rank test results: statistic = {stat}, p-value = {round(p_val,7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befffd0-acb1-4fa7-8adf-e14b8b48d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_nolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02773b00-bf50-4eb6-ab15-d696fbb4d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl = []\n",
    "all_dl = []\n",
    "all_sr = []\n",
    "all_dr = []\n",
    "same_nolas = []; same_las = []\n",
    "diff_nolas = []; diff_las = []\n",
    "for id in mouse_ids[:-1]:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_sl.append(same_l); all_sr.append(same_r); \n",
    "    all_dl.append(diff_l); all_dr.append(diff_r); \n",
    "    same_nolas.append(same_l[0]); same_nolas.append(same_r[0]); \n",
    "    same_las.append(same_l[1]); same_las.append(same_r[1]); \n",
    "    diff_nolas.append(diff_l[0]); diff_nolas.append(diff_r[0]); \n",
    "    diff_las.append(diff_l[1]); diff_las.append(diff_r[1]); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_sl, axis=0), 'b', linewidth=6)\n",
    "plt.plot([0,1], np.mean(all_sr, axis=0), 'r', linewidth=6)\n",
    "\n",
    "plt.plot([2,3], np.mean(all_dl, axis=0), 'c', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_dr, axis=0), 'm', linewidth=6)\n",
    "plt.show()\n",
    "# do the ttest\n",
    "stat, p_val = stats.ttest_ind(same_nolas, same_las)    \n",
    "print('p for ', p_val)\n",
    "stat, p_val = stats.ttest_ind(diff_nolas, diff_las)    \n",
    "print('p for ', p_val)\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test\n",
    "stat, p_val = wilcoxon(same_nolas, same_las)\n",
    "print(f\"Wilcoxon signed-rank test results: statistic = {stat}, p-value = {round(p_val,7)}\")\n",
    "# Perform Wilcoxon signed-rank test\n",
    "stat, p_val = wilcoxon(diff_nolas, diff_las)\n",
    "print(f\"Wilcoxon signed-rank test results: statistic = {stat}, p-value = {round(p_val,7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79724ca4-6dbc-473c-b453-59268bf7a0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62592c6c-8455-494d-b1a4-4062420afdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl = []\n",
    "all_dl = []\n",
    "all_sr = []\n",
    "all_dr = []\n",
    "for id in mouse_ids[1:]:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_sl.append(same_l); all_sr.append(same_r); \n",
    "    all_dl.append(diff_l); all_dr.append(diff_r); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_sl, axis=0), 'b', linewidth=6)\n",
    "plt.plot([0,1], np.mean(all_sr, axis=0), 'r', linewidth=6)\n",
    "\n",
    "plt.plot([2,3], np.mean(all_dl, axis=0), 'c', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_dr, axis=0), 'm', linewidth=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d2238-cf67-4f9f-86ac-08f33ed92503",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl = []\n",
    "all_dl = []\n",
    "all_sr = []\n",
    "all_dr = []\n",
    "for id in ['os86a']:\n",
    "    table_means = data[id]['table_means']\n",
    "    same_l = table_means[(table_means['is_same']==True) & (table_means['side']==1)]['mean'].tolist()\n",
    "    same_r = table_means[(table_means['is_same']==True) & (table_means['side']==-1)]['mean'].tolist()\n",
    "    diff_l = table_means[(table_means['is_same']==False) & (table_means['side']==1)]['mean'].tolist()\n",
    "    diff_r = table_means[(table_means['is_same']==False) & (table_means['side']==-1)]['mean'].tolist()\n",
    "   # print(same_las, 'vs', same_nolas)\n",
    "    plt.plot([0,1], same_l, 'b')\n",
    "    plt.plot([0,1], same_r, 'r')\n",
    "    plt.plot([2,3], diff_l, 'c')\n",
    "    plt.plot([2,3], diff_r, 'm')\n",
    "    all_sl.append(same_l); all_sr.append(same_r); \n",
    "    all_dl.append(diff_l); all_dr.append(diff_r); \n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot([0,1], np.mean(all_sl, axis=0), 'b', linewidth=6)\n",
    "plt.plot([0,1], np.mean(all_sr, axis=0), 'r', linewidth=6)\n",
    "\n",
    "plt.plot([2,3], np.mean(all_dl, axis=0), 'c', linewidth=6)\n",
    "plt.plot([2,3], np.mean(all_dr, axis=0), 'm', linewidth=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547fb9a-319a-4cbd-a0b4-51cf15d7886c",
   "metadata": {},
   "source": [
    "## Time to calculate distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461610d-2ed4-4d69-9ea1-13620e9b7afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd709e0-71a3-4d7a-98ff-2ae22edba772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with calculating the distanecs btw left and right and verifying it with permutation\n",
    "coords_av = {'left_side_nolas': [], 'left_side_las': []}\n",
    "coords_av_permut = {'left_side': [], 'right_side': []}\n",
    "param_val_keys = {'left_side': {'params': ['side', 'laser', 'missed'], 'vals': [1,0,0]}, \n",
    "              'right_side': {'params': ['side', 'laser', 'missed'], 'vals': [-1,0,0]},\n",
    "              'left_side_nolas': {'params': ['side', 'laser', 'missed'], 'vals': [1,0,0]}, \n",
    "              'left_side_las': {'params': ['side', 'laser', 'missed'], 'vals': [1,1,0]} }\n",
    "w = [9,17]\n",
    "span = [0,30]\n",
    "icas = ica_df_time_points.keys()\n",
    "for key in coords_av.keys():\n",
    "    params = param_val_keys[key]['params']\n",
    "    vals = param_val_keys[key]['vals']\n",
    "    coords_cond = [] # all the coordinates of the given condition\n",
    "    # select segments based on the parameters and values specified\n",
    "    for ica_n in icas:\n",
    "        comp = ica_df_time_points[ica_n]\n",
    "        traces = get_segments_old(data_exp, params, vals, n, frame_type='frame_tone', span=span, is_pca=True, pc=comp)\n",
    "        coords_n = []\n",
    "        for tr_n in np.arange(len(traces)):\n",
    "            coord = np.mean(traces[tr_n][span[0]+w[0]:span[0]+w[1]])\n",
    "            coords_n.append(coord)\n",
    "        coord_n_av = np.mean(coords_n)\n",
    "        coords_cond.append(coord_n_av)\n",
    "   # coords_cond = np.array(coords_cond).T\n",
    "    coords_av[key] = coords_cond\n",
    "        \n",
    "        \n",
    "        \n",
    "# Compute the Euclidean distance btw the averaged coordinates\n",
    "distance = np.sqrt(np.sum((np.array(coords_av['left_side_nolas']) - np.array(coords_av['left_side_las']))**2))\n",
    "\n",
    "print(f'The distance between {str(coords_av.keys())[11:-2]} is {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d3162-721b-4c23-9027-afe3a2d9d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1505c1-ef38-4082-b705-db103a4943e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a0377-f3b3-40d8-913e-1eb8221b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# same thing as above but as a function\n",
    "\n",
    "def distance_btw_comp(condtions, data_exp, ca_df_time_points, w=[9, 17], span=[0, 30]):\n",
    "    coords_av = {condtions[0]:[], condtions[1]:[]}\n",
    "    \n",
    "\n",
    "    cas = ca_df_time_points.keys()\n",
    "    \n",
    "    for key in coords_av.keys():\n",
    "        params = param_val_keys[key]['params']\n",
    "        vals = param_val_keys[key]['vals']\n",
    "        coords_cond = []\n",
    "        \n",
    "        for ca_n in cas:\n",
    "            comp = ca_df_time_points[ca_n]\n",
    "            traces = get_segments_old(data_exp, params, vals, n, frame_type='frame_tone', span=span, is_pca=True, pc=comp)\n",
    "            coords_n = [np.mean(trace[span[0]+w[0]:span[0]+w[1]]) for trace in traces]\n",
    "            coord_n_av = np.mean(coords_n)\n",
    "            coords_cond.append(coord_n_av)\n",
    "        \n",
    "        coords_av[key] = coords_cond\n",
    "    \n",
    "    distance = np.sqrt(np.sum((np.array(coords_av[condtions[0]]) - np.array(coords_av[condtions[1]]))**2))\n",
    "    return distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f56940-d68e-41f1-bf3a-6172caac3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse 86 on 2024-05-26\n",
    "# For prev. conrtast laser vs no laser\n",
    "condtions_pairs = [\n",
    "                    ['left_side', 'right_side'],\n",
    "                    ['left_side_same_nolas', 'left_side_diff_nolas'],\n",
    "                    ['right_side_same_nolas', 'right_side_diff_nolas'],\n",
    "                    ['left_side_same_las', 'left_side_diff_las'],\n",
    "                    ['right_side_same_las', 'right_side_diff_las'],\n",
    "                  ]\n",
    "\n",
    "# ok lets do ica for all the mice\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print('=== ' + id + ' ' + date + ' ===')\n",
    "        data_exp = data[id][date]\n",
    "        ica_df_time_points = data_exp['ICA']\n",
    "        for conditions in condtions_pairs:\n",
    "            distance = distance_btw_comp(conditions, data_exp, ica_df_time_points, w=[8,14])\n",
    "            print(f'The distance between {conditions[0]} and {conditions[1]} is {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e80706-4483-4e43-97a7-c609990b2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for conditions in condtions_pairs:\n",
    "    distance = distance_btw_comp(conditions, data_exp, ica_df_time_points, w=[8,14])\n",
    "    print(f'The distance between {conditions[0]} and {conditions[1]} is {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765acc8f-6c60-4c66-bdb3-3b6dd34efbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "condtions_example = ['left_side_nolas', 'left_side_las']\n",
    "data_exp_example = data_exp  # Replace with your data\n",
    "ica_df_time_points_example = ica_df_time_points  # Replace with your data\n",
    "\n",
    "distance = distance_btw_comp(condtions_example, data_exp_example, ica_df_time_points_example)\n",
    "print(f'The distance between {condtions_example[0]} and {condtions_example[1]} is {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39c18c-8ded-47bf-aaca-1b3786207e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but with laser\n",
    "    \n",
    "pc = ica_df_time_points['IC4']\n",
    "n = 99\n",
    "params = ['side', 'prev_reward', 'laser']\n",
    "traces_pc1 = {\n",
    "    'l_same_nolas': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_nolas': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_same_las': get_segments_old(data_exp, params, [1, 1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_las': get_segments_old(data_exp, params, [1, -1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "pc = ica_df_time_points['IC7']\n",
    "traces_pc2 = {\n",
    "    'l_same_nolas': get_segments_old(data_exp, params, [1, 1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_nolas': get_segments_old(data_exp, params, [1, -1, 0], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_same_las': get_segments_old(data_exp, params, [1, 1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "    'l_diff_las': get_segments_old(data_exp, params, [1, -1, 1], n, frame_type='frame_tone', is_pca=True, pc=pc),\n",
    "}\n",
    "\n",
    "marker_specs = {'l_same_nolas': {'color':'b', 'marker':'o'},\n",
    "                'l_diff_nolas':{'color':'c', 'marker':'o'},\n",
    "                'l_same_las': {'color':'b', 'marker':'D'},\n",
    "                'l_diff_las': {'color':'c', 'marker':'D'}}\n",
    "\n",
    "# t_windows = [ [0,5], [6,10], [11,15], [16,20]]\n",
    "t_windows = [[t, t + 1] for t in np.arange(0, 30, 5)]\n",
    "\n",
    "# setup the plot\n",
    "fig, axs = plt.subplots(1, len(t_windows), figsize=(15, 2))\n",
    "ax_n = 0\n",
    "\n",
    "for w in t_windows:\n",
    "    for key in traces_pc1.keys():\n",
    "        segms_pc1 = traces_pc1[key]\n",
    "        segms_pc2 = traces_pc2[key]\n",
    "        avs_pc1 = []\n",
    "        avs_pc2 = []\n",
    "        color = marker_specs[key]['color']\n",
    "        marker = marker_specs[key]['marker']\n",
    "    \n",
    "        for segment_n in np.arange(len(segms_pc1)):\n",
    "            segm_pc1 = traces_pc1[key][segment_n]\n",
    "            segm_pc2 = traces_pc2[key][segment_n]\n",
    "            av_pc1 = np.mean(segm_pc1[w[0]:w[1]])\n",
    "            av_pc2 = np.mean(segm_pc2[w[0]:w[1]])\n",
    "            avs_pc1.append(av_pc1)\n",
    "            avs_pc2.append(av_pc2)\n",
    "            \n",
    "            axs[ax_n].plot(av_pc1, av_pc2, color=color, marker=marker, markersize=3, alpha=0.2)\n",
    "        av_segms_1 = np.mean(avs_pc1)\n",
    "        av_segms_2 = np.mean(avs_pc2)\n",
    "        axs[ax_n].plot(av_segms_1,av_segms_2, color=color, marker=marker, markersize=12,markeredgewidth=2,fillstyle='none')\n",
    "\n",
    "    ax_n += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e5c4f-7dce-46d3-8be8-c1e9ba849495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['deconv'] \n",
    "        behav = data_exp['behav']\n",
    "        params = ['side', 'prev_choice', 'laser']\n",
    "        \n",
    "        all_aucs = []\n",
    "        for neu in np.arange(traces.shape[0]):\n",
    "            # if the neurons is not good or fair, skip it\n",
    "            if data_exp['good_neurons'][neu] + data_exp['fair_neurons'][neu] == 0:\n",
    "                continue\n",
    "            \n",
    "            trace = traces[neu,:]\n",
    "            aucs = []\n",
    "            for trial_n in np.arange(behav.shape[0]):\n",
    "                f = behav['frame_tone'][trial_n]\n",
    "                if f > traces.shape[1]:\n",
    "                    continue\n",
    "                auc = sum(trace[f+10:f+20])\n",
    "                aucs.append(auc)\n",
    "            if len(all_aucs) == 0:\n",
    "                all_aucs = aucs\n",
    "            else:\n",
    "                all_aucs = np.column_stack((all_aucs,aucs))\n",
    "        # Perform PCA to reduce from 60 to 2 dimensions\n",
    "        pca = PCA(n_components=10)\n",
    "        pca_result = pca.fit_transform(all_aucs)\n",
    "        \n",
    "        # Create a DataFrame for easier handling\n",
    "        columns=['PC1', 'PC2','PC3', 'PC4']\n",
    "        laser_conds = [str(behav['prev_choice'][n]) + str(behav['choice'][n]) for n in np.arange(all_aucs.shape[0])] \n",
    "        pcaa_df = pd.DataFrame(pca_result[:,0:4], columns=columns[0:4] ) #, 'PC3', 'PC4', 'PC5', 'PC6','PC7', 'PC8', 'PC9'])\n",
    "        pcaa_df['TrialType'] =  behav['choice'][0:all_aucs.shape[0]] #laser_conds\n",
    "        pcaa_df['laser'] = behav['laser'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['side'] = behav['side'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['choice'] = behav['choice'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['prev_choice'] = behav['prev_choice'][0:all_aucs.shape[0]]\n",
    "        \n",
    "        # Plot the PCA results\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        pca_l_same = pcaa_df[(pcaa_df['side']==1) & (pcaa_df['prev_choice']==1) & (pcaa_df['laser']==0)]\n",
    "        pca_l_diff = pcaa_df[(pcaa_df['side']==1) & (pcaa_df['prev_choice']==1) & (pcaa_df['laser']==1)]\n",
    "        pca_r_same = pcaa_df[(pcaa_df['side']==1) & (pcaa_df['prev_choice']==-1) & (pcaa_df['laser']==0)]\n",
    "        pca_r_diff = pcaa_df[(pcaa_df['side']==1) & (pcaa_df['prev_choice']==-1) & (pcaa_df['laser']==1)]\n",
    "        ax.scatter(pca_l_same['PC1'], pca_l_same['PC2'], pca_l_same['PC3'], label='left same no laser')\n",
    "        ax.scatter(pca_l_diff['PC1'], pca_l_diff['PC2'], pca_l_diff['PC2'], label='left same laser')\n",
    "        ax.scatter(pca_r_same['PC1'], pca_r_same['PC2'], pca_r_same['PC3'], label='left diff no laser')\n",
    "        ax.scatter(pca_r_diff['PC1'], pca_r_diff['PC2'], pca_r_diff['PC3'], label='left diff laser')\n",
    "        \n",
    "        #plt.scatter(pca_df['PC1'], pca_df['PC2'], label=trial_type)\n",
    "        plt.title('PCA of Neuronal Activity (AUC Features)')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd150ce-c7e1-45d2-8ad7-e5971cf2d8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bfdde-9570-439b-a207-9bbf037ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca'] \n",
    "        behav = data_exp['behav']\n",
    "        params = ['side', 'prev_choice', 'laser']\n",
    "        \n",
    "        all_aucs = []\n",
    "        for neu in np.arange(traces.shape[0]):\n",
    "            # if the neurons is not good or fair, skip it\n",
    "            if data_exp['good_neurons'][neu] == 0: # + data_exp['fair_neurons'][neu] == 0:\n",
    "\n",
    "                continue\n",
    "            \n",
    "            trace = traces[neu,:]\n",
    "\n",
    "            aucs = []\n",
    "            for trial_n in np.arange(behav.shape[0]):\n",
    "                f = behav['frame_tone'][trial_n]\n",
    "                if f > traces.shape[1]:\n",
    "                    continue\n",
    "                auc = sum(trace[f+5:f+25])\n",
    "                aucs.append(auc)\n",
    "            if len(all_aucs) == 0:\n",
    "                all_aucs = aucs\n",
    "            else:\n",
    "                all_aucs = np.column_stack((all_aucs,aucs))\n",
    "        # Perform PCA to reduce from 60 to 2 dimensions\n",
    "        pca = PCA(n_components=10)\n",
    "        pca_result = pca.fit_transform(all_aucs)\n",
    "        \n",
    "        # Create a DataFrame for easier handling\n",
    "        columns=['PC1', 'PC2','PC3', 'PC4']\n",
    "        laser_conds = [behav['laser'][n] + behav['choice'][n] for n in np.arange(all_aucs.shape[0])] \n",
    "        pcaa_df = pd.DataFrame(pca_result[:,0:4], columns=columns[0:4] ) #, 'PC3', 'PC4', 'PC5', 'PC6','PC7', 'PC8', 'PC9'])\n",
    "        pcaa_df['TrialType'] = behav['side'][0:all_aucs.shape[0]] \n",
    "        pcaa_df['laser'] = behav['laser'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['side'] = behav['side'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['choice'] = behav['choice'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['prev_choice'] = behav['prev_choice'][0:all_aucs.shape[0]]\n",
    "        \n",
    "        # Plot the PCA results\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for trial_type in pcaa_df['TrialType'].unique():\n",
    "            subset = pcaa_df[pcaa_df['TrialType'] == trial_type]\n",
    "            plt.scatter(subset['PC1'], subset['PC2'], label=trial_type)\n",
    "        #plt.scatter(pca_df['PC1'], pca_df['PC2'], label=trial_type)\n",
    "        plt.title('PCA of Neuronal Activity (AUC Features)')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a5d77-c0d3-4b4d-9b46-f435f9e6eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in mouse_ids:\n",
    "    dates = data[id].keys()\n",
    "    #if a:\n",
    "    for date in dates:\n",
    "        print(f\"::: Mouse  {id}, {date} :::\")\n",
    "\n",
    "        data_exp = data[id][date]\n",
    "        traces = data_exp['ca'] \n",
    "        behav = data_exp['behav']\n",
    "        params = ['side', 'prev_choice', 'laser']\n",
    "        \n",
    "        all_aucs = []\n",
    "        for neu in np.arange(traces.shape[0]):\n",
    "            # if the neurons is not good or fair, skip it\n",
    "            if data_exp['good_neurons'][neu] == 0: # + data_exp['fair_neurons'][neu] == 0:\n",
    "\n",
    "                continue\n",
    "            \n",
    "            trace = traces[neu,:]\n",
    "\n",
    "            aucs = []\n",
    "            for trial_n in np.arange(behav.shape[0]):\n",
    "                f = behav['frame_tone'][trial_n]\n",
    "                if f > traces.shape[1]:\n",
    "                    continue\n",
    "                auc = sum(trace[f+5:f+25])\n",
    "                aucs.append(auc)\n",
    "            if len(all_aucs) == 0:\n",
    "                all_aucs = aucs\n",
    "            else:\n",
    "                all_aucs = np.column_stack((all_aucs,aucs))\n",
    "        # Perform PCA to reduce from 60 to 2 dimensions\n",
    "        pca = PCA(n_components=10)\n",
    "        pca_result = pca.fit_transform(all_aucs)\n",
    "        \n",
    "        # Create a DataFrame for easier handling\n",
    "        columns=['PC1', 'PC2','PC3', 'PC4']\n",
    "        laser_conds = [behav['laser'][n] + behav['choice'][n] for n in np.arange(all_aucs.shape[0])] \n",
    "        pcaa_df = pd.DataFrame(pca_result[:,0:4], columns=columns[0:4] ) #, 'PC3', 'PC4', 'PC5', 'PC6','PC7', 'PC8', 'PC9'])\n",
    "        pcaa_df['TrialType'] = behav['side'][0:all_aucs.shape[0]] \n",
    "        pcaa_df['laser'] = behav['laser'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['side'] = behav['side'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['choice'] = behav['choice'][0:all_aucs.shape[0]]\n",
    "        pcaa_df['prev_choice'] = behav['prev_choice'][0:all_aucs.shape[0]]\n",
    "        \n",
    "        # Plot the PCA results\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for trial_type in pcaa_df['TrialType'].unique():\n",
    "            subset = pcaa_df[pcaa_df['TrialType'] == trial_type]\n",
    "            plt.scatter(subset['PC3'], subset['PC2'], label=trial_type)\n",
    "        #plt.scatter(pca_df['PC1'], pca_df['PC2'], label=trial_type)\n",
    "        plt.title('PCA of Neuronal Activity (AUC Features)')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b20048-ba52-4147-acc7-7b2846bd62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to reduce from 60 to 2 dimensions\n",
    "pca = PCA(n_components=10)\n",
    "pca_result = pca.fit_transform(all_aucs)\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "columns=['PC1', 'PC2','PC3', 'PC4']\n",
    "\n",
    "pcaa_df = pd.DataFrame(pca_result[:,0:4], columns=columns[0:4] ) #, 'PC3', 'PC4', 'PC5', 'PC6','PC7', 'PC8', 'PC9'])\n",
    "pcaa_df['TrialType'] = behav['prev_choice'][0:all_aucs.shape[0]]\n",
    "pcaa_df['laser'] = behav['laser'][0:all_aucs.shape[0]]\n",
    "pcaa_df['side'] = behav['side'][0:all_aucs.shape[0]]\n",
    "pcaa_df['choice'] = behav['choice'][0:all_aucs.shape[0]]\n",
    "pcaa_df['prev_choice'] = behav['prev_choice'][0:all_aucs.shape[0]]\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for trial_type in pcaa_df['TrialType'].unique():\n",
    "    subset = pcaa_df[pcaa_df['TrialType'] == trial_type]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=trial_type)\n",
    "#plt.scatter(pca_df['PC1'], pca_df['PC2'], label=trial_type)\n",
    "plt.title('PCA of Neuronal Activity (AUC Features)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249ae6d-78f1-4d76-a555-dbf27074a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d685aba-5865-4b63-ad84-abb00fc82c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68697e-b93d-42f9-84bf-d4f85ff1eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example data: rows are time points, columns are neurons\n",
    "id = 'os86'\n",
    "date = '2024-06-03'\n",
    "data_exp = data[id][date]\n",
    "traces = data_exp['deconv'] \n",
    "behav = data_exp['behav']\n",
    "params = ['side', 'prev_choice', 'laser']\n",
    "\n",
    "for neu in np.arange(traces.shape[0]):\n",
    "    # if the neurons is not good or fair, skip it\n",
    "    if data_exp['good_neurons'][neu] == 0:\n",
    "        continue\n",
    "    trace = traces[neu,:]\n",
    "    \n",
    "    aucs = []\n",
    "    for trial_n in behav.shape[0]:\n",
    "        f = behav['frame_tone']\n",
    "        if f > traces.shape[1]-11:\n",
    "            continue\n",
    "        auc = sum(trace[f:f+10])\n",
    "        aucs.append(auc)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "traces_left_same = get_segments_old(data_exp, params, [-1,-1,0], n, frame_type='frame_tone', \n",
    "                        trace_type='deconv') \n",
    "traces_left_diff = get_segments_old(data_exp, params, [-1,1,0], n, frame_type='frame_tone', \n",
    "                        trace_type='deconv') \n",
    "pre_tone = [0, 10]\n",
    "post_tone = [10, 20]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract AUC features for each trial\n",
    "left_same_aucs = []\n",
    "left_diff_aucs = []\n",
    "\n",
    "for trial_n in np.arange(traces_left_same.shape[0]):  # Assuming each column is a trial\n",
    "    signal = traces_left_same[trial_n,:]\n",
    "    auc_pre = sum(signal[0:10])\n",
    "    auc_post = sum(signal[10:20])\n",
    "    left_same_aucs.append([auc_pre, auc_post])\n",
    "\n",
    "for trial_n in np.arange(traces_left_diff.shape[0]):  # Assuming each column is a trial\n",
    "    signal = traces_left_diff[trial_n,:]\n",
    "    auc_pre = sum(signal[0:10])\n",
    "    auc_post = sum(signal[10:20])\n",
    "    left_diff_aucs.append([auc_pre, auc_post])\n",
    "    \n",
    "\n",
    "# Perform PCA to reduce from 60 to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_aucs)\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['TrialType'] = trial_labels\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for trial_type in pca_df['TrialType'].unique():\n",
    "    subset = pca_df[pca_df['TrialType'] == trial_type]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=trial_type)\n",
    "\n",
    "plt.title('PCA of Neuronal Activity (AUC Features)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"PCA of Neuronal Activity\", dataframe=pca_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe4977-a69d-4a82-a910-056235d83559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580ddfd-8716-4c1c-96e8-167a9e092b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832a25e-11c9-4f45-a870-5368071c9b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb592c-a6a9-402c-b96a-1d71a6be90b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e90304-4795-45af-93c6-d5c00d9cc18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
